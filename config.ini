
[PATH]
# OUTPUT_PATH (optional, folder path):
OUTPUT_PATH =
# VIDEO_TO_LABEL_PATH (required, file path): If the path is RELATIVE, it will be relative to DLC_PROJECT_PATH  # TODO: move this to PATH section
VIDEO_TO_LABEL_PATH =
[APP]
# PIPELINE_NAME (required, str): A default name for your pipeline output
PIPELINE_NAME = TestPipeline

# VIDEO_FRAME_RATE (required, float):
VIDEO_FRAME_RATE = 30
# PLOT_GRAPHS (required, bool): Change to False if you don't want plots brought up. It'll still save the output CSVs.
PLOT_GRAPHS = False
# SAVE_GRAPHS_TO_FILE (required, bool):
SAVE_GRAPHS_TO_FILE = False
# GENERATE_VIDEOS (required, bool): if this is true, make sure direct to the video below AND that you created the two specified folders!
GENERATE_VIDEOS = True
# FRAMES_OUTPUT_FORMAT (str):
FRAMES_OUTPUT_FORMAT = png
# DEFAULT_SAVED_GRAPH_FILE_FORMAT (str): Some valid file extensions: svg, jpg . For now, you must not pick 'png'. TODO: elaborate on below var desc.
DEFAULT_SAVED_GRAPH_FILE_FORMAT = jpg
# PERCENT_FRAMES_TO_LABEL (required, float): the percent of frames in VIDEO to label and output to FRAMES output path  # TODO: evaluate how it works, and if to keep, in new model structure
PERCENT_FRAMES_TO_LABEL = 0.5
# OUTPUT_VIDEO_FPS (optional, int): If left blank, package will match the input video FPS on output taking PERCENT_FRAMES_TO_LABEL into account TODO: explain better
OUTPUT_VIDEO_FPS =
# N_JOBS (required, int): Number of cores to use in multiprocessing steps. This value must be 1 or greater.
N_JOBS = 4
# FILE_IDENTIFICATION_ORDER_LEGACY (required, int): TODO: low/med: deprecate
FILE_IDENTIFICATION_ORDER_LEGACY = 0

[STREAMLIT]
# default_pipeline_location (str, optional): specify the location  # TODO: elaborate. Useful!
default_pipeline_location =

;[VIDEO]
;stuff =

[DLC_FEATURES]
# Modify the below values to reflect the name of the body parts used in DLC which will then be parsed in package.
SNOUT/HEAD = Snout/Head
LEFT_SHOULDER/FOREPAW = Forepaw/Shoulder1
RIGHT_SHOULDER/FOREPAW = Forepaw/Shoulder2
LEFT_HIP/HINDPAW = Hindpaw/Hip1
RIGHT_HIP/HINDPAW = Hindpaw/Hip2
TAILBASE = TailBase
NOSETIP = NoseTip
FOREPAW_LEFT = ForepawLeft
FOREPAW_RIGHT = ForepawRight
HINDPAW_LEFT = HindpawLeft
HINDPAW_RIGHT = HindpawRight


[MODEL]
# DEFAULT_CLASSIFIER (required, str): Valid entries include { SVM, RANDOMFOREST }
DEFAULT_CLASSIFIER = RANDOMFOREST
# RANDOM_STATE (required, int): Leave random_state value blank for using an actually random seed value
RANDOM_STATE = 42
# HOLDOUT_TEST_PCT (required, float):
HOLDOUT_TEST_PCT = 0.35
# CROSS_VALIDATION_K (required, int):
CROSS_VALIDATION_K = 5
# CROSS_VALIDATION_N_JOBS (required, int): Number of cores used for k-fold cross validation
#                                          (set to -1 to use all cores, -2 to use all cores but one)
CROSS_VALIDATION_N_JOBS = -2


[LOGGING]
### Name, format, and create log levels for the logger
### Valid log levels are limited to: CRITICAL, FATAL, ERROR, WARN, WARNING, INFO, DEBUG, NOTSET
# LOGGER_NAME (required, str):
DEFAULT_LOGGER_NAME = default_logger
# LOG_FILE_NAME (required, str):
LOG_FILE_NAME = default.log
# LOG_FORMAT (required, str):
LOG_FORMAT = %(asctime)s - %(name)s - %(levelname)-8s - %(message)s
# STREAM_LOG_LEVEL (required, str): (Debugging: DEBUG) The log level at which log message are pushed to STDOUT
STREAM_LOG_LEVEL = WARNING
# FILE_LOG_LEVEL (required):
FILE_LOG_LEVEL = WARNING
# LOG_FILE_FOLDER_PATH (optional, absolute path): Leave LOG_FILE_FOLDER_PATH blank to use the default pathing. Otherwise,
#    fill value with an ABSOLUTE to the folder where log will be kept
LOG_FILE_FOLDER_PATH =


[TESTING]
# DEFAULT_TEST_FILE (required, file name): Must reside in: DIBS/tests/test_data  TODO: low: elaborate
DEFAULT_PIPELINE_PRIME_CSV_TEST_FILE = TruncatedSample_Video1DLC_resnet50_EPM_DLC_BSAug25shuffle1_495000.csv
# DEFAULT_H5_TEST_FILE (optional, file name): must reside in DIBS/tests/test_data  TODO: low: elaborate
DEFAULT_H5_TEST_FILE = RowsDeleted_FullSample_Video1DLC_resnet50_EPM_DLC_BSOIDAug25shuffle1_495000.h5
# max_rows_to_read_in_from_csv (optional, int): change this value to set the maximum  # TODO: deprecate since old and new way of reading max lines is different?
MAX_ROWS_TO_READ_IN_FROM_CSV = 100_000_000_000


[VIDEO]
DEFAULT_FONT_SCALE = 1
DEFAULT_TEXT_BGR = (255, 255, 255)
DEFAULT_TEXT_BACKGROUND_BGR = (0, 0, 0)


[LEGACY]
# COMPILE_CSVS_FOR_TRAINING (required, int):  COMP=0 is one classifier/CSV file; COMP=1 is one classifier for all CSV files
COMPILE_CSVS_FOR_TRAINING = 1

########################################################################################################################
### Classifier parameters ###

[EM/GMM]
# n_components (required, int): n clusters (set to 30 after debugging)  TODO: med: re-read paper and find optimal n_components
n_components = 16
# covariance_type: # Must be one of: {full, tied, diag, spherical} (see the following link for more information: https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_covariances.html)
covariance_type = full
# tol (: (set to 0.001 after debugging)  TODO: Elaborate
tol = 0.001
# reg_covar: (set to 1e-06 after debugging)
reg_covar = 1e-06
# init_params (required, str): Initialization parameters. Must be one of {random, kmeans}
init_params = kmeans
# max_iter (required, int): TODO: Elaborate
max_iter = 100
# n_init (required, int): TODO: elaborate
n_init = 20
# verbose (required, int): Enable verbose output. If 1 then it prints the current initialization and each iteration step. If greater than 1 then it prints also the log probability and the time needed for each step.
verbose = 0
# verbose_interval (optional, int): How often the verbose output goes to stdout
verbose_interval = 50

[HDBSCAN]
# min_samples (required, int): (authors' note: small number)
min_samples = 10


[MLP]
# activation (required, str): logistics appears to outperform tanh and relu
activation = logistic
# hidden_layer_size (required, tuple of integers): **IMPORTANT NOTE**: hidden_layer_sizes is a
#   special variable that is evaluated exactly as it is written. Thus, if it is
#   written as '(100, 10)' (without the single quotes), it will be interpreted as a tuple of integers.
hidden_layer_sizes = (100, 10)
# solver (required, str):
solver = adam
# learning_rate (required, str):
learning_rate = constant
# learning_rate_init (required, float):
learning_rate_init = 0.001
# alpha (required, float): (Original note: regularization default is better than higher values.)
alpha = 0.0001
# max_iter: (original value is 1000)
max_iter = 100
# early_stopping (required, bool):
early_stopping = False
# verbose (required, int): set verbose=1 for tuning feedforward neural network
verbose = 0

[RANDOMFOREST]
# n_estimators (required, int): TODO: elaborate
n_estimators = 100


[SVM]
# C (required, float):
C = 10
# gamma (required, float):
gamma = 0.5
# probability (required, bool):
probability = True
# verbose (required, int): (Change back to 0 when done debugging)
verbose = 0
# n_jobs (required, int): Number of cores to use in training model.
#    n_jobs = -1 means all cores being used, set to -2 for all cores but one.
n_jobs = -2


[UMAP]
# n_neighbors (required, int): TODO: explain
n_neighbors = 100
# n_components (required, int): TODO: explain
n_components = 3
# min_dist: small value
min_dist = 0.0


[TSNE]
# early_exaggeration (required, float):
early_exaggeration = 16
# init (required, str): Initialization of embedding. "PCA initialization ... is usually more globally stable than random initialization.". Must one of the following: { random, pca }
init = pca
# n_components (required, int): (another author's note: 3 is good, 2 will not create unique pockets, 4 will screw GMM up (curse of dimensionality))
n_components = 3
# n_iter (required, int): 250 is the minimum value...previous n_iter was set to 1,000
n_iter = 1_000
# n_jobs: n_jobs=-1: all cores being used, set to -2 for all cores but one.
n_jobs = -2
# perplexity (optional, float): t-SNE perplexity value. If a value is not set, then the default is
perplexity = 15
# theta (float, required):
theta = 0.5
# verbose (required, int): (original note: verbose=2 shows check points)
verbose = 0










