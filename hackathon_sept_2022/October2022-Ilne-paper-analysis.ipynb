{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT: Comparing ML model (built in or same as Simba) interaction times to gold standard holdout set and stopwatch human data\n",
    "\n",
    "NOTE: \"score\" will refer to binary f1, precision, and/or recall.  Relative to the target class, \"Interaction\".\n",
    "\n",
    "Goal:  \n",
    "- Build a classifier based on the same procedure as Simba.  \n",
    "- Score via per-video cross validation during training, to estimate the generalization accuracy for unseen videos.\n",
    "- Score at each step of processing:\n",
    "    - Building the classifier\n",
    "    - min_bought_duratin post processing\n",
    "    - Kleinburg Filtering post processing\n",
    "- Compare to stop watched labelled human data.\n",
    "- Analyze the distribution of errors relative to each individual object, each treatment class, and each rat.\n",
    "    - Ideally the errors will have no bias and be zero mean Guassian across each categorical split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import glob\n",
    "import os\n",
    "import functools\n",
    "\n",
    "## Dataset class to encapsulate opening files and creating cv_indexes required for running cross_validation in sklearn\n",
    "## on a per video basis.  We will also encapsulate handling individual Dataframes per video vs. one large Dataframe\n",
    "## with all the videos.  The large Dataframe\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "PartialResults = namedtuple(\n",
    "    'PartialResults',\n",
    "    'precision recall f1 c_mat')\n",
    "# TODO: FullResults appears to be unused!\n",
    "FullResults = namedtuple(\n",
    "    'FullResults',\n",
    "    'model test_results train_results total_time')\n",
    "\n",
    "def build_partial_result(y_true, y_pred):\n",
    "    try:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    except:\n",
    "        # must be multi class\n",
    "        classes = sorted(x for x in numpy.unique(y_true) if x != 0) # Exclude the majority class\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=classes, average='weighted')\n",
    "    # precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    c_mat = confusion_matrix(y_true, y_pred)\n",
    "    return PartialResults(precision, recall, f1, c_mat)\n",
    "\n",
    "class ModelResultLabels(object):\n",
    "    \"\"\" Another data class for holding results \"\"\"\n",
    "    def __init__(self, func, y_binary, y_multi, y_prob, binary_results, multi_label_results):\n",
    "        self._func = func # just in case, will use name for printing\n",
    "        self.y_binary = y_binary\n",
    "        self.y_multi = y_multi\n",
    "        self.y_prob = y_prob # Probability will always be relative to the binary labels.\n",
    "        self.binary_results: PartialResults = binary_results\n",
    "        self.multi_label_results: PartialResults = multi_label_results\n",
    "\n",
    "class PerVideoDataClass(object):\n",
    "    \"\"\" The Dataset class will aggregate 1 instance of this class for each video it manages. \"\"\"\n",
    "    def __init__(self, file_path, df, x_extractor, y_binary_label_extractor, y_multi_label_extractor):\n",
    "        self.file_path = file_path # just in case\n",
    "        self.video_name = os.path.splitext(os.path.basename(file_path))[0] # the video name contains meta data about animal and treatment group etc.\n",
    "        if video_name_map is not None:\n",
    "            if self.video_name in video_name_map:\n",
    "                self.video_name = video_name_map[self.video_name]\n",
    "            elif self.video_name not in video_name_map.values():\n",
    "                msg = f'WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): {self.video_name}'\n",
    "                print(msg)\n",
    "                # raise RuntimeError(msg)\n",
    "        # self.video_metadata = VideoMetadata.from_name(self.video_name)\n",
    "        self.video_metadata = None # TODO: Put the meta-data on the per video class??\n",
    "        self.X = x_extractor(df)\n",
    "        self.y_binary = y_binary_label_extractor(df) # The test labels.\n",
    "        self.y_multi = y_multi_label_extractor(df, self.y_binary)\n",
    "        self._y_multi_label_extractor = functools.partial(y_multi_label_extractor, df) # need for later, the rest can go.\n",
    "        from collections import OrderedDict, defaultdict\n",
    "        # Dictionary with keys being classifier descriptions (tuples, or other hashable types that describe your classifier),\n",
    "        # and values being ordered dictionaries.\n",
    "        self.model_result_labels = defaultdict(OrderedDict)\n",
    "    \n",
    "    def apply_and_record_postprocessing_step(self, classifier_desc, func, y_binary, y_prob=None):\n",
    "        \"\"\" Func was used to produce y_binary, we record the results for analysis later. \"\"\"\n",
    "\n",
    "        assert y_binary.shape == self.y_binary.shape, \\\n",
    "            f'Model y_binary.shape: {y_binary.shape}; Golden y_binary.shape: {self.y_binary.shape}'\n",
    "\n",
    "        if isinstance(func, str):\n",
    "            # Kinda hacky, oh well\n",
    "            step_key = func\n",
    "        elif callable(func):\n",
    "            step_key = func.__name__\n",
    "        else:\n",
    "            step_key = func.__class__.__name__\n",
    "        y_multi = self._y_multi_label_extractor(y_binary)\n",
    "        self.model_result_labels[classifier_desc][step_key] = ModelResultLabels(\n",
    "            func, y_binary, y_multi, y_prob, \n",
    "            build_partial_result(self.y_binary, y_binary),\n",
    "            build_partial_result(self.y_multi, y_multi))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'''\n",
    "        Video name: {self.video_name}\n",
    "        Results stored: {self.model_result_labels.keys()}\n",
    "        '''\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, per_video_data_classes):\n",
    "        self.per_video_data_classes = per_video_data_classes\n",
    "\n",
    "    @classmethod\n",
    "    def from_scratch(cls, input_files, x_extractor, y_binary_label_extractor, y_multi_label_extractor):\n",
    "        # assert isinstance(input_files, list)\n",
    "        dfs = [pd.read_csv(f, index_col=0) for f in input_files]\n",
    "        # self._original_dfs = dfs # Just in case\n",
    "        per_video_data_classes = [\n",
    "            PerVideoDataClass(\n",
    "                file_path,\n",
    "                df, \n",
    "                x_extractor=x_extractor,\n",
    "                y_binary_label_extractor=y_binary_label_extractor,\n",
    "                y_multi_label_extractor=y_multi_label_extractor)\n",
    "            for file_path, df in zip(input_files, dfs)\n",
    "        ]\n",
    "        return cls(per_video_data_classes)\n",
    "\n",
    "    @property\n",
    "    def data_files(self):\n",
    "        return [per_video_data.file_path for per_video_data in self.per_video_data_classes]\n",
    "\n",
    "    def __str__(self):\n",
    "        files_str = '\\n\\t'.join(self.data_files)\n",
    "        paths_str = f'Data files: {files_str}'\n",
    "        return f'{self.__class__.__name__}:\\n' \\\n",
    "               f'Number of files: {len(self.data_files)}\\n' \\\n",
    "               f'Paths: {paths_str}'\n",
    "\n",
    "## Pre Processing:\n",
    "## All we need to do is select the desired input features, and the target columns\n",
    "\n",
    "## Define specific extraction methods.\n",
    "def build_Y_get_interaction(col='Interaction'):\n",
    "    \"\"\" For the objects datasets \"\"\"\n",
    "    def Y_get_interaction(df: pd.DataFrame):\n",
    "        ys = df[col]\n",
    "        ys = ys.fillna(value=0.0)\n",
    "        return ys.values\n",
    "    return Y_get_interaction\n",
    "\n",
    "\n",
    "def build_Y_get_multi_label(distance_features):\n",
    "    def Y_get_multi_label(df, ys_binary):\n",
    "        # +1 Because column_0 ==>  Object_1\n",
    "        nearest_obj = df[distance_features].values.argmin(axis=1) + 1\n",
    "        return nearest_obj * ys_binary\n",
    "    return Y_get_multi_label\n",
    "\n",
    "# x extractors\n",
    "def build_X_extractor(input_features):\n",
    "    def X_extractor(df):\n",
    "        # input_features should be a set of columns known to be in the Dataframe.\n",
    "        return df[input_features]\n",
    "    return X_extractor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load video name map into global env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Waiting on video_name_map from Tim/Ilne\n",
    "video_almost_map = pd.read_csv(os.path.join('hackathon', 'OBJ-novelposition.csv'))\n",
    "video_almost_map['gold_video_name'].fillna(video_almost_map['video_name'], inplace=True)\n",
    "\n",
    "video_name_map = {\n",
    "    new_video_name:old_video_name for new_video_name,old_video_name in \n",
    "    zip(video_almost_map['gold_video_name'], video_almost_map['video_name'])\n",
    "}\n",
    "#video_name_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI_features: ['Stimulus 1 Animal_1 distance', 'Stimulus 2 Animal_1 distance', 'Stimulus 3 Animal_1 distance', 'Stimulus 4 Animal_1 distance', 'Stimulus 5 Animal_1 distance', 'Stimulus 6 Animal_1 distance']\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08092021_DOT_Rat9_10(2)\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08102021_DOT_Rat7_8(2)\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08102021_IOT_Rat3_4(2)\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-11_NOD_DOT_11\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-11_NOD_DOT_9\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-11_NOD_IOT_12\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-12_NOD_IOT_14\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-12_NOD_IOT_18\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-18_NOD_IOT_18-upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08092021_DOT_Rat9_10(2)\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08102021_DOT_Rat7_8(2)\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-26_NOB_IOT_5 (2)\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03152021_NOD_IOT_3\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03162021_NOD_DOT_3_upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03162021_NOD_DOT_9_upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08092021_NOD_IOT_11\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08102021_IOT_Rat3_4(2)\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08112021_NOD_IOT_Rat12\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08122021_NOD_DOT_Rat5\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-11_NOD_DOT_11\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-11_NOD_DOT_7_WC\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-11_NOD_DOT_9\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-11_NOD_IOT_12\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-12_NOD_IOT_14\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-12_NOD_IOT_18\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-15_NOD_IOT_13\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-15_NOD_IOT_15\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-18_NOD_IOT_18-upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-21_NOD_IOT_13\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 2022-06-26_NOD_IOT_7\n",
      "Training Dataset: ['hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08092021_DOT_Rat3_4.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08092021_DOT_Rat5_6.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08092021_DOT_Rat9_10(2).csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08092021_DOT_Rat9_10.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08092021_IOT_Rat11_12.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08102021_DOT_Rat11_12.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08102021_DOT_Rat7_8(2).csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08102021_IOT_Rat3_4(2).csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08102021_IOT_Rat3_4.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08112021_IOT_Rat1_2.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08_11_2021_DOT_Rat7_8.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08_12_2021_IOT_Rat3_4.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08_13_2021_DOT_Rat9_10.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\08_14_2021_DOT_Rat7_8.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-11_NOD_DOT_11.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-11_NOD_DOT_9.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-11_NOD_IOT_12.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-12_NOD_IOT_14.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-12_NOD_IOT_18.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-18_NOD_IOT_18-upsidedown.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-20_NOB_DOT_4.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-21_NOB_DOT_22.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-21_NOB_IOT_23.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-24_NOB_IOT_22.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-26_NOB_DOT_4.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-26_NOB_IOT_1.csv', 'hackathon\\\\Iteration_2_withROI\\\\targets_inserted\\\\2022-06-26_NOB_IOT_5.csv']\n",
      "Holdout Dataset: ['hackathon\\\\hold_final\\\\object\\\\03142021_NOB_DOT_5_upsidedown.csv', 'hackathon\\\\hold_final\\\\object\\\\03142021_NOB_IOT_7_upsidedown.csv', 'hackathon\\\\hold_final\\\\object\\\\03152021_NOB_IOT_8.csv', 'hackathon\\\\hold_final\\\\object\\\\08092021_DOT_Rat9_10(2).csv', 'hackathon\\\\hold_final\\\\object\\\\08092021_NOB_DOT_Rat10.csv', 'hackathon\\\\hold_final\\\\object\\\\08102021_DOT_Rat11_12.csv', 'hackathon\\\\hold_final\\\\object\\\\08102021_DOT_Rat7_8(2).csv', 'hackathon\\\\hold_final\\\\object\\\\08112021_NOB_DOT_Rat7.csv', 'hackathon\\\\hold_final\\\\object\\\\08122021_NOB_IOT_Rat4.csv', 'hackathon\\\\hold_final\\\\object\\\\08132021_NOB_IOT_8.csv', 'hackathon\\\\hold_final\\\\object\\\\08142021_NOB_DOT_Rat11.csv', 'hackathon\\\\hold_final\\\\object\\\\08142021_NOB_IOT_Rat5.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-11_NOB_IOT_2(upsidedown)_WC.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-17_NOB_IOT_4.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-20_NOB_DOT_4.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-20_NOB_IOT_1.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-20_NOB_IOT_3.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-21_NOB_DOT_22.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-21_NOB_DOT_24.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-21_NOB_IOT_23.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-23_NOB_DOT_1.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-24_NOB_IOT_22.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-24_NOB_IOT_24.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-26_NOB_DOT_2.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-26_NOB_DOT_4.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-26_NOB_IOT_1.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-26_NOB_IOT_5 (2).csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-26_NOB_IOT_5.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-27_NOB_DOT_20.csv', 'hackathon\\\\hold_final\\\\object\\\\2022-06-27_NOB_IOT_21.csv', 'hackathon\\\\hold_final\\\\odour\\\\03152021_NOD_IOT_3.csv', 'hackathon\\\\hold_final\\\\odour\\\\03162021_NOD_DOT_3_upsidedown.csv', 'hackathon\\\\hold_final\\\\odour\\\\03162021_NOD_DOT_9_upsidedown.csv', 'hackathon\\\\hold_final\\\\odour\\\\08092021_DOT_Rat3_4.csv', 'hackathon\\\\hold_final\\\\odour\\\\08092021_DOT_Rat5_6.csv', 'hackathon\\\\hold_final\\\\odour\\\\08092021_DOT_Rat9_10.csv', 'hackathon\\\\hold_final\\\\odour\\\\08092021_IOT_Rat11_12.csv', 'hackathon\\\\hold_final\\\\odour\\\\08092021_NOD_IOT_11.csv', 'hackathon\\\\hold_final\\\\odour\\\\08102021_DOT_Rat7_8.csv', 'hackathon\\\\hold_final\\\\odour\\\\08102021_IOT_Rat3_4(2).csv', 'hackathon\\\\hold_final\\\\odour\\\\08112021_NOD_IOT_Rat12.csv', 'hackathon\\\\hold_final\\\\odour\\\\08122021_NOD_DOT_Rat5.csv', 'hackathon\\\\hold_final\\\\odour\\\\08_11_2021_DOT_Rat7_8.csv', 'hackathon\\\\hold_final\\\\odour\\\\08_12_2021_IOT_Rat3_4.csv', 'hackathon\\\\hold_final\\\\odour\\\\08_13_2021_DOT_Rat9_10.csv', 'hackathon\\\\hold_final\\\\odour\\\\08_14_2021_DOT_Rat7_8.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-11_NOD_DOT_11.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-11_NOD_DOT_7_WC.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-11_NOD_DOT_9.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-11_NOD_IOT_12.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-12_NOD_IOT_14.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-12_NOD_IOT_18.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-15_NOD_IOT_13.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-15_NOD_IOT_15.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-18_NOD_IOT_18-upsidedown.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-21_NOD_IOT_13.csv', 'hackathon\\\\hold_final\\\\odour\\\\2022-06-26_NOD_IOT_7.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interaction_features = [\n",
    "    'Interaction',\n",
    "    'Probability_Interaction'\n",
    "]\n",
    "\n",
    "raw_dlc_features_only = [\n",
    "    \"Ear_left_p\",\n",
    "    \"Ear_left_x\",\n",
    "    \"Ear_left_y\",\n",
    "\n",
    "    \"Ear_right_p\",\n",
    "    \"Ear_right_x\",\n",
    "    \"Ear_right_y\",\n",
    "\n",
    "    \"Lat_left_p\",\n",
    "    \"Lat_left_x\",\n",
    "    \"Lat_left_y\",\n",
    "\n",
    "    \"Lat_right_p\",\n",
    "    \"Lat_right_x\",\n",
    "    \"Lat_right_y\",\n",
    "\n",
    "    \"Center_p\",\n",
    "    \"Center_x\",\n",
    "    \"Center_y\",\n",
    "\n",
    "    \"Nose_p\",\n",
    "    \"Nose_x\",\n",
    "    \"Nose_y\",\n",
    "\n",
    "    \"Tail_base_p\",\n",
    "    \"Tail_base_x\",\n",
    "    \"Tail_base_y\",\n",
    "\n",
    "    \"Tail_end_x\",\n",
    "    \"Tail_end_y\",\n",
    "    \"Tail_end_p\",\n",
    "]\n",
    "\n",
    "## Load the data.  Pre engineered features created in Simba with Region of Interest (ROI) data included.\n",
    "## ROI data is centered on each of 6 objects of interest.\n",
    "training_simba_csv_files = glob.glob(\n",
    "    os.path.join('hackathon', 'Iteration_2_withROI', 'targets_inserted', '*.csv'))\n",
    "holdout_simba_csv_files = glob.glob(\n",
    "    os.path.join('hackathon', 'hold_final', '*', '*.csv'))\n",
    "    # os.path.join('hackathon', 'Iteration_2_withROI', 'hold_dataset', '*.csv'))\n",
    "\n",
    "# # TEMP: Only 1 each for now while coding\n",
    "# training_simba_csv_files = training_simba_csv_files[0:2]\n",
    "# holdout_simba_csv_files = holdout_simba_csv_files[0:2]\n",
    "\n",
    "# temporary Dataframe so we can read the columns.\n",
    "temp_df = pd.read_csv(training_simba_csv_files[0], index_col=0)\n",
    "temp_df_cols = set(temp_df.columns)\n",
    "# The following cols are not in new dfs, we will drop them\n",
    "cols_to_drop = ['Stimulus 6 Animal_1 in zone_cumulative_percent', 'Stimulus 1 Animal_1 in zone_cumulative_percent', 'Stimulus 2 Animal_1 in zone_cumulative_percent', 'Stimulus 3 Animal_1 in zone_cumulative_time', 'Stimulus 5 Animal_1 in zone_cumulative_percent', 'Stimulus 6 Animal_1 in zone_cumulative_time', 'Stimulus 3 Animal_1 in zone_cumulative_percent', 'Stimulus 1 Animal_1 in zone_cumulative_time', 'Stimulus 5 Animal_1 in zone_cumulative_time', 'Stimulus 2 Animal_1 in zone_cumulative_time', 'Stimulus 4 Animal_1 in zone_cumulative_percent', 'Stimulus 4 Animal_1 in zone_cumulative_time']\n",
    "\n",
    "# for csv_file in training_simba_csv_files + holdout_simba_csv_files:\n",
    "#     cur_df = pd.read_csv(csv_file, nrows=2, index_col=0)\n",
    "#     cur_df_cols = set(cur_df.columns)\n",
    "#     sym_diff = cur_df_cols.symmetric_difference(temp_df_cols)\n",
    "#     if sym_diff:\n",
    "#         print(f'Found differences in cols for {csv_file}')\n",
    "#         print(f'Cols in temp_df but not curr: {sym_diff - cur_df_cols}')\n",
    "#         print(f'Cols in curr_df but not temp: {sym_diff - temp_df_cols}')\n",
    "#         raise RuntimeError('Not happy with columns')\n",
    "\n",
    "exclude_columns = interaction_features + raw_dlc_features_only + cols_to_drop\n",
    "input_features = [col for col in temp_df.columns if col not in exclude_columns]\n",
    "x_extractor = build_X_extractor(input_features)\n",
    "y_binary_label_extractor = build_Y_get_interaction(col='Interaction')\n",
    "\n",
    "import re\n",
    "distance_re = re.compile(r'^Stimulus [0-9] Animal_[0-9]+ distance$')\n",
    "# \n",
    "distance_features = [col for col in temp_df.columns if distance_re.match(col)]\n",
    "print('ROI_features:', distance_features)\n",
    "y_multi_label_extractor = build_Y_get_multi_label(distance_features)\n",
    "\n",
    "# def apply_and_record_postprocessing_step(self, func, y_binary): # Don't forget to use this later\n",
    "\n",
    "training_dataset = Dataset.from_scratch(training_simba_csv_files, x_extractor, y_binary_label_extractor, y_multi_label_extractor)\n",
    "# We don't make cv indexes for the holdout set because we will only be using this to verify\n",
    "# model performance on unseen videos.\n",
    "holdout_dataset = Dataset.from_scratch(holdout_simba_csv_files, x_extractor, y_binary_label_extractor, y_multi_label_extractor)\n",
    "print(f'Training Dataset: {training_dataset.data_files}')\n",
    "print(f'Holdout Dataset: {holdout_dataset.data_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03142021_NOB_DOT_9_upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03142021_NOB_IOT_1_upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03152021_NOB_IOT_10\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03152021_NOB_IOT_12\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03192021_NOB_IOT_5_upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 03192021_NOB_IOT_6_upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 04032021_NOB_IOT_9_upsidedown\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08092021_NOB_IOT_Rat2\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08102021_NOB_IOT_5\n",
      "WARNING: Found a video name that is not in the video_name_map!!! (should be either a new name, or an old name with a mapped name): 08142021_NOB_IOT_Rat9\n",
      "['hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03142021_NOB_DOT_3_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03142021_NOB_DOT_5_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03142021_NOB_DOT_9_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03142021_NOB_IOT_11_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03142021_NOB_IOT_1_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03142021_NOB_IOT_7_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03152021_NOB_DOT_2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03152021_NOB_IOT_10.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03152021_NOB_IOT_12.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03152021_NOB_IOT_6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03152021_NOB_IOT_8.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03162021_NOB_DOT_10_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03162021_NOB_DOT_4_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03162021_NOB_DOT_8_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03162021_NOB_IOT_12_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03162021_NOB_IOT_2_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03162021_NOB_IOT_6_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03172021_NOB_DOT_1_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03172021_NOB_DOT_5_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03172021_NOB_IOT_11_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03172021_NOB_IOT_3_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03172021_NOB_IOT_7_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03182021_NOB_DOT_1_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03182021_NOB_DOT_5_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03182021_NOB_DOT_9_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03182021_NOB_IOT_11_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03182021_NOB_IOT_3_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03182021_NOB_IOT_7_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03192021_NOB_DOT_12_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03192021_NOB_DOT_8_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03192021_NOB_IOT_10_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03192021_NOB_IOT_2_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03192021_NOB_IOT_5_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03192021_NOB_IOT_6_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\03192021_NOB__DOT_4_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\04032021_NOB_IOT_9_upsidedown.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08092021_NOB_DOT_Rat10.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08092021_NOB_DOT_Rat4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08092021_NOB_DOT_Rat6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08092021_NOB_IOT_12.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08092021_NOB_IOT_Rat2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08092021_NOB_IOT_Rat8.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08102021_NOB_DOT_11.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08102021_NOB_DOT_2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08102021_NOB_DOT_7.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08102021_NOB_IOT_5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08102021_NOB_IOT_Rat3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08102021_NOB_IOT_Rat9.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08112021_NOB_DOT_Rat3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08112021_NOB_DOT_Rat7.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08112021_NOB_DOT_Rat9.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08112021_NOB_IOT_Rat1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08112021_NOB_IOT_Rat11.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08112021_NOB_IOT_Rat5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08122021_NOB_DOT_Rat1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08122021_NOB_DOT_Rat10.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08122021_NOB_DOT_Rat6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08122021_NOB_IOT_Rat12.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08122021_NOB_IOT_Rat4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08122021_NOB_IOT_Rat8.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08132021_NOB_DOT_Rat10.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08132021_NOB_DOT_Rat2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08132021_NOB_DOT_Rat6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08132021_NOB_IOT_12.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08132021_NOB_IOT_8.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08132021_NOB_IOT_Rat4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08142021_NOB_DOT_Rat11.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08142021_NOB_DOT_Rat3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08142021_NOB_DOT_Rat7.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08142021_NOB_IOT_Rat1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08142021_NOB_IOT_Rat5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\08142021_NOB_IOT_Rat9.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-11_NOB_DOT_1(upsidedown)_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-11_NOB_DOT_3(upsidedown)_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-11_NOB_DOT_5_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-11_NOB_IOT_2(upsidedown)_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-11_NOB_IOT_4_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-11_NOB_IOT_6_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-12_NOB_DOT_19_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-12_NOB_DOT_21_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-12_NOB_DOT_23_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-12_NOB_IOT_20_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-12_NOB_IOT_22_WC.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-12_NOB_IOT_24.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-14_NOB_DOT_2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-14_NOB_DOT_4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-14_NOB_DOT_6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-14_NOB_IOT_1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-14_NOB_IOT_3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-14_NOB_IOT_5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-15_NOB_DOT_20.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-15_NOB_DOT_22.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-15_NOB_DOT_24.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-15_NOB_IOT_19.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-15_NOB_IOT_21.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-15_NOB_IOT_23.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-17_NOB_DOT_1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-17_NOB_DOT_3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-17_NOB_DOT_5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-17_NOB_IOT_2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-17_NOB_IOT_4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-17_NOB_IOT_6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-18_NOB_DOT_19.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-18_NOB_DOT_21.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-18_NOB_DOT_23.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-18_NOB_IOT_20.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-18_NOB_IOT_22.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-18_NOB_IOT_24.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-20_NOB_DOT_2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-20_NOB_DOT_4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-20_NOB_DOT_6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-20_NOB_IOT_1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-20_NOB_IOT_3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-20_NOB_IOT_5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-21_NOB_DOT_20.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-21_NOB_DOT_22.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-21_NOB_DOT_24.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-21_NOB_IOT_19.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-21_NOB_IOT_21.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-21_NOB_IOT_23.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-23_NOB_DOT_1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-23_NOB_DOT_3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-23_NOB_DOT_5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-23_NOB_IOT_2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-23_NOB_IOT_4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-23_NOB_IOT_6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-24_NOB_DOT_19.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-24_NOB_DOT_21.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-24_NOB_DOT_23.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-24_NOB_IOT_20.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-24_NOB_IOT_22.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-24_NOB_IOT_24.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-26_NOB_DOT_2.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-26_NOB_DOT_4.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-26_NOB_DOT_6.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-26_NOB_IOT_1.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-26_NOB_IOT_3.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-26_NOB_IOT_5.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-27_NOB_DOT_20.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-27_NOB_DOT_22.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-27_NOB_DOT_24.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-27_NOB_IOT_19.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-27_NOB_IOT_21.csv', 'hackathon\\\\Iteration_3_withSimbaModelLabels\\\\machine_results_object\\\\2022-06-27_NOB_IOT_23.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iteration_3_csv_files = glob.glob(\n",
    "    os.path.join('hackathon', 'Iteration_3_withSimbaModelLabels', 'machine_results_object', '*'))\n",
    "simba_prelabeled_dataset = Dataset.from_scratch(iteration_3_csv_files, x_extractor, y_binary_label_extractor, y_multi_label_extractor)\n",
    "print(simba_prelabeled_dataset.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.replace('\\\\', '/') for x in holdout_dataset.data_files] + [x.replace('\\\\', '/') for x in training_dataset.data_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Video Metadata and split by Odour/Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Rat ID Stimuli Type Task Variation  Novel ID\n",
      "File Name                                                           \n",
      "08_11_2021_DOT_Rat7_8        7        Odour            DOT       NaN\n",
      "08_12_2021_IOT_Rat3_4        3        Odour            IOT       NaN\n",
      "08_13_2021_DOT_Rat9_10       9        Odour            DOT       NaN\n",
      "08_14_2021_DOT_Rat7_8        8        Odour            DOT       NaN\n",
      "2022-06-11_NOD_DOT_9         9        Odour            DOT       NaN\n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_DOT_Rat4\n",
      "        Rat ID: Rat4\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_DOT_Rat6\n",
      "        Rat ID: Rat6\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_DOT_Rat10\n",
      "        Rat ID: Rat10\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_IOT_12\n",
      "        Rat ID: 12\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08102021_NOB_DOT_11\n",
      "        Rat ID: 11\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08102021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08102021_NOB_IOT_Rat3\n",
      "        Rat ID: Rat3\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08102021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08112021_NOB_IOT_Rat1\n",
      "        Rat ID: Rat1\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08112021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08112021_NOB_DOT_Rat7\n",
      "        Rat ID: Rat7\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08112021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08122021_NOB_IOT_Rat4\n",
      "        Rat ID: Rat4\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08122021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08132021_NOB_DOT_Rat10\n",
      "        Rat ID: Rat10\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08132021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08142021_NOB_DOT_Rat7\n",
      "        Rat ID: Rat7\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08142021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-26_NOB_IOT_5\n",
      "        Rat ID: 5\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-26\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 03142021_NOB_DOT_5_upsidedown\n",
      "        Rat ID: 5\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 03142021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 03142021_NOB_IOT_7_upsidedown\n",
      "        Rat ID: 7\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 03142021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 03152021_NOB_IOT_8\n",
      "        Rat ID: 8\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 03152021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_DOT_Rat10\n",
      "        Rat ID: Rat10\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08102021_NOB_DOT_11\n",
      "        Rat ID: 11\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08102021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08112021_NOB_DOT_Rat7\n",
      "        Rat ID: Rat7\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08112021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08122021_NOB_IOT_Rat4\n",
      "        Rat ID: Rat4\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08122021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08132021_NOB_IOT_8\n",
      "        Rat ID: 8\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08132021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08142021_NOB_DOT_Rat11\n",
      "        Rat ID: Rat11\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08142021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08142021_NOB_IOT_Rat5\n",
      "        Rat ID: Rat5\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08142021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-11_NOB_IOT_2(upsidedown)_WC\n",
      "        Rat ID: 2(upsidedown)\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-11\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-17_NOB_IOT_4\n",
      "        Rat ID: 4\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-17\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-20_NOB_IOT_1\n",
      "        Rat ID: 1\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-20\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-20_NOB_IOT_3\n",
      "        Rat ID: 3\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-20\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-21_NOB_DOT_24\n",
      "        Rat ID: 24\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-21\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-23_NOB_DOT_1\n",
      "        Rat ID: 1\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-23\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-24_NOB_IOT_24\n",
      "        Rat ID: 24\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-24\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-26_NOB_DOT_2\n",
      "        Rat ID: 2\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-26\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-26_NOB_IOT_5 (2)\n",
      "        Rat ID: 5 (2)\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-26\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-26_NOB_IOT_5\n",
      "        Rat ID: 5\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-26\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-27_NOB_DOT_20\n",
      "        Rat ID: 20\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-27\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-27_NOB_IOT_21\n",
      "        Rat ID: 21\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-27\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 03152021_NOD_IOT_3\n",
      "        Rat ID: 3\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 03152021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 03162021_NOD_DOT_3_upsidedown\n",
      "        Rat ID: 3\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 03162021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 03162021_NOD_DOT_9_upsidedown\n",
      "        Rat ID: 9\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 03162021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_DOT_Rat4\n",
      "        Rat ID: Rat4\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_DOT_Rat6\n",
      "        Rat ID: Rat6\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_DOT_Rat10\n",
      "        Rat ID: Rat10\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOB_IOT_12\n",
      "        Rat ID: 12\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08092021_NOD_IOT_11\n",
      "        Rat ID: 11\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08092021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08102021_NOB_DOT_7\n",
      "        Rat ID: 7\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08102021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08112021_NOD_IOT_Rat12\n",
      "        Rat ID: Rat12\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08112021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08122021_NOD_DOT_Rat5\n",
      "        Rat ID: Rat5\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08122021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08112021_NOB_DOT_Rat7\n",
      "        Rat ID: Rat7\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08112021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08122021_NOB_IOT_Rat4\n",
      "        Rat ID: Rat4\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08122021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08132021_NOB_DOT_Rat10\n",
      "        Rat ID: Rat10\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08132021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 08142021_NOB_DOT_Rat7\n",
      "        Rat ID: Rat7\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 08142021\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-11_NOD_DOT_7_WC\n",
      "        Rat ID: 7\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: DOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-11\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-15_NOD_IOT_13\n",
      "        Rat ID: 13\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-15\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-15_NOD_IOT_15\n",
      "        Rat ID: 15\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-15\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-21_NOD_IOT_13\n",
      "        Rat ID: 13\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-21\n",
      "        Extra (notes): None\n",
      "        \n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-26_NOD_IOT_7\n",
      "        Rat ID: 7\n",
      "        Stimuli Type: Odour\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-26\n",
      "        Extra (notes): None\n",
      "        \n",
      "Training object dataset: Dataset:\n",
      "Number of files: 20\n",
      "Paths: Data files: hackathon\\Iteration_2_withROI\\targets_inserted\\08092021_DOT_Rat3_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08092021_DOT_Rat5_6.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08092021_DOT_Rat9_10(2).csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08092021_DOT_Rat9_10.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08092021_IOT_Rat11_12.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08102021_DOT_Rat11_12.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08102021_DOT_Rat7_8(2).csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08102021_IOT_Rat3_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08112021_IOT_Rat1_2.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_11_2021_DOT_Rat7_8.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_12_2021_IOT_Rat3_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_13_2021_DOT_Rat9_10.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_14_2021_DOT_Rat7_8.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-20_NOB_DOT_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-21_NOB_DOT_22.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-21_NOB_IOT_23.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-24_NOB_IOT_22.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-26_NOB_DOT_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-26_NOB_IOT_1.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-26_NOB_IOT_5.csv\n",
      "Holdout object dataset: Dataset:\n",
      "Number of files: 39\n",
      "Paths: Data files: hackathon\\hold_final\\object\\03142021_NOB_DOT_5_upsidedown.csv\n",
      "\thackathon\\hold_final\\object\\03142021_NOB_IOT_7_upsidedown.csv\n",
      "\thackathon\\hold_final\\object\\03152021_NOB_IOT_8.csv\n",
      "\thackathon\\hold_final\\object\\08092021_DOT_Rat9_10(2).csv\n",
      "\thackathon\\hold_final\\object\\08092021_NOB_DOT_Rat10.csv\n",
      "\thackathon\\hold_final\\object\\08102021_DOT_Rat11_12.csv\n",
      "\thackathon\\hold_final\\object\\08102021_DOT_Rat7_8(2).csv\n",
      "\thackathon\\hold_final\\object\\08112021_NOB_DOT_Rat7.csv\n",
      "\thackathon\\hold_final\\object\\08122021_NOB_IOT_Rat4.csv\n",
      "\thackathon\\hold_final\\object\\08132021_NOB_IOT_8.csv\n",
      "\thackathon\\hold_final\\object\\08142021_NOB_DOT_Rat11.csv\n",
      "\thackathon\\hold_final\\object\\08142021_NOB_IOT_Rat5.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-11_NOB_IOT_2(upsidedown)_WC.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-17_NOB_IOT_4.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-20_NOB_DOT_4.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-20_NOB_IOT_1.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-20_NOB_IOT_3.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-21_NOB_DOT_22.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-21_NOB_DOT_24.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-21_NOB_IOT_23.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-23_NOB_DOT_1.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-24_NOB_IOT_22.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-24_NOB_IOT_24.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-26_NOB_DOT_2.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-26_NOB_DOT_4.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-26_NOB_IOT_1.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-26_NOB_IOT_5 (2).csv\n",
      "\thackathon\\hold_final\\object\\2022-06-26_NOB_IOT_5.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-27_NOB_DOT_20.csv\n",
      "\thackathon\\hold_final\\object\\2022-06-27_NOB_IOT_21.csv\n",
      "\thackathon\\hold_final\\odour\\08092021_DOT_Rat3_4.csv\n",
      "\thackathon\\hold_final\\odour\\08092021_DOT_Rat5_6.csv\n",
      "\thackathon\\hold_final\\odour\\08092021_DOT_Rat9_10.csv\n",
      "\thackathon\\hold_final\\odour\\08092021_IOT_Rat11_12.csv\n",
      "\thackathon\\hold_final\\odour\\08102021_DOT_Rat7_8.csv\n",
      "\thackathon\\hold_final\\odour\\08_11_2021_DOT_Rat7_8.csv\n",
      "\thackathon\\hold_final\\odour\\08_12_2021_IOT_Rat3_4.csv\n",
      "\thackathon\\hold_final\\odour\\08_13_2021_DOT_Rat9_10.csv\n",
      "\thackathon\\hold_final\\odour\\08_14_2021_DOT_Rat7_8.csv\n",
      "Training odour dataset: Dataset:\n",
      "Number of files: 7\n",
      "Paths: Data files: hackathon\\Iteration_2_withROI\\targets_inserted\\08102021_IOT_Rat3_4(2).csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-11_NOD_DOT_11.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-11_NOD_DOT_9.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-11_NOD_IOT_12.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-12_NOD_IOT_14.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-12_NOD_IOT_18.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-18_NOD_IOT_18-upsidedown.csv\n",
      "Holdout odour dataset: Dataset:\n",
      "Number of files: 18\n",
      "Paths: Data files: hackathon\\hold_final\\odour\\03152021_NOD_IOT_3.csv\n",
      "\thackathon\\hold_final\\odour\\03162021_NOD_DOT_3_upsidedown.csv\n",
      "\thackathon\\hold_final\\odour\\03162021_NOD_DOT_9_upsidedown.csv\n",
      "\thackathon\\hold_final\\odour\\08092021_NOD_IOT_11.csv\n",
      "\thackathon\\hold_final\\odour\\08102021_IOT_Rat3_4(2).csv\n",
      "\thackathon\\hold_final\\odour\\08112021_NOD_IOT_Rat12.csv\n",
      "\thackathon\\hold_final\\odour\\08122021_NOD_DOT_Rat5.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-11_NOD_DOT_11.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-11_NOD_DOT_7_WC.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-11_NOD_DOT_9.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-11_NOD_IOT_12.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-12_NOD_IOT_14.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-12_NOD_IOT_18.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-15_NOD_IOT_13.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-15_NOD_IOT_15.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-18_NOD_IOT_18-upsidedown.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-21_NOD_IOT_13.csv\n",
      "\thackathon\\hold_final\\odour\\2022-06-26_NOD_IOT_7.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Load the unlabeled set?\n",
    "# TODO: Load and record the video meta-data for each\n",
    "\n",
    "class VideoMetadata(object):\n",
    "    def __init__(self, video_name, *, rat_id, stimuli_type, task_variation, treatment, novel_id, date, extra):\n",
    "        # TODO: Video stub name? Or with extension? A path ever??\n",
    "        # 'phase' == 'task_variation'\n",
    "        self.video_name = video_name\n",
    "        self.rat_id = rat_id\n",
    "        self.stimuli_type = stimuli_type\n",
    "        self.task_variation = task_variation\n",
    "        self.treatment = treatment\n",
    "        self.novel_id = novel_id\n",
    "        self.date = date\n",
    "        self.extra = extra\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'''\n",
    "        Video Name: {self.video_name}\n",
    "        Rat ID: {self.rat_id}\n",
    "        Stimuli Type: {self.stimuli_type}\n",
    "        Task Variation: {self.task_variation}\n",
    "        Treatment: {self.treatment}\n",
    "        Novel ID: {self.novel_id}\n",
    "        Date (of recording): {self.date}\n",
    "        Extra (notes): {self.extra}\n",
    "        '''\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, video_name):\n",
    "        # ex: 2022-06-11_NOD_DOT_9\n",
    "        nod_nob_to_stimuli_type = {\n",
    "            'NOD': 'Odour',\n",
    "            'NOB': 'Object'\n",
    "        }\n",
    "        parts = video_name.split('_')\n",
    "        date, raw_NOD_NOB, task_variation, rat_id = [x.strip() for x in parts[:4]]\n",
    "        stimuli_type = nod_nob_to_stimuli_type[raw_NOD_NOB].strip() # If this errors out, name is malformed\n",
    "        # Treatment is unknown... unless we get a rat_id -> treatment mapping...\n",
    "        # Extra is not present from name alone...\n",
    "        # Don't know what novel id is from video name alone...\n",
    "        return cls(video_name, rat_id=rat_id, stimuli_type=stimuli_type,\n",
    "                    task_variation=task_variation, treatment=None, novel_id=None, date=date, extra=None)\n",
    "\n",
    "\n",
    "video_metadata_csv = os.path.join('hackathon', 'Iteration_2_withROI', 'trainingset_key.csv')\n",
    "## TODO: Does this key have metadata for all the videos? Training set? Holdout set?\n",
    "video_metadata_df = pd.read_csv(video_metadata_csv, index_col='File Name')\n",
    "print(video_metadata_df.head())\n",
    "\n",
    "def populate_video_metadata(dataset):\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        try:\n",
    "            row = video_metadata_df.loc[per_video_data.video_name]\n",
    "            rat_id = row['Rat ID']\n",
    "            stimuli_type = row['Stimuli Type'].strip()\n",
    "            assert stimuli_type in ['Object', 'Odour'], stimuli_type\n",
    "            task_variation = row['Task Variation']\n",
    "            novel_id = row['Novel ID']\n",
    "            per_video_data.video_metadata = VideoMetadata(\n",
    "                video_name=per_video_data.video_name,\n",
    "                rat_id=rat_id,\n",
    "                stimuli_type=stimuli_type,\n",
    "                novel_id=novel_id,\n",
    "                task_variation=task_variation,\n",
    "                treatment=None,\n",
    "                date=None,\n",
    "                extra=None\n",
    "                )\n",
    "\n",
    "        except KeyError:\n",
    "            video_metadata = VideoMetadata.from_name(per_video_data.video_name)\n",
    "            print('Generated from video name:', video_metadata)\n",
    "            per_video_data.video_metadata = video_metadata\n",
    "\n",
    "populate_video_metadata(training_dataset)\n",
    "populate_video_metadata(holdout_dataset)\n",
    "\n",
    "training_odour_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in training_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Odour'])\n",
    "training_object_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in training_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Object'])\n",
    "\n",
    "holdout_odour_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in holdout_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Odour'])\n",
    "holdout_object_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in holdout_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Object'])\n",
    "\n",
    "\n",
    "training_combined_dataset = training_dataset # Only required for training xgb combined\n",
    "# holdout_combined_dataset = holdout_dataset # Not required\n",
    "\n",
    "print(f'Training object dataset: {training_object_dataset}')\n",
    "print(f'Holdout object dataset: {holdout_object_dataset}')\n",
    "print(f'Training odour dataset: {training_odour_dataset}')\n",
    "print(f'Holdout odour dataset: {holdout_odour_dataset}')\n",
    "\n",
    "\n",
    "# del training_dataset\n",
    "# del holdout_dataset # LOL; Risky\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model\n",
    "Okay, data is loaded, features and labels extracted and stored in two Dataset objects.\n",
    "No we are ready to fit a model, and get some performance metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new XGBClassifier_odour model\n",
      "Fitting new xgb model...\n",
      "Sample weight applied to positive class: 3.7094734547040225\n",
      "Saving to hackathon\\temp_xgb_models\\XGBClassifier_odour.pkl\n",
      "Training new XGBClassifier_object model\n",
      "Fitting new xgb model...\n",
      "Sample weight applied to positive class: 4.23712540005819\n",
      "Saving to hackathon\\temp_xgb_models\\XGBClassifier_object.pkl\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "# From a previous GridSearchCV:\n",
    "# \n",
    "# Finished training model; best_score: 0.4699529225702816; \n",
    "# best_estimator: XGBClassifier(base_score=0.5, booster='gbtree', gamma=0.0,\n",
    "#               grow_policy='lossguide', interaction_constraints=None,\n",
    "#               learning_rate=0.3, max_delta_step=1, max_depth=4,\n",
    "#               min_child_weight=0, missing=None, n_estimators=300, n_jobs=14,\n",
    "#               nthread=None, num_parallel_tree=1, objective='binary:logistic',\n",
    "#               random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "#               sampling_method='gradient_based',\n",
    "#               scale_pos_weight=4.296046179280971, seed=None, silent=None,\n",
    "#               subsample=0.5, tree_method='gpu_hist', verbosity=1)\n",
    "# Best grid search params: {'gamma': 0.0, 'learning_rate': 0.3, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 300, 'scale_pos_weight': 4.296046179280971}\n",
    "#\n",
    "# NOTE: scale_pos_weight will be fit with a bit of a trick for xgboost, based on the frequency of labels\n",
    "#       in the input dataset.\n",
    "\n",
    "\n",
    "# 1. Get all training Xs and ys from the dataset.  Use proportion in ys to set scale_pos_weight\n",
    "\n",
    "def load_or_save(models_dir, train_new=False):\n",
    "    def inner(func):\n",
    "      def wrapper(dataset, classifier_desc):\n",
    "        maybe_path = os.path.join('hackathon', models_dir, classifier_desc + '.pkl')\n",
    "        if not train_new and maybe_path and os.path.isfile(maybe_path):\n",
    "          print(f'Loading model from: {maybe_path}')\n",
    "          with open(maybe_path, 'rb') as f:\n",
    "            clf = pickle.load(f)\n",
    "        else:\n",
    "          print(f'Training new {classifier_desc} model')\n",
    "          clf = func(dataset, classifier_desc)\n",
    "          if maybe_path is not False:\n",
    "            with open(maybe_path, 'wb') as clf_file:\n",
    "                print(f'Saving to {maybe_path}')\n",
    "                pickle.dump(clf, clf_file)\n",
    "        return clf\n",
    "      return wrapper\n",
    "    return inner\n",
    "\n",
    "@load_or_save('temp_xgb_models', train_new=True)\n",
    "def train_xgb(dataset: Dataset, classifier_desc):\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        Xs.append(per_video_data.X)\n",
    "        ys.append(per_video_data.y_binary) # use binary ys for training and predictions.\n",
    "\n",
    "    Xs = pd.concat(Xs)\n",
    "    # Xs = numpy.vstack(Xs)\n",
    "    ys = numpy.hstack(ys)\n",
    "    print('Fitting new xgb model...')\n",
    "    new_scale_pos_weights = (ys == 0).sum() / (ys >= 1).sum()\n",
    "    print('Sample weight applied to positive class:', new_scale_pos_weights)\n",
    "    xgb_clf = XGBClassifier(base_score=0.5, booster='gbtree', gamma=0.0,\n",
    "                  grow_policy='lossguide', learning_rate=0.3, max_delta_step=1, max_depth=4,\n",
    "                  min_child_weight=0, missing=0, n_estimators=300, n_jobs=14,\n",
    "                  objective='binary:logistic',\n",
    "                  # objective='binary:logitraw',\n",
    "                  tree_method='gpu_hist', sampling_method='gradient_based',\n",
    "                  random_state=42, \n",
    "                  scale_pos_weight=new_scale_pos_weights, seed=42, silent=None,\n",
    "                  subsample=0.5, \n",
    "                  verbosity=1)\n",
    "    xgb_clf.fit(Xs, ys)\n",
    "    xgb_clf._classifier_desc = classifier_desc\n",
    "    return xgb_clf\n",
    "\n",
    "@load_or_save('temp_RF_models', train_new=False)\n",
    "def train_RF(dataset: Dataset, classifier_desc):\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        Xs.append(per_video_data.X)\n",
    "        ys.append(per_video_data.y_binary) # use binary ys for training and predictions.\n",
    "\n",
    "    rf_clf = RandomForestClassifier(\n",
    "                  # n_estimators=200,\n",
    "                  n_estimators=2000,\n",
    "                  bootstrap=True,\n",
    "                  verbose=0, # 1 if you want to see jobs etc\n",
    "                  n_jobs=-1,\n",
    "                  criterion='entropy',  # Gini is standard, shouldn't be a huge factor\n",
    "                  min_samples_leaf=2,\n",
    "                  max_features='sqrt',\n",
    "                  # max_depth=15,  # LIMIT MAX DEPTH!!  Runtime AND generalization error should improve drastically\n",
    "                  random_state=42,\n",
    "                  #     ccp_alpha=0.005, # NEW PARAMETER, I NEED TO DEFINE MY EXPERIMENT SETUPS BETTER, AND STORE SOME RESULTS!!\n",
    "                  # Probably need to whip up a database again, that's the only way I have been able to navigate this in the past\n",
    "                  # Alternatively I could very carefully define my experiments, and then run them all in a batch and create a\n",
    "                  # meaningful report.  This is probably the best way to proceed.  It will lead to the most robust iteration\n",
    "                  # and progress.\n",
    "                  ## NEW: Turning this on rather than under/over sampling.\n",
    "                  class_weight='balanced',  # balance weights at nodes based on class frequencies\n",
    "                )\n",
    "    Xs = pd.concat(Xs)\n",
    "    # Xs = numpy.vstack(Xs)\n",
    "    ys = numpy.hstack(ys)\n",
    "    print('Fitting new RF model...')\n",
    "    rf_clf.fit(Xs, ys)\n",
    "    rf_clf._classifier_desc = classifier_desc\n",
    "    return rf_clf\n",
    "\n",
    "xgb_odour_clf = train_xgb(training_odour_dataset, 'XGBClassifier_odour')\n",
    "xgb_object_clf = train_xgb(training_object_dataset, 'XGBClassifier_object')\n",
    "# xgb_combined_clf = train_xgb(training_combined_dataset, 'XGBClassifier_combined')\n",
    "\n",
    "## NOTE: Using pre-computed labels now\n",
    "# rf_odour_clf = train_RF(training_odour_dataset, 'RFClassifier_odour')\n",
    "# rf_object_clf = train_RF(training_object_dataset, 'RFClassifier_object')\n",
    "# # rf_combined_clf = train_RF(training_combined_dataset, 'RFClassifier_combined')\n",
    "# simba_odour_clf = rf_odour_clf\n",
    "# simba_object_clf = rf_object_clf\n",
    "\n",
    "# If a path is provided we load a model file from disk, otherwise we fit a new one.\n",
    "# model_path = 'TEMP_DecisionTreeModel_for_notebook.pkl' # Put path to your model here\n",
    "## No longer loading simba models, out of date which causes errors.\n",
    "# object_simba_model_path = os.path.join('hackathon', 'Iteration_2_withROI', 'models', 'object', 'Interaction.sav')\n",
    "# odour_simba_model_path = os.path.join('hackathon', 'Iteration_2_withROI', 'models', 'odour', 'Interaction.sav')\n",
    "# if object_simba_model_path and os.path.isfile(object_simba_model_path):\n",
    "#   print(f'Loading model from: {object_simba_model_path}')\n",
    "#   with open(object_simba_model_path, 'rb') as f:\n",
    "#     simba_object_clf = pickle.load(f)\n",
    "# if odour_simba_model_path and os.path.isfile(odour_simba_model_path):\n",
    "#   print(f'Loading model from: {odour_simba_model_path}')\n",
    "#   with open(odour_simba_model_path, 'rb') as f:\n",
    "#     simba_odour_clf = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Results and Apply Post Processing\n",
    "Now we have a trained model.  We're going to define some post-processing functions that match what is provided in Simba and then record the results at each step (classifier labels, labels after min_bought_duration smoothing, \n",
    "and labels after Kleinburg Filtering).  Then we will calculate classifier performance at each of these steps.\n",
    "Finally we will calculate total interaction times for each video, then aggregate the results per animal, per treatment group, and per object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min bought duration in frames: 3\n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_9\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_IOT_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_IOT_14\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_IOT_18\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-18_NOD_IOT_18-upsidedown\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 03152021_NOD_IOT_3\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 03162021_NOD_DOT_3_upsidedown\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 03162021_NOD_DOT_9_upsidedown\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_NOD_IOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08112021_NOD_IOT_Rat12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08122021_NOD_DOT_Rat5\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_7_WC\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_9\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_IOT_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_IOT_14\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_IOT_18\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-15_NOD_IOT_13\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-15_NOD_IOT_15\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-18_NOD_IOT_18-upsidedown\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOD_IOT_13\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOD_IOT_7\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_DOT_Rat4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_DOT_Rat6\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_DOT_Rat10\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_IOT_12\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08102021_NOB_DOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08102021_NOB_IOT_Rat3\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08112021_NOB_IOT_Rat1\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08112021_NOB_DOT_Rat7\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08122021_NOB_IOT_Rat4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08132021_NOB_DOT_Rat10\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08142021_NOB_DOT_Rat7\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-20_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_DOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_IOT_23\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-24_NOB_IOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_1\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_5\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 03142021_NOB_DOT_5_upsidedown\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 03142021_NOB_IOT_7_upsidedown\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 03152021_NOB_IOT_8\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_DOT_Rat10\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08102021_NOB_DOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08112021_NOB_DOT_Rat7\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08122021_NOB_IOT_Rat4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08132021_NOB_IOT_8\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08142021_NOB_DOT_Rat11\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08142021_NOB_IOT_Rat5\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOB_IOT_2(upsidedown)_WC\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-17_NOB_IOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-20_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 2022-06-20_NOB_IOT_1\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-20_NOB_IOT_3\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_DOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_DOT_24\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_IOT_23\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-23_NOB_DOT_1\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-24_NOB_IOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-24_NOB_IOT_24\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_2\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_1\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_5 (2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_5\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-27_NOB_DOT_20\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 2022-06-27_NOB_IOT_21\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_DOT_Rat4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_DOT_Rat6\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_DOT_Rat10\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 08092021_NOB_IOT_12\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 08102021_NOB_DOT_7\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08112021_NOB_DOT_Rat7\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded data for: \n",
      "        Video name: 08122021_NOB_IOT_Rat4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08132021_NOB_DOT_Rat10\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "Recorded data for: \n",
      "        Video name: 08142021_NOB_DOT_Rat7\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def kleinberg(offsets: np.ndarray, s=2, gamma=1):\n",
    "    \"\"\" TODO: Cite/give credit to Simba devs for implementation\"\"\"\n",
    "    if s <= 1:\n",
    "        raise ValueError(\"s must be greater than 1'!\")\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be positive!\")\n",
    "    if len(offsets) < 1:\n",
    "        raise ValueError(\"offsets must be non-empty!\")\n",
    "\n",
    "    assert offsets.ndim == 1\n",
    "    offsets = np.array(offsets, dtype=object)\n",
    "\n",
    "    if offsets.size == 1:\n",
    "        bursts = np.array([0, offsets[0], offsets[0]], ndmin=2, dtype=object)\n",
    "        return bursts\n",
    "\n",
    "    # offsets = np.sort(offsets)\n",
    "    gaps = np.diff(offsets)\n",
    "\n",
    "    if not np.all(gaps):\n",
    "        raise ValueError(\"Input cannot contain events with zero time between!\")\n",
    "\n",
    "    T = np.sum(gaps)\n",
    "    n = np.size(gaps)\n",
    "\n",
    "    g_hat = T / n\n",
    "\n",
    "    k = int(math.ceil(float(1 + math.log(T, s) + math.log(1 / np.amin(gaps), s))))\n",
    "\n",
    "    gamma_log_n = gamma * math.log(n)\n",
    "\n",
    "    def tau(i, j):\n",
    "        if i >= j:\n",
    "            return 0\n",
    "        else:\n",
    "            return (j - i) * gamma_log_n\n",
    "\n",
    "    alpha_function = np.vectorize(lambda x: s ** x / g_hat)\n",
    "    alpha = alpha_function(np.arange(k))\n",
    "\n",
    "    def f(j, x): # The exponential dist function for index j\n",
    "        return alpha[j] * math.exp(-alpha[j] * x)\n",
    "\n",
    "    C = np.repeat(float(\"inf\"), k)\n",
    "    C[0] = 0\n",
    "\n",
    "    q = np.empty((k, 0))\n",
    "    for t in range(n):\n",
    "        C_prime = np.repeat(float(\"inf\"), k)\n",
    "        q_prime = np.empty((k, t + 1))\n",
    "        q_prime.fill(np.nan)\n",
    "\n",
    "        for j in range(k):\n",
    "            cost_function = np.vectorize(lambda x: C[x] + tau(x, j))\n",
    "            cost = cost_function(np.arange(0, k))\n",
    "\n",
    "            el = np.argmin(cost)\n",
    "\n",
    "            if f(j, gaps[t]) > 0:\n",
    "                C_prime[j] = cost[el] - math.log(f(j, gaps[t]))\n",
    "\n",
    "            if t > 0:\n",
    "                q_prime[j, :t] = q[el, :]\n",
    "\n",
    "            q_prime[j, t] = j + 1\n",
    "\n",
    "        C = C_prime\n",
    "        q = q_prime\n",
    "\n",
    "    j = np.argmin(C)\n",
    "    q = q[j, :]\n",
    "\n",
    "    prev_q = 0\n",
    "\n",
    "    N = 0\n",
    "    for t in range(n):\n",
    "        if q[t] > prev_q:\n",
    "            N = N + q[t] - prev_q\n",
    "        prev_q = q[t]\n",
    "\n",
    "    # bursts = np.vstack([np.repeat(np.nan, N), np.repeat(offsets[0], N), np.repeat(offsets[0], N)]).transpose()\n",
    "    bursts = np.array([np.repeat(np.nan, N), np.repeat(offsets[0], N), np.repeat(offsets[0], N)], ndmin=2, dtype=object).transpose()\n",
    "    burst_counter = -1\n",
    "    prev_q = 0\n",
    "    stack = np.repeat(np.nan, N)\n",
    "    stack_counter = -1\n",
    "    for t in range(n):\n",
    "        if q[t] > prev_q:\n",
    "            num_levels_opened = q[t] - prev_q\n",
    "            for i in range(int(num_levels_opened)):\n",
    "                burst_counter += 1\n",
    "                bursts[burst_counter, 0] = prev_q + i\n",
    "                bursts[burst_counter, 1] = offsets[t]\n",
    "                stack_counter += 1\n",
    "                stack[stack_counter] = burst_counter\n",
    "        elif q[t] < prev_q:\n",
    "            num_levels_closed = prev_q - q[t]\n",
    "            for i in range(int(num_levels_closed)):\n",
    "                bursts[int(stack[stack_counter]), 2] = offsets[t]\n",
    "                stack_counter -= 1\n",
    "        prev_q = q[t]\n",
    "\n",
    "    while stack_counter >= 0:\n",
    "        bursts[int(stack[stack_counter]), 2] = offsets[n]\n",
    "        stack_counter -= 1\n",
    "\n",
    "    return bursts\n",
    "\n",
    "def build_Y_post_processor_klienberg_filtering():\n",
    "    def Y_post_processor_klienberg_filtering(y_pred): #, _df: pd.DataFrame):\n",
    "        # df = _df.copy(deep=True)\n",
    "        # AARONT: TODO: Had 'math domain error downstream here, would have to fix that!  Turning off'\n",
    "        # from simba.Kleinberg_burst_analysis import kleinberg\n",
    "        # kleinberg filtering setup args etc\n",
    "        classifierName = 'Interaction'\n",
    "        logs_path = 'TEMP_kburg_logs_path'\n",
    "        os.makedirs(logs_path, exist_ok=True)\n",
    "        hierarchy = 1\n",
    "        ## Trying to do this without requiring the dataframe...\n",
    "        # assert len(df) == len(y_pred)\n",
    "        # currDf = df[y_pred == 1]\n",
    "        # offsets = list(currDf.index.values)\n",
    "        # split into offsets by video\n",
    "        ## AARONT: This will cause issues if we used for example undersampling upstream, since we\n",
    "        #          aren't using the video indexes anymore.  But we shouldn't be doing that upstream,\n",
    "        #          so it shouldn't be a problem.  And even if someone did that would produce very strange\n",
    "        #          results and shouldn't be done.\n",
    "        offsets = numpy.where(y_pred == 1)[0]\n",
    "\n",
    "        # kleinberg apply algorithm\n",
    "        # print(f'offsets: {offsets}')\n",
    "        # print(f'df cols: {df.columns}')\n",
    "        # AARONT: TODO: I think the math domain error is due to the offsets calculation, they need to have some spacing\n",
    "        #               or something like that and are not getting the spacing they need!\n",
    "        # From the paper: Adjusting 'b' controls inertia that keeps automaton in it's current state (which arg is b?)\n",
    "        #\n",
    "        kleinbergBouts = kleinberg(offsets, s=2.0, gamma=0.3) # TODO: Params?\n",
    "        # print(f'AARONT: k-filtering bouts (head): {kleinbergBouts[0:3]}')\n",
    "        kleinbergDf = pd.DataFrame(kleinbergBouts, columns=['Hierarchy', 'Start', 'Stop'])\n",
    "        kleinbergDf['Stop'] += 1\n",
    "        file_name = 'Kleinberg_log_' + classifierName + '.csv'\n",
    "        logs_file_name = os.path.join(logs_path, file_name)\n",
    "        kleinbergDf.to_csv(logs_file_name)\n",
    "        kleinbergDf_2 = kleinbergDf[kleinbergDf['Hierarchy'] == hierarchy].reset_index(drop=True)\n",
    "        # df[classifierName] = 0\n",
    "        new_y_pred = numpy.zeros_like(y_pred)\n",
    "        for index, row in kleinbergDf_2.iterrows():\n",
    "            rangeList = list(range(int(row['Start']), int(row['Stop'])))\n",
    "            new_y_pred[rangeList] = 1\n",
    "            # for frame in rangeList:\n",
    "                # df.at[frame, classifierName] = 1\n",
    "        # y_pred = df[classifierName].values\n",
    "        return new_y_pred\n",
    "    return Y_post_processor_klienberg_filtering\n",
    "\n",
    "\n",
    "def FROM_SIMBA_plug_holes_shortest_bout(y_pred, min_bout_duration): #, fps=None, shortest_bout=None):\n",
    "    \"\"\"\n",
    "    First, find all patterns like `1 0 0 0 ... 0 0 0 1` where the number of frames that are zeros is\n",
    "    less than or equal to min_bout_duration and fill them with 1's.\n",
    "    Then find all patterns like `0 1 1 1 ... 1 1 1 0` with the same length specification, and fill those\n",
    "    with 0's.\n",
    "    \"\"\"\n",
    "    col_name = 'y_pred_col'\n",
    "    data_df = pd.DataFrame(y_pred, columns=[col_name])\n",
    "    # frames_to_plug = int(int(fps) * int(shortest_bout) / 1000)\n",
    "    frames_to_plug_lst = list(range(1, min_bout_duration + 1))\n",
    "    frames_to_plug_lst.reverse()\n",
    "    patternListofLists, negPatternListofList = [], []\n",
    "    for k in frames_to_plug_lst:\n",
    "        zerosInList, oneInlist = [0] * k, [1] * k\n",
    "        currList = [1]\n",
    "        currList.extend(zerosInList)\n",
    "        currList.extend([1])\n",
    "        currListNeg = [0]\n",
    "        currListNeg.extend(oneInlist)\n",
    "        currListNeg.extend([0])\n",
    "        patternListofLists.append(currList)\n",
    "        negPatternListofList.append(currListNeg)\n",
    "    fill_patterns = numpy.asarray(patternListofLists, dtype=object)\n",
    "    remove_patterns = numpy.asarray(negPatternListofList, dtype=object)\n",
    "\n",
    "    for currPattern in fill_patterns:\n",
    "        n_obs = len(currPattern)\n",
    "        data_df['rolling_match'] = (data_df[col_name].rolling(window=n_obs, min_periods=n_obs)\n",
    "                                    .apply(lambda x: (x == currPattern).all(), raw=True)\n",
    "                                    .mask(lambda x: x == 0)\n",
    "                                    .bfill(limit=n_obs - 1)\n",
    "                                    .fillna(0)\n",
    "                                    .astype(bool)\n",
    "                                    )\n",
    "        data_df.loc[data_df['rolling_match'] == True, col_name] = 1\n",
    "        data_df = data_df.drop(['rolling_match'], axis=1)\n",
    "\n",
    "    for currPattern in remove_patterns:\n",
    "        n_obs = len(currPattern)\n",
    "        data_df['rolling_match'] = (data_df[col_name].rolling(window=n_obs, min_periods=n_obs)\n",
    "                                    .apply(lambda x: (x == currPattern).all(), raw=True)\n",
    "                                    .mask(lambda x: x == 0)\n",
    "                                    .bfill(limit=n_obs - 1)\n",
    "                                    .fillna(0)\n",
    "                                    .astype(bool)\n",
    "                                    )\n",
    "        data_df.loc[data_df['rolling_match'] == True, col_name] = 0\n",
    "        data_df = data_df.drop(['rolling_match'], axis=1)\n",
    "\n",
    "    return data_df[col_name]\n",
    "\n",
    "\n",
    "def build_Y_post_processor_min_bought_duration(min_bout_duration):\n",
    "    def Y_post_processor_min_bought_duration(y_pred: numpy.ndarray):\n",
    "        \"\"\" given y_pred a vector of binary predictions, enforce a minimum number of\n",
    "        concurrent predictions \"\"\"\n",
    "        assert numpy.all((y_pred == 1) | (y_pred == 0)), f'ERROR: y_pred must be a binary vector.  Got this instead: {y_pred}'\n",
    "        assert isinstance(min_bout_duration, int)\n",
    "\n",
    "        # print(f'y_pred BEFORE min_bought: (sum is {numpy.sum(y_pred)}; {y_pred}')\n",
    "        y_pred = FROM_SIMBA_plug_holes_shortest_bout(y_pred, min_bout_duration)\n",
    "        # print(f'y_pred AFTER min_bought: (sum is {numpy.sum(y_pred)}; {y_pred}')\n",
    "        return y_pred\n",
    "    return Y_post_processor_min_bought_duration\n",
    "\n",
    "\n",
    "video_frame_rate_in_seconds = 30 # fps for all of our videos\n",
    "min_bought_duration_in_ms = 100\n",
    "# ms * (frame_rate/ms) = frame_rate\n",
    "min_bought_duration_in_frames = int(\n",
    "    min_bought_duration_in_ms * video_frame_rate_in_seconds / 1000\n",
    ")\n",
    "print('min bought duration in frames:', min_bought_duration_in_frames)\n",
    "Y_post_processor_min_bought_duration = build_Y_post_processor_min_bought_duration(min_bought_duration_in_frames)\n",
    "Y_post_processor_klienberg_filtering = build_Y_post_processor_klienberg_filtering()\n",
    "\n",
    "def get_classifier_desc(clf):\n",
    "    if isinstance(clf, type(None)):\n",
    "        return 'simba-RF-precomputed'\n",
    "    elif isinstance(clf, str):\n",
    "        # Hacky, just return this is a string\n",
    "        return clf\n",
    "    elif isinstance(clf, XGBClassifier):\n",
    "        # NOTE: If we ever try searching parameters we can modify this to be a tuple with the classifier name and params\n",
    "        return clf._classifier_desc # I added this manually haha\n",
    "    elif isinstance(clf, RandomForestClassifier):\n",
    "        return clf.__class__.__name__\n",
    "    else:\n",
    "        raise NotImplementedError(f'Do not have a classifier description extractor defined for {clf.__class__.__name__} models')\n",
    "\n",
    "# Store the results of applying the base classifier to the data\n",
    "def run_model_and_record_results(dataset, clf=None, precomputed_y_preds=None):\n",
    "    assert not (clf and precomputed_y_preds), 'If clf is provided it will be used to compute y predictions, otherwise you can provide \"precomputed_y_preds\".  You can not provide both.  Pick one'\n",
    "    assert clf or precomputed_y_preds, 'You most provide one of \"clf\" or \"precomputed_y_preds\"'\n",
    "    # precomputed_y_preds must be a dictionary of video_names -> np.ndarray of y predictions.\n",
    "    assert len(dataset.per_video_data_classes) > 0, 'Must have loaded the dataset and have data already!'\n",
    "    classifier_desc = get_classifier_desc(clf)\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        if clf:\n",
    "            X = per_video_data.X\n",
    "            y_pred = clf.predict(X)\n",
    "            y_prob = clf.predict_proba(X)\n",
    "            per_video_data.apply_and_record_postprocessing_step(classifier_desc, clf, y_pred, y_prob)\n",
    "        else:\n",
    "            assert precomputed_y_preds\n",
    "            y_pred = precomputed_y_preds[per_video_data.video_name] # If this fails, we are missing the video name!\n",
    "            # Hacky: Hard coding the classifier_desc here\n",
    "            per_video_data.apply_and_record_postprocessing_step(classifier_desc, classifier_desc, y_pred)\n",
    "        y_pred = Y_post_processor_min_bought_duration(y_pred)\n",
    "        per_video_data.apply_and_record_postprocessing_step(classifier_desc, Y_post_processor_min_bought_duration, y_pred)\n",
    "        y_pred = Y_post_processor_klienberg_filtering(y_pred)\n",
    "        per_video_data.apply_and_record_postprocessing_step(classifier_desc, Y_post_processor_klienberg_filtering, y_pred)\n",
    "\n",
    "        print('Recorded data for:', per_video_data)\n",
    "\n",
    "\n",
    "\n",
    "run_model_and_record_results(training_odour_dataset, xgb_odour_clf)\n",
    "run_model_and_record_results(holdout_odour_dataset, xgb_odour_clf)\n",
    "run_model_and_record_results(training_object_dataset, xgb_object_clf)\n",
    "run_model_and_record_results(holdout_object_dataset, xgb_object_clf)\n",
    "\n",
    "# run_model_and_record_results(training_odour_dataset, xgb_combined_clf)\n",
    "# run_model_and_record_results(holdout_odour_dataset, xgb_combined_clf)\n",
    "# run_model_and_record_results(training_object_dataset, xgb_combined_clf)\n",
    "# run_model_and_record_results(holdout_object_dataset, xgb_combined_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1200,) (9000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[244], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m precomputed_y_preds \u001b[39m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     per_video_data\u001b[39m.\u001b[39mvideo_name: per_video_data\u001b[39m.\u001b[39my_binary \n\u001b[0;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m per_video_data \u001b[39min\u001b[39;00m simba_prelabeled_dataset\u001b[39m.\u001b[39mper_video_data_classes}\n\u001b[0;32m      6\u001b[0m \u001b[39m# TODO: Here insert the labels Tim provided!\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# run_model_and_record_results(simba_prelabeled_dataset, precomputed_y_preds=precomputed_y_preds)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# run_model_and_record_results(holdout_odour_dataset, precomputed_y_preds=precomputed_y_preds) # Don't have odour yet\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# run_model_and_record_results(training_object_dataset, precomputed_y_preds=precomputed_y_preds)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m run_model_and_record_results(holdout_object_dataset, precomputed_y_preds\u001b[39m=\u001b[39;49mprecomputed_y_preds)\n",
      "Cell \u001b[1;32mIn[243], line 267\u001b[0m, in \u001b[0;36mrun_model_and_record_results\u001b[1;34m(dataset, clf, precomputed_y_preds)\u001b[0m\n\u001b[0;32m    265\u001b[0m     y_pred \u001b[39m=\u001b[39m precomputed_y_preds[per_video_data\u001b[39m.\u001b[39mvideo_name] \u001b[39m# If this fails, we are missing the video name!\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[39m# Hacky: Hard coding the classifier_desc here\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     per_video_data\u001b[39m.\u001b[39;49mapply_and_record_postprocessing_step(classifier_desc, classifier_desc, y_pred)\n\u001b[0;32m    268\u001b[0m y_pred \u001b[39m=\u001b[39m Y_post_processor_min_bought_duration(y_pred)\n\u001b[0;32m    269\u001b[0m per_video_data\u001b[39m.\u001b[39mapply_and_record_postprocessing_step(classifier_desc, Y_post_processor_min_bought_duration, y_pred)\n",
      "Cell \u001b[1;32mIn[235], line 76\u001b[0m, in \u001b[0;36mPerVideoDataClass.apply_and_record_postprocessing_step\u001b[1;34m(self, classifier_desc, func, y_binary, y_prob)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     step_key \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m---> 76\u001b[0m y_multi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_y_multi_label_extractor(y_binary)\n\u001b[0;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_result_labels[classifier_desc][step_key] \u001b[39m=\u001b[39m ModelResultLabels(\n\u001b[0;32m     78\u001b[0m     func, y_binary, y_multi, y_prob, \n\u001b[0;32m     79\u001b[0m     build_partial_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_binary, y_binary),\n\u001b[0;32m     80\u001b[0m     build_partial_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_multi, y_multi))\n",
      "Cell \u001b[1;32mIn[235], line 139\u001b[0m, in \u001b[0;36mbuild_Y_get_multi_label.<locals>.Y_get_multi_label\u001b[1;34m(df, ys_binary)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mY_get_multi_label\u001b[39m(df, ys_binary):\n\u001b[0;32m    137\u001b[0m     \u001b[39m# +1 Because column_0 ==>  Object_1\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     nearest_obj \u001b[39m=\u001b[39m df[distance_features]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39margmin(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m nearest_obj \u001b[39m*\u001b[39;49m ys_binary\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1200,) (9000,) "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Manually load the pre-computed videos... THE NAMES WON'T MATCH UP! (use the name map up top)\n",
    "precomputed_y_preds = {\n",
    "    per_video_data.video_name: per_video_data.y_binary \n",
    "    for per_video_data in simba_prelabeled_dataset.per_video_data_classes}\n",
    "\n",
    "# TODO: Here insert the labels Tim provided!\n",
    "# run_model_and_record_results(simba_prelabeled_dataset, precomputed_y_preds=precomputed_y_preds)\n",
    "\n",
    "## TODO: Don't have the video name map!!\n",
    "# run_model_and_record_results(training_odour_dataset, precomputed_y_preds=precomputed_y_preds)\n",
    "# run_model_and_record_results(holdout_odour_dataset, precomputed_y_preds=precomputed_y_preds) # Don't have odour yet\n",
    "# run_model_and_record_results(training_object_dataset, precomputed_y_preds=precomputed_y_preds)\n",
    "run_model_and_record_results(holdout_object_dataset, precomputed_y_preds=precomputed_y_preds)\n",
    "\n",
    "## OLD: When we had the actual model\n",
    "# run_model_and_record_results(training_odour_dataset, simba_odour_clf)\n",
    "# run_model_and_record_results(holdout_odour_dataset, simba_odour_clf)\n",
    "# run_model_and_record_results(training_object_dataset, simba_object_clf)\n",
    "# run_model_and_record_results(holdout_object_dataset, simba_object_clf)\n",
    "\n",
    "\n",
    "# TODO: Load arbitrary results (ROI predictions in particular) and add them to the per_video_data_classes as another classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in holdout_object_dataset.per_video_data_classes:\n",
    "    print(d)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Per Video Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "TRAINING ODOUR SCORES\n",
      "\n",
      "########################################\n",
      "08102021_IOT_Rat3_4(2)\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9897189856065799, recall=1.0, f1=0.994832931450224, c_mat=array([[5741,   15],\n",
      "       [   0, 1444]], dtype=int64))\n",
      "PartialResults(precision=0.9897688897710282, recall=1.0, f1=0.9948456059472239, c_mat=array([[5741,    0,    1,    0,    6,    3,    5],\n",
      "       [   0,  146,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  160,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,   77,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  301,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  466,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  294]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-11_NOD_DOT_11\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9861218195836546, recall=1.0, f1=0.9930124223602486, c_mat=array([[4103,   18],\n",
      "       [   0, 1279]], dtype=int64))\n",
      "PartialResults(precision=0.9861359108170823, recall=1.0, f1=0.9930160179833688, c_mat=array([[4103,    6,    2,    1,    3,    2,    4],\n",
      "       [   0,  391,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  115,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  146,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  144,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  193,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  290]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-11_NOD_DOT_9\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9864864864864865, recall=1.0, f1=0.9931972789115647, c_mat=array([[4660,   10],\n",
      "       [   0,  730]], dtype=int64))\n",
      "PartialResults(precision=0.9868338400797124, recall=1.0, f1=0.9932868043904963, c_mat=array([[4660,    0,    0,    0,    1,    8,    1],\n",
      "       [   0,  129,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  123,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  120,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   85,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  166,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  107]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-11_NOD_IOT_12\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9916267942583732, recall=1.0, f1=0.9957957957957958, c_mat=array([[3728,   14],\n",
      "       [   0, 1658]], dtype=int64))\n",
      "PartialResults(precision=0.9916386740028451, recall=1.0, f1=0.9957988064506347, c_mat=array([[3728,    2,    0,    1,    2,    4,    5],\n",
      "       [   0,  287,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   52,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  148,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  215,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  614,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  342]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-12_NOD_IOT_14\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9891745602165088, recall=1.0, f1=0.9945578231292517, c_mat=array([[4661,    8],\n",
      "       [   0,  731]], dtype=int64))\n",
      "PartialResults(precision=0.9893055398007508, recall=1.0, f1=0.9945912439694169, c_mat=array([[4661,    3,    1,    0,    2,    0,    2],\n",
      "       [   0,  111,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  130,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,   84,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  141,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  208,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   57]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-12_NOD_IOT_18\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9816933638443935, recall=1.0, f1=0.9907621247113163, c_mat=array([[4089,   24],\n",
      "       [   0, 1287]], dtype=int64))\n",
      "PartialResults(precision=0.9817993749547664, recall=1.0, f1=0.9907893786911106, c_mat=array([[4089,    7,    4,    0,    8,    3,    2],\n",
      "       [   0,  192,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  293,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  116,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  322,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  137,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  227]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-18_NOD_IOT_18-upsidedown\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9941634241245136, recall=1.0, f1=0.9970731707317073, c_mat=array([[6944,   12],\n",
      "       [   0, 2044]], dtype=int64))\n",
      "PartialResults(precision=0.9942190919246157, recall=1.0, f1=0.9970873241790145, c_mat=array([[6944,    2,    3,    0,    4,    2,    1],\n",
      "       [   0,  321,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  737,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  510,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  138,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,   92,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  246]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "\n",
      "**************************************************\n",
      "HOLDOUT ODOUR SCORES\n",
      "\n",
      "\n",
      "**************************************************\n",
      "TRAINING OBJECT SCORES\n",
      "\n",
      "########################################\n",
      "08092021_NOB_DOT_Rat4\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7884130982367759, recall=0.9842767295597484, f1=0.8755244755244755, c_mat=array([[6396,  168],\n",
      "       [  10,  626]], dtype=int64))\n",
      "PartialResults(precision=0.79255782664138, recall=0.9842767295597484, f1=0.8770940197762976, c_mat=array([[6396,   30,   31,   36,   25,   27,   19],\n",
      "       [   4,   60,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  109,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  110,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   79,    0,    0],\n",
      "       [   3,    0,    0,    0,    0,  137,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  131]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08092021_NOB_DOT_Rat6\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8026151930261519, recall=0.9884969325153374, f1=0.8859106529209622, c_mat=array([[5579,  317],\n",
      "       [  15, 1289]], dtype=int64))\n",
      "PartialResults(precision=0.8092922826147468, recall=0.9884969325153374, f1=0.8883038193419508, c_mat=array([[5579,   38,   52,   38,   45,   63,   81],\n",
      "       [   1,  352,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  164,    0,    0,    0,    0],\n",
      "       [   3,    0,    0,  106,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  101,    0,    0],\n",
      "       [   7,    0,    0,    0,    0,  149,    0],\n",
      "       [   3,    0,    0,    0,    0,    0,  417]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08092021_DOT_Rat9_10(2)\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8401215805471125, recall=0.9871428571428571, f1=0.9077175697865353, c_mat=array([[5537,  263],\n",
      "       [  18, 1382]], dtype=int64))\n",
      "PartialResults(precision=0.8425958768278559, recall=0.9871428571428571, f1=0.9085402008910783, c_mat=array([[5537,   50,   30,   33,   31,   88,   31],\n",
      "       [   5,  278,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  253,    0,    0,    0,    0],\n",
      "       [   4,    0,    0,  244,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  168,    0,    0],\n",
      "       [   5,    0,    0,    0,    0,  280,    0],\n",
      "       [   3,    0,    0,    0,    0,    0,  159]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08092021_NOB_DOT_Rat10\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8675417661097852, recall=0.9958904109589041, f1=0.9272959183673468, c_mat=array([[3718,  222],\n",
      "       [   6, 1454]], dtype=int64))\n",
      "PartialResults(precision=0.873323707874437, recall=0.9958904109589041, f1=0.9291796447545182, c_mat=array([[3718,   67,   34,   25,   38,   31,   27],\n",
      "       [   3,  352,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,   85,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  319,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   98,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  314,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  286]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08092021_NOB_IOT_12\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7444051825677267, recall=0.9753086419753086, f1=0.8443553774215098, c_mat=array([[5470,  434],\n",
      "       [  32, 1264]], dtype=int64))\n",
      "PartialResults(precision=0.7511268052574525, recall=0.9753086419753086, f1=0.8469557526183761, c_mat=array([[5470,  118,   51,  128,   63,   13,   61],\n",
      "       [   6,  323,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,  108,    0,    0,    0,    0],\n",
      "       [   8,    0,    0,  255,    0,    0,    0],\n",
      "       [   4,    0,    0,    0,  369,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,   70,    0],\n",
      "       [   7,    0,    0,    0,    0,    0,  139]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08102021_NOB_DOT_11\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8625803262481463, recall=0.9869909502262444, f1=0.9206014244262728, c_mat=array([[5154,  278],\n",
      "       [  23, 1745]], dtype=int64))\n",
      "PartialResults(precision=0.8647061852729557, recall=0.9869909502262444, f1=0.9212362121414686, c_mat=array([[5154,   59,   30,   16,   96,   38,   39],\n",
      "       [   2,  261,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  184,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,   81,    0,    0,    0],\n",
      "       [   8,    0,    0,    0,  439,    0,    0],\n",
      "       [   6,    0,    0,    0,    0,  367,    0],\n",
      "       [   5,    0,    0,    0,    0,    0,  413]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08102021_DOT_Rat7_8(2)\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8475881637616538, recall=0.9872521246458924, f1=0.9121046892039258, c_mat=array([[4706,  376],\n",
      "       [  27, 2091]], dtype=int64))\n",
      "PartialResults(precision=0.8501128780974468, recall=0.9872521246458924, f1=0.9128554123122788, c_mat=array([[4706,   48,  106,   28,   65,   80,   49],\n",
      "       [   2,  361,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,  360,    0,    0,    0,    0],\n",
      "       [  11,    0,    0,  257,    0,    0,    0],\n",
      "       [   2,    0,    0,    0,  384,    0,    0],\n",
      "       [   4,    0,    0,    0,    0,  346,    0],\n",
      "       [   2,    0,    0,    0,    0,    0,  383]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08102021_NOB_IOT_Rat3\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8218543046357616, recall=0.999194847020934, f1=0.9018895348837209, c_mat=array([[3889,  269],\n",
      "       [   1, 1241]], dtype=int64))\n",
      "PartialResults(precision=0.8280895246129304, recall=0.999194847020934, f1=0.9039394186738914, c_mat=array([[3889,   43,   51,   29,   34,   83,   29],\n",
      "       [   0,  132,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  143,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  162,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   88,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  357,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  359]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08112021_NOB_IOT_Rat1\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8568353067814855, recall=0.9937578027465668, f1=0.9202312138728324, c_mat=array([[4466,  133],\n",
      "       [   5,  796]], dtype=int64))\n",
      "PartialResults(precision=0.8601308310121081, recall=0.9937578027465668, f1=0.9212028808062758, c_mat=array([[4466,   27,    6,   20,   39,   40,    1],\n",
      "       [   2,  190,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   79,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  173,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  145,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  176,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,   33]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08112021_NOB_DOT_Rat7\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8493234932349324, recall=0.9956741167988464, f1=0.9166943245934285, c_mat=array([[3768,  245],\n",
      "       [   6, 1381]], dtype=int64))\n",
      "PartialResults(precision=0.852069817185882, recall=0.9956741167988464, f1=0.9176130842023683, c_mat=array([[3768,   60,   64,   35,   43,   43],\n",
      "       [   1,  273,    0,    0,    0,    0],\n",
      "       [   2,    0,  211,    0,    0,    0],\n",
      "       [   0,    0,    0,  295,    0,    0],\n",
      "       [   3,    0,    0,    0,  210,    0],\n",
      "       [   0,    0,    0,    0,    0,  392]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08122021_NOB_IOT_Rat4\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7428571428571429, recall=0.9883040935672515, f1=0.8481806775407779, c_mat=array([[4941,  117],\n",
      "       [   4,  338]], dtype=int64))\n",
      "PartialResults(precision=0.7636368212449148, recall=0.9883040935672515, f1=0.8590122582125372, c_mat=array([[4941,   34,   18,   20,   17,   12,   16],\n",
      "       [   2,   64,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,   68,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  103,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   44,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    2,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   57]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08132021_NOB_DOT_Rat10\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8311965811965812, recall=0.9948849104859335, f1=0.9057043073341094, c_mat=array([[4460,  158],\n",
      "       [   4,  778]], dtype=int64))\n",
      "PartialResults(precision=0.8340031229393817, recall=0.9948849104859335, f1=0.906581685059138, c_mat=array([[4460,   13,   30,   20,   69,   16,   10],\n",
      "       [   0,   36,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  166,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,   96,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  258,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  142,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,   80]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08142021_NOB_DOT_Rat7\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8733297701763763, recall=0.9975579975579976, f1=0.9313194642348247, c_mat=array([[3525,  237],\n",
      "       [   4, 1634]], dtype=int64))\n",
      "PartialResults(precision=0.875092183610952, recall=0.9975579975579976, f1=0.9318662904406949, c_mat=array([[3525,   14,   45,   32,   66,   50,   30],\n",
      "       [   2,  136,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  445,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  200,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  255,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  348,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  250]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-20_NOB_DOT_4\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8158253751705321, recall=0.9917081260364843, f1=0.8952095808383234, c_mat=array([[7524,  270],\n",
      "       [  10, 1196]], dtype=int64))\n",
      "PartialResults(precision=0.819134803201785, recall=0.9917081260364843, f1=0.896386460443442, c_mat=array([[7524,   13,   70,   43,   48,   39,   57],\n",
      "       [   0,   85,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  462,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  150,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  157,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  193,    0],\n",
      "       [   5,    0,    0,    0,    0,    0,  149]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-21_NOB_DOT_22\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9124792013311148, recall=0.9952813067150635, f1=0.9520833333333333, c_mat=array([[5982,  263],\n",
      "       [  13, 2742]], dtype=int64))\n",
      "PartialResults(precision=0.9157180460468609, recall=0.9952813067150635, f1=0.9530820577994723, c_mat=array([[5982,    8,   43,   18,   45,   48,  101],\n",
      "       [   0,  443,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  170,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  386,    0,    0,    0],\n",
      "       [   2,    0,    0,    0,  158,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  491,    0],\n",
      "       [   9,    0,    0,    0,    0,    0, 1094]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-21_NOB_IOT_23\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8032786885245902, recall=0.9932432432432432, f1=0.8882175226586103, c_mat=array([[7896,  216],\n",
      "       [   6,  882]], dtype=int64))\n",
      "PartialResults(precision=0.810236828376383, recall=0.9932432432432432, f1=0.8907110761750758, c_mat=array([[7896,   10,   31,   24,   34,   67,   50],\n",
      "       [   0,  123,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,   51,    0,    0,    0,    0],\n",
      "       [   2,    0,    0,  166,    0,    0,    0],\n",
      "       [   2,    0,    0,    0,  102,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  287,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  153]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-24_NOB_IOT_22\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8507462686567164, recall=0.9978991596638656, f1=0.9184660006445375, c_mat=array([[7322,  250],\n",
      "       [   3, 1425]], dtype=int64))\n",
      "PartialResults(precision=0.8527209630636091, recall=0.9978991596638656, f1=0.9190659154392548, c_mat=array([[7322,   30,   42,   43,   44,   39,   52],\n",
      "       [   0,  170,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  172,    0,    0,    0,    0],\n",
      "       [   2,    0,    0,  414,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  222,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  143,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  304]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-26_NOB_DOT_4\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9230118443316413, recall=0.9963470319634703, f1=0.9582784365393061, c_mat=array([[6628,  182],\n",
      "       [   8, 2182]], dtype=int64))\n",
      "PartialResults(precision=0.9235721312706692, recall=0.9963470319634703, f1=0.9584359532641424, c_mat=array([[6628,   40,   38,   24,    9,   19,   52],\n",
      "       [   1,  317,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  557,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  178,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   95,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  370,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  665]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-26_NOB_IOT_1\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8168701442841287, recall=0.9986431478968792, f1=0.8986568986568987, c_mat=array([[8098,  165],\n",
      "       [   1,  736]], dtype=int64))\n",
      "PartialResults(precision=0.8226420318167164, recall=0.9986431478968792, f1=0.9006405611020806, c_mat=array([[8098,   14,   35,   19,   24,   62,   11],\n",
      "       [   0,  107,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   92,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  124,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  162,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  174,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   77]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-26_NOB_IOT_5\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8794326241134752, recall=0.9952785646836638, f1=0.9337763012181617, c_mat=array([[6593,  289],\n",
      "       [  10, 2108]], dtype=int64))\n",
      "PartialResults(precision=0.8836288726233522, recall=0.9952785646836638, f1=0.9351097911126418, c_mat=array([[6593,   36,   69,   34,   32,   52,   66],\n",
      "       [   2,  279,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  207,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  233,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  661,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  253,    0],\n",
      "       [   3,    0,    0,    0,    0,    0,  475]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "\n",
      "**************************************************\n",
      "HOLDOUT OBJECT SCORES\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_dataset_scores(dataset: Dataset):\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        print()\n",
    "        print('#' * 40)\n",
    "        print(per_video_data.video_name)\n",
    "        for classifier_desc, ordered_results_dict in per_video_data.model_result_labels.items():\n",
    "            print(f':::: Results for {classifier_desc} model pipeline ::::')\n",
    "            func_name = classifier_desc.split('_')[0]\n",
    "            results = ordered_results_dict[func_name]\n",
    "            print(func_name)\n",
    "            print(results.binary_results)\n",
    "            print(results.multi_label_results)\n",
    "            print('-' * 30)\n",
    "            # for func_name, results in ordered_results_dict.items():\n",
    "            #     print(func_name)\n",
    "            #     print(results.binary_results)\n",
    "            #     print(results.multi_label_results)\n",
    "            #     print('-' * 30)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('TRAINING ODOUR SCORES')\n",
    "print_dataset_scores(training_odour_dataset)\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('HOLDOUT ODOUR SCORES')\n",
    "print_dataset_scores(holdout_odour_dataset)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('TRAINING OBJECT SCORES')\n",
    "print_dataset_scores(training_object_dataset)\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('HOLDOUT OBJECT SCORES')\n",
    "print_dataset_scores(holdout_object_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[210], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m             y_preds[step_name] \u001b[39m=\u001b[39m []\n\u001b[0;32m     47\u001b[0m         y_preds[step_name]\u001b[39m.\u001b[39mextend(data_thing\u001b[39m.\u001b[39my_binary)\n\u001b[1;32m---> 49\u001b[0m \u001b[39mfor\u001b[39;00m step_name, y_pred \u001b[39min\u001b[39;00m y_preds\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     50\u001b[0m     classification_report_like_simba(y_true, y_pred, title\u001b[39m=\u001b[39mtask_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m step_name)\n\u001b[0;32m     51\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[210], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m             y_preds[step_name] \u001b[39m=\u001b[39m []\n\u001b[0;32m     47\u001b[0m         y_preds[step_name]\u001b[39m.\u001b[39mextend(data_thing\u001b[39m.\u001b[39my_binary)\n\u001b[1;32m---> 49\u001b[0m \u001b[39mfor\u001b[39;00m step_name, y_pred \u001b[39min\u001b[39;00m y_preds\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     50\u001b[0m     classification_report_like_simba(y_true, y_pred, title\u001b[39m=\u001b[39mtask_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m step_name)\n\u001b[0;32m     51\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:662\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1087\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1078\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   1973\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   1975\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 1976\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   1978\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   1981\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_mpl_hook()\n\u001b[0;32m   2010\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2011\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2015\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def classification_report_like_simba(y_true, y_pred=None, clf=None, X_data=None, title='', output_file=None):\n",
    "    assert (clf and X_data) or y_pred\n",
    "    # assert not((clf or X_data) and y_pred)\n",
    "    # Make a heat map of classifier measures.\n",
    "    if clf:\n",
    "        y_pred = clf.predict(X_data)\n",
    "\n",
    "    f1_data_interactions: PartialResults = build_partial_result(y_true, y_pred)\n",
    "    f1_data_non_interaction: PartialResults = build_partial_result(np.logical_not(y_true), np.logical_not(y_pred))\n",
    "    support_interaction = y_true.sum() / y_true.shape[0]\n",
    "    support_non_interaction = np.logical_not(y_true).sum() / y_true.shape[0]\n",
    "\n",
    "    annot_interaction = [f1_data_interactions.precision, f1_data_interactions.recall, f1_data_interactions.f1, y_true.sum()]\n",
    "    annot_non_interaction = [f1_data_non_interaction.precision, f1_data_non_interaction.recall, f1_data_non_interaction.f1, np.logical_not(y_true).sum()]\n",
    "\n",
    "    interaction_data = [f1_data_interactions.precision, f1_data_interactions.recall, f1_data_interactions.f1,support_interaction]\n",
    "    non_interaction_data = [f1_data_non_interaction.precision, f1_data_non_interaction.recall, f1_data_non_interaction.f1, support_non_interaction]\n",
    "\n",
    "    columns = ['Precision', 'Recall', 'F1', 'Support']\n",
    "    sns.heatmap([interaction_data, non_interaction_data], vmin=0.0, vmax=1.0, cmap='RdYlGn', annot=[annot_interaction, annot_non_interaction],\\\n",
    "                 xticklabels=columns, yticklabels=['Interaction', 'Non-interaction'])\n",
    "    plt.title(title)\n",
    "    if output_file:\n",
    "        plt.savefig('test.pdf')\n",
    "    plt.show()\n",
    "\n",
    "for holdout_dataset, xgb_clf, task_name in [\n",
    "        (holdout_object_dataset, xgb_object_clf, 'XGB Object'),\n",
    "        # (holdout_object_dataset, simba_object_clf, 'Simba Object'),\n",
    "        # (holdout_odour_dataset, xgb_odour_clf, 'XGB odour'),\n",
    "        # (holdout_odour_dataset, simba_odour_clf, 'Simba odour'),\n",
    "    ]:\n",
    "    print(task_name)\n",
    "    y_true = []\n",
    "    from collections import OrderedDict\n",
    "    y_preds = OrderedDict() # Will be a list with each step of processing in it\n",
    "    for video_data in holdout_dataset.per_video_data_classes:\n",
    "        y_true.extend(video_data.y_binary)\n",
    "        for step_name, data_thing in video_data.model_result_labels[get_classifier_desc(xgb_clf)].items():\n",
    "            if step_name not in y_preds:\n",
    "                y_preds[step_name] = []\n",
    "            y_preds[step_name].extend(data_thing.y_binary)\n",
    "\n",
    "    for step_name, y_pred in y_preds.items():\n",
    "        classification_report_like_simba(y_true, y_pred, title=task_name + ' ' + step_name)\n",
    "        break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Final Results.\n",
    "Results will be aggregated in a hierarchy of classes like so:\n",
    "\n",
    "AggregationFunction: Defines the measureable we wish to compute;\n",
    "    - PerVideoResults: Similar to before, we store reusult dataframes pervideo, then classifier, then step.  \n",
    "                       We want to see how the different stages in post processing effect our various measureables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Lets produce our own data as best we can.\n",
    "# Get the results we have per video, grab the per object results, and then use the 30 frames per second assumtion\n",
    "# to caclulate the total time at each object in seconds.  Can also break this down by minute later BUT need to confirm\n",
    "# with Tim how the data is setup!! Because given 30 frames per second assumption, these videos are (7200/30)/60 = 4 minutes long\n",
    "# which doesn't make sense with the stop watch data provided that makes it seem there are 10 minutes of video in each!!\n",
    "# (5 minutes per animal, with 2 animals per video being given 1 treatment!)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "def build_results_df_from_agg_funcs_and_per_video_data(per_video_data_classes: list[PerVideoDataClass],\n",
    "                    agg_funcs, per_minute, classifier_desc, pipeline_model_step=None):\n",
    "    \"\"\" Dataset will have precomputed results for all the classifiers and videos of interest. \"\"\"\n",
    "    # NOTE: No rat_id_col for these results dataframes, we can map the videoname -> rat_id via the \n",
    "    #       stopwatch dataframe later if we wish.\n",
    "    assert isinstance(agg_funcs, list)\n",
    "    if pipeline_model_step is None:\n",
    "        # Identity, default pipeline step\n",
    "        pipeline_model_step = classifier_desc\n",
    "    video_col = 'video_name'\n",
    "    rat_id_col = 'rat_id'\n",
    "    object_col = 'object'\n",
    "    minute_col = 'min'\n",
    "    if per_minute:\n",
    "        cols = [video_col, object_col, minute_col]\n",
    "    else:\n",
    "        cols = [video_col, object_col]\n",
    "    cols += [func.__name__ for func in agg_funcs]\n",
    "\n",
    "    model_res_df = pd.DataFrame([], columns=cols)\n",
    "    golden_res_df = pd.DataFrame([], columns=cols)\n",
    "    # print(f':::: Processing {classifier_desc};{pipeline_model_step} model ::::')\n",
    "\n",
    "    for per_video_data in per_video_data_classes:\n",
    "        # print('Processing:', per_video_data.video_name)\n",
    "        print('-', end='')\n",
    "        y_multi_golden = per_video_data.y_multi\n",
    "        X = per_video_data.X\n",
    "\n",
    "        results: ModelResultLabels = per_video_data.model_result_labels[classifier_desc][pipeline_model_step]\n",
    "        # Let's just do the base classifier for now??? Or lets do all 3??\n",
    "        # print(results.multi_label_results)\n",
    "        y_multi = results.y_multi\n",
    "        # TODO:  Here we need to take 1 minute 'bites' of the data!\n",
    "        #        We will build up a dataframe with the same format was what Tim provided!\n",
    "        unique_labels = numpy.unique(y_multi)\n",
    "\n",
    "        if per_minute:\n",
    "            start = 0\n",
    "            frame_rate = 30 # frames per second\n",
    "            frames_in_1_minute = frame_rate * 60\n",
    "            end = frames_in_1_minute\n",
    "            minute_number = 1 # Puny human 1 based indexing\n",
    "            while start < len(y_multi):\n",
    "                if end > len(y_multi):\n",
    "                    print('Maybe going to have a problem, end is', end, 'and y_multi len is ', len(y_multi))\n",
    "                y_multi_cur = y_multi[start:end] # Remember, exclusive indexing\n",
    "                y_multi_golden_cur = y_multi_golden[start:end] # Remember, exclusive indexing\n",
    "                for label in unique_labels:\n",
    "                    model_agg_func_results = {}\n",
    "                    golden_agg_func_results = {}\n",
    "                    if label == 0:\n",
    "                        # Majority label, no interaction\n",
    "                        continue\n",
    "                    # golden_interaction_times[label] = (y_multi_golden_cur == label).sum() / video_frame_rate\n",
    "                    for agg_func in agg_funcs:\n",
    "                        model_agg_func_results[agg_func.__name__] = agg_func(y_multi_cur, label, X)\n",
    "                        golden_agg_func_results[agg_func.__name__] = agg_func(y_multi_golden_cur, label, X)\n",
    "                    model_res_df = model_res_df.append({\n",
    "                        video_col: per_video_data.video_name,\n",
    "                        object_col: label,\n",
    "                        minute_col: minute_number,\n",
    "                        **model_agg_func_results},\n",
    "                        ignore_index=True)\n",
    "                    golden_res_df = golden_res_df.append({\n",
    "                        video_col: per_video_data.video_name,\n",
    "                        object_col: label,\n",
    "                        minute_col: minute_number,\n",
    "                        **golden_agg_func_results},\n",
    "                        ignore_index=True)\n",
    "                minute_number += 1\n",
    "                start = end\n",
    "                end += frames_in_1_minute\n",
    "        else:\n",
    "            for label in unique_labels:\n",
    "                model_agg_func_results = {}\n",
    "                golden_agg_func_results = {}\n",
    "                if label == 0:\n",
    "                    # Majority label, no interaction\n",
    "                    continue\n",
    "                # golden_interaction_times[label] = (y_multi_golden_cur == label).sum() / video_frame_rate\n",
    "                for agg_func in agg_funcs:\n",
    "                    model_agg_func_results[agg_func.__name__] = agg_func(y_multi, label, X)\n",
    "                    golden_agg_func_results[agg_func.__name__] = agg_func(y_multi_golden, label, X)\n",
    "                model_res_df = model_res_df.append({\n",
    "                    video_col: per_video_data.video_name,\n",
    "                    object_col: label,\n",
    "                    **model_agg_func_results},\n",
    "                    ignore_index=True)\n",
    "                golden_res_df = golden_res_df.append({\n",
    "                    video_col: per_video_data.video_name,\n",
    "                    object_col: label,\n",
    "                    **golden_agg_func_results},\n",
    "                    ignore_index=True)\n",
    "    return model_res_df, golden_res_df\n",
    "\n",
    "\n",
    "def build_agg_sum_total_time(video_frame_rate):\n",
    "    def agg_sum_total_time(y_multi, label, _X):\n",
    "        return (y_multi == label).sum() / video_frame_rate\n",
    "    return agg_sum_total_time\n",
    "\n",
    "def build_agg_num_interaction_bouts():\n",
    "    def agg_num_interaction_bouts(y_multi: np.ndarray, label, _X):\n",
    "        assert isinstance(y_multi, np.ndarray) and y_multi.ndim == 1, 'If we get a list of arrays or an array with more dims we will have to think harder.'\n",
    "        # Find indexes associated with this label.\n",
    "        # If our vector looks like this:\n",
    "        # [0,0,2,2,2,0,0,2]\n",
    "        # Then for label 2 we will get indexes:\n",
    "        # [2,3,4,7]\n",
    "        # The diffs here will be:\n",
    "        # [1,1,3]\n",
    "        # With each 1 associated with at least 2 frames that are part of the same bout.\n",
    "        # So we bound the number of entries in the diff array that are greater than 1,\n",
    "        # and this gives the number of bouts.\n",
    "        idxes = np.where(y_multi == label)[0] # HACKS: The [0] is required because of the way\n",
    "        diffs = np.diff(idxes)\n",
    "        num_bouts = (diffs > 1).sum()\n",
    "        return num_bouts\n",
    "    return agg_num_interaction_bouts\n",
    "\n",
    "\n",
    "def calculate_animal_in_zone(label, X):\n",
    "    in_stimulus_zone_label = [x for x in X.columns if 'in zone' in x.lower() and f'stimulus {label}' in x.lower()]\n",
    "    assert len(in_stimulus_zone_label) == 1\n",
    "    in_stimulus_zone_label = in_stimulus_zone_label[0]\n",
    "    animal_in_zone = X[in_stimulus_zone_label] != 0\n",
    "    return animal_in_zone\n",
    "\n",
    "def build_agg_mean_bout_duration(video_frame_rate):\n",
    "    def agg_mean_bout_duration(y_multi: np.ndarray, label, X):\n",
    "        assert isinstance(y_multi, np.ndarray) and y_multi.ndim == 1, 'If we get a list of arrays or an array with more dims we will have to think harder.'\n",
    "        animal_in_zone = calculate_animal_in_zone(label, X)\n",
    "        idxes = np.where((y_multi == label) & animal_in_zone)[0]\n",
    "        diffs = np.diff(idxes)\n",
    "        num_bouts = (diffs > 1).sum()\n",
    "        # Like agg_sum_total_time\n",
    "        total_time = (y_multi == label).sum() / video_frame_rate\n",
    "        if num_bouts > 0:\n",
    "            assert total_time > 0\n",
    "            # Combine them, and that's the mean\n",
    "            return total_time / num_bouts\n",
    "        else:\n",
    "            return 0\n",
    "    return agg_mean_bout_duration\n",
    "\n",
    "def build_approach_latency(video_frame_rate):\n",
    "    def approach_latency(y_multi: np.ndarray, label, X):\n",
    "        animal_in_zone = calculate_animal_in_zone(label, X)\n",
    "        idxes = np.where((y_multi == label) & animal_in_zone)[0]\n",
    "        if idxes.size > 0:\n",
    "            first_interaction = idxes[0]\n",
    "            # Time in seconds before first interaction\n",
    "            total_time = first_interaction / video_frame_rate\n",
    "            return total_time\n",
    "        return None # No interaction with this object.  Return NaN might be better\n",
    "    return approach_latency\n",
    "\n",
    "def build_agg_function_dfs(clf_dir_name, classifier, data_split_dir_name, dataset):\n",
    "    # training_model_res_per_minute_df, training_golden_res_per_minute_df = build_results_df_from_agg_funcs_and_per_video_data(\n",
    "    #         training_dataset.per_video_data_classes,\n",
    "    #         classifier_desc=get_classifier_desc(xgb_clf),\n",
    "    #         per_minute=True,\n",
    "    #         pipeline_model_step=None,\n",
    "    #         agg_funcs=[\n",
    "    #             build_agg_sum_total_time(30),\n",
    "    #             build_agg_mean_bout_duration(30),\n",
    "    #             build_agg_num_interaction_bouts(),\n",
    "    #         ]\n",
    "    #     )\n",
    "    classifier_desc = get_classifier_desc(classifier) \n",
    "    if classifier is None:\n",
    "        pipeline_model_step = classifier_desc\n",
    "    else:\n",
    "        pipeline_model_step = classifier.__class__.__name__\n",
    "\n",
    "    # holdout_model_res_per_minute_df, holdout_golden_res_per_minute_df = build_results_df_from_agg_funcs_and_per_video_data(\n",
    "    #         dataset.per_video_data_classes,\n",
    "    #         classifier_desc=classifier_desc,\n",
    "    #         per_minute=True,\n",
    "    #         pipeline_model_step=pipeline_model_step, # NOTE: ONLY CALCULATING FOR RAW MODEL RIGHT NOW! Not worried about other steps\n",
    "    #         agg_funcs=[\n",
    "    #             build_agg_sum_total_time(30),\n",
    "    #             build_agg_mean_bout_duration(30),\n",
    "    #             build_agg_num_interaction_bouts(),\n",
    "    #         ]\n",
    "    #     )\n",
    "\n",
    "    holdout_model_res_per_video_df, holdout_golden_res_per_video_df = build_results_df_from_agg_funcs_and_per_video_data(\n",
    "            dataset.per_video_data_classes,\n",
    "            classifier_desc=classifier_desc,\n",
    "            per_minute=False,\n",
    "            pipeline_model_step=pipeline_model_step,\n",
    "            agg_funcs=[\n",
    "                build_agg_sum_total_time(30),\n",
    "                build_agg_mean_bout_duration(30),\n",
    "                build_agg_num_interaction_bouts(),\n",
    "                build_approach_latency(30)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def to_csv(df, path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        df.to_csv(path)\n",
    "\n",
    "    # to_csv(holdout_model_res_per_minute_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_model_results_per_minute.csv'))\n",
    "    # to_csv(holdout_golden_res_per_minute_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_golden_results_per_minute.csv'))\n",
    "    to_csv(holdout_model_res_per_video_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_model_results_per_video.csv'))\n",
    "    to_csv(holdout_golden_res_per_video_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_golden_results_per_video.csv'))\n",
    "    return AggFuncDfs(\n",
    "        # holdout_model_res_per_minute_df, holdout_golden_res_per_minute_df, \n",
    "        holdout_model_res_per_video_df, holdout_golden_res_per_video_df)\n",
    "\n",
    "AggFuncDfs = namedtuple('AggFuncDfs', \n",
    "    # 'holdout_model_per_minute holdout_golden_per_minute holdout_model_per_video holdout_golden_per_video')\n",
    "    'holdout_model_per_video holdout_golden_per_video')\n",
    "\n",
    "simba_object_dfs = build_agg_function_dfs('simba_clf', None, 'object', simba_prelabeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::: Processing XGBClassifier_odour;XGBClassifier model ::::\n",
      "Processing: 08102021_DOT_Rat7_8\n",
      "Processing: 08122021_IOT_Rat11_12\n",
      "Processing: 2022-06-12_NOD_DOT_17\n",
      ":::: Processing XGBClassifier_object;XGBClassifier model ::::\n",
      "Processing: 03142021_NOB_DOT_5_upsidedown\n",
      "Processing: 08092021_IOT_Rat7_8\n",
      "Processing: 2022-06-11_NOB_IOT_2(upsidedown)_WC\n",
      "Processing: 2022-06-17_NOB_IOT_4\n",
      "Processing: 2022-06-20_NOB_IOT_1\n",
      "Processing: 2022-06-20_NOB_IOT_3\n",
      "Processing: 2022-06-21_NOB_DOT_24\n",
      "Processing: 2022-06-23_NOB_DOT_1\n",
      "Processing: 2022-06-23_NOB_IOT_4\n",
      "Processing: 2022-06-24_NOB_IOT_22 (2)\n",
      "Processing: 2022-06-24_NOB_IOT_22\n",
      "Processing: 2022-06-24_NOB_IOT_24\n",
      "Processing: 2022-06-26_NOB_DOT_2\n",
      "Processing: 2022-06-26_NOB_DOT_6\n",
      "Processing: 2022-06-26_NOB_IOT_5 (2)\n",
      "Processing: 2022-06-27_NOB_DOT_20\n",
      "Processing: 2022-06-27_NOB_IOT_21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_odour_dfs = build_agg_function_dfs('xgb_clf', xgb_odour_clf, 'odour', holdout_odour_dataset)\n",
    "# simba_odour_dfs = build_agg_function_dfs('simba_clf', simba_odour_clf, 'odour', holdout_odour_dataset)\n",
    "xgb_object_dfs = build_agg_function_dfs('xgb_clf', xgb_object_clf, 'object', holdout_object_dataset)\n",
    "# simba_object_dfs = build_agg_function_dfs('simba_clf', simba_object_clf, 'object', holdout_object_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::: Processing simba-RF-precomputed;simba-RF-precomputed model ::::\n",
      "Processing: 03142021_NOB_DOT_3_upsidedown\n",
      "Processing: 03142021_NOB_DOT_5_upsidedown\n",
      "Processing: 03142021_NOB_DOT_9_upsidedown\n",
      "Processing: 03142021_NOB_IOT_11_upsidedown\n",
      "Processing: 03142021_NOB_IOT_1_upsidedown\n",
      "Processing: 03142021_NOB_IOT_7_upsidedown\n",
      "Processing: 03152021_NOB_DOT_2\n",
      "Processing: 03152021_NOB_IOT_10\n",
      "Processing: 03152021_NOB_IOT_12\n",
      "Processing: 03152021_NOB_IOT_6\n",
      "Processing: 03152021_NOB_IOT_8\n",
      "Processing: 03162021_NOB_DOT_10_upsidedown\n",
      "Processing: 03162021_NOB_DOT_4_upsidedown\n",
      "Processing: 03162021_NOB_DOT_8_upsidedown\n",
      "Processing: 03162021_NOB_IOT_12_upsidedown\n",
      "Processing: 03162021_NOB_IOT_2_upsidedown\n",
      "Processing: 03162021_NOB_IOT_6_upsidedown\n",
      "Processing: 03172021_NOB_DOT_1_upsidedown\n",
      "Processing: 03172021_NOB_DOT_5_upsidedown\n",
      "Processing: 03172021_NOB_IOT_11_upsidedown\n",
      "Processing: 03172021_NOB_IOT_3_upsidedown\n",
      "Processing: 03172021_NOB_IOT_7_upsidedown\n",
      "Processing: 03182021_NOB_DOT_1_upsidedown\n",
      "Processing: 03182021_NOB_DOT_5_upsidedown\n",
      "Processing: 03182021_NOB_DOT_9_upsidedown\n",
      "Processing: 03182021_NOB_IOT_11_upsidedown\n",
      "Processing: 03182021_NOB_IOT_3_upsidedown\n",
      "Processing: 03182021_NOB_IOT_7_upsidedown\n",
      "Processing: 03192021_NOB_DOT_12_upsidedown\n",
      "Processing: 03192021_NOB_DOT_8_upsidedown\n",
      "Processing: 03192021_NOB_IOT_10_upsidedown\n",
      "Processing: 03192021_NOB_IOT_2_upsidedown\n",
      "Processing: 03192021_NOB_IOT_5_upsidedown\n",
      "Processing: 03192021_NOB_IOT_6_upsidedown\n",
      "Processing: 03192021_NOB__DOT_4_upsidedown\n",
      "Processing: 04032021_NOB_IOT_9_upsidedown\n",
      "Processing: 08092021_NOB_DOT_Rat10\n",
      "Processing: 08092021_NOB_DOT_Rat4\n",
      "Processing: 08092021_NOB_DOT_Rat6\n",
      "Processing: 08092021_NOB_IOT_12\n",
      "Processing: 08092021_NOB_IOT_Rat2\n",
      "Processing: 08092021_NOB_IOT_Rat8\n",
      "Processing: 08102021_NOB_DOT_11\n",
      "Processing: 08102021_NOB_DOT_2\n",
      "Processing: 08102021_NOB_DOT_7\n",
      "Processing: 08102021_NOB_IOT_5\n",
      "Processing: 08102021_NOB_IOT_Rat3\n",
      "Processing: 08102021_NOB_IOT_Rat9\n",
      "Processing: 08112021_NOB_DOT_Rat3\n",
      "Processing: 08112021_NOB_DOT_Rat7\n",
      "Processing: 08112021_NOB_DOT_Rat9\n",
      "Processing: 08112021_NOB_IOT_Rat1\n",
      "Processing: 08112021_NOB_IOT_Rat11\n",
      "Processing: 08112021_NOB_IOT_Rat5\n",
      "Processing: 08122021_NOB_DOT_Rat1\n",
      "Processing: 08122021_NOB_DOT_Rat10\n",
      "Processing: 08122021_NOB_DOT_Rat6\n",
      "Processing: 08122021_NOB_IOT_Rat12\n",
      "Processing: 08122021_NOB_IOT_Rat4\n",
      "Processing: 08122021_NOB_IOT_Rat8\n",
      "Processing: 08132021_NOB_DOT_Rat10\n",
      "Processing: 08132021_NOB_DOT_Rat2\n",
      "Processing: 08132021_NOB_DOT_Rat6\n",
      "Processing: 08132021_NOB_IOT_12\n",
      "Processing: 08132021_NOB_IOT_8\n",
      "Processing: 08132021_NOB_IOT_Rat4\n",
      "Processing: 08142021_NOB_DOT_Rat11\n",
      "Processing: 08142021_NOB_DOT_Rat3\n",
      "Processing: 08142021_NOB_DOT_Rat7\n",
      "Processing: 08142021_NOB_IOT_Rat1\n",
      "Processing: 08142021_NOB_IOT_Rat5\n",
      "Processing: 08142021_NOB_IOT_Rat9\n",
      "Processing: 2022-06-11_NOB_DOT_1(upsidedown)_WC\n",
      "Processing: 2022-06-11_NOB_DOT_3(upsidedown)_WC\n",
      "Processing: 2022-06-11_NOB_DOT_5_WC\n",
      "Processing: 2022-06-11_NOB_IOT_2(upsidedown)_WC\n",
      "Processing: 2022-06-11_NOB_IOT_4_WC\n",
      "Processing: 2022-06-11_NOB_IOT_6_WC\n",
      "Processing: 2022-06-12_NOB_DOT_19_WC\n",
      "Processing: 2022-06-12_NOB_DOT_21_WC\n",
      "Processing: 2022-06-12_NOB_DOT_23_WC\n",
      "Processing: 2022-06-12_NOB_IOT_20_WC\n",
      "Processing: 2022-06-12_NOB_IOT_22_WC\n",
      "Processing: 2022-06-12_NOB_IOT_24\n",
      "Processing: 2022-06-14_NOB_DOT_2\n",
      "Processing: 2022-06-14_NOB_DOT_4\n",
      "Processing: 2022-06-14_NOB_DOT_6\n",
      "Processing: 2022-06-14_NOB_IOT_1\n",
      "Processing: 2022-06-14_NOB_IOT_3\n",
      "Processing: 2022-06-14_NOB_IOT_5\n",
      "Processing: 2022-06-15_NOB_DOT_20\n",
      "Processing: 2022-06-15_NOB_DOT_22\n",
      "Processing: 2022-06-15_NOB_DOT_24\n",
      "Processing: 2022-06-15_NOB_IOT_19\n",
      "Processing: 2022-06-15_NOB_IOT_21\n",
      "Processing: 2022-06-15_NOB_IOT_23\n",
      "Processing: 2022-06-17_NOB_DOT_1\n",
      "Processing: 2022-06-17_NOB_DOT_3\n",
      "Processing: 2022-06-17_NOB_DOT_5\n",
      "Processing: 2022-06-17_NOB_IOT_2\n",
      "Processing: 2022-06-17_NOB_IOT_4\n",
      "Processing: 2022-06-17_NOB_IOT_6\n",
      "Processing: 2022-06-18_NOB_DOT_19\n",
      "Processing: 2022-06-18_NOB_DOT_21\n",
      "Processing: 2022-06-18_NOB_DOT_23\n",
      "Processing: 2022-06-18_NOB_IOT_20\n",
      "Processing: 2022-06-18_NOB_IOT_22\n",
      "Processing: 2022-06-18_NOB_IOT_24\n",
      "Processing: 2022-06-20_NOB_DOT_2\n",
      "Processing: 2022-06-20_NOB_DOT_4\n",
      "Processing: 2022-06-20_NOB_DOT_6\n",
      "Processing: 2022-06-20_NOB_IOT_1\n",
      "Processing: 2022-06-20_NOB_IOT_3\n",
      "Processing: 2022-06-20_NOB_IOT_5\n",
      "Processing: 2022-06-21_NOB_DOT_20\n",
      "Processing: 2022-06-21_NOB_DOT_22\n",
      "Processing: 2022-06-21_NOB_DOT_24\n",
      "Processing: 2022-06-21_NOB_IOT_19\n",
      "Processing: 2022-06-21_NOB_IOT_21\n",
      "Processing: 2022-06-21_NOB_IOT_23\n",
      "Processing: 2022-06-23_NOB_DOT_1\n",
      "Processing: 2022-06-23_NOB_DOT_3\n",
      "Processing: 2022-06-23_NOB_DOT_5\n",
      "Processing: 2022-06-23_NOB_IOT_2\n",
      "Processing: 2022-06-23_NOB_IOT_4\n",
      "Processing: 2022-06-23_NOB_IOT_6\n",
      "Processing: 2022-06-24_NOB_DOT_19\n",
      "Processing: 2022-06-24_NOB_DOT_21\n",
      "Processing: 2022-06-24_NOB_DOT_23\n",
      "Processing: 2022-06-24_NOB_IOT_20\n",
      "Processing: 2022-06-24_NOB_IOT_22\n",
      "Processing: 2022-06-24_NOB_IOT_24\n",
      "Processing: 2022-06-26_NOB_DOT_2\n",
      "Processing: 2022-06-26_NOB_DOT_4\n",
      "Processing: 2022-06-26_NOB_DOT_6\n",
      "Processing: 2022-06-26_NOB_IOT_1\n",
      "Processing: 2022-06-26_NOB_IOT_3\n",
      "Processing: 2022-06-26_NOB_IOT_5\n",
      "Processing: 2022-06-27_NOB_DOT_20\n",
      "Processing: 2022-06-27_NOB_DOT_22\n",
      "Processing: 2022-06-27_NOB_DOT_24\n",
      "Processing: 2022-06-27_NOB_IOT_19\n",
      "Processing: 2022-06-27_NOB_IOT_21\n",
      "Processing: 2022-06-27_NOB_IOT_23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "simba_object_dfs = build_agg_function_dfs('simba_clf', None, 'object', simba_prelabeled_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Watch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the csv file, flatten it into a dataframe, print that dataframe out for reference, then calculate statistics.\n",
    "\n",
    "stop_watch_csv = os.path.join('hackathon', 'Iteration_2_withROI', 'models', 'holdout_stopwatch_TJO.csv')\n",
    "stop_watch_interaction_times_df = pd.read_csv(stop_watch_csv, index_col=None)\n",
    "stop_watch_interaction_times_df.rename(columns={'value':'agg_sum_total_time'}, inplace=True)\n",
    "\n",
    "del stop_watch_interaction_times_df # Not using right now, was per minute and not aggregating because Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>object</th>\n",
       "      <th>agg_sum_total_time</th>\n",
       "      <th>agg_mean_bout_duration</th>\n",
       "      <th>agg_num_interaction_bouts</th>\n",
       "      <th>approach_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08102021_DOT_Rat7_8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>1</td>\n",
       "      <td>38.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08102021_DOT_Rat7_8</td>\n",
       "      <td>2</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>1.138889</td>\n",
       "      <td>6</td>\n",
       "      <td>35.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08102021_DOT_Rat7_8</td>\n",
       "      <td>3</td>\n",
       "      <td>14.633333</td>\n",
       "      <td>2.438889</td>\n",
       "      <td>6</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08102021_DOT_Rat7_8</td>\n",
       "      <td>4</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>4</td>\n",
       "      <td>46.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08102021_DOT_Rat7_8</td>\n",
       "      <td>5</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>1.308333</td>\n",
       "      <td>4</td>\n",
       "      <td>16.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            video_name object  agg_sum_total_time  agg_mean_bout_duration  \\\n",
       "0  08102021_DOT_Rat7_8      1            1.633333                1.633333   \n",
       "1  08102021_DOT_Rat7_8      2            6.833333                1.138889   \n",
       "2  08102021_DOT_Rat7_8      3           14.633333                2.438889   \n",
       "3  08102021_DOT_Rat7_8      4            4.266667                1.066667   \n",
       "4  08102021_DOT_Rat7_8      5            5.233333                1.308333   \n",
       "\n",
       "  agg_num_interaction_bouts  approach_latency  \n",
       "0                         1         38.066667  \n",
       "1                         6         35.466667  \n",
       "2                         6          2.400000  \n",
       "3                         4         46.166667  \n",
       "4                         4         16.233333  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_odour_dfs.holdout_golden_per_video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = stop_watch_interaction_times_df.merge(\n",
    "#     xgb_object_dfs.holdout_golden_per_minute, # TODO: If you want the stop watch data... this is the easiest (haha) way to aggregate that data.. by minute\n",
    "#      on=('video_name', 'object', 'min'),\n",
    "#      suffixes=['_stopwatch', '_model'], validate='1:1')\n",
    "#     #  lsuffix='stopwatch',\n",
    "#     #  rsuffix='model')\n",
    "# full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m     videos_to_consider \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(model_dfs\u001b[39m.\u001b[39mholdout_model_per_video[video_col]) \u001b[39m&\u001b[39m \\\n\u001b[0;32m     27\u001b[0m                         \u001b[39mset\u001b[39m(model_dfs\u001b[39m.\u001b[39mholdout_golden_per_video[video_col])\n\u001b[0;32m     28\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n\u001b[1;32m---> 30\u001b[0m plot_model_vs_holdout(xgb_object_dfs)\n",
      "Cell \u001b[1;32mIn[149], line 28\u001b[0m, in \u001b[0;36mplot_model_vs_holdout\u001b[1;34m(model_dfs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_model_vs_holdout\u001b[39m(model_dfs):\n\u001b[0;32m     26\u001b[0m     videos_to_consider \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(model_dfs\u001b[39m.\u001b[39mholdout_model_per_video[video_col]) \u001b[39m&\u001b[39m \\\n\u001b[0;32m     27\u001b[0m                         \u001b[39mset\u001b[39m(model_dfs\u001b[39m.\u001b[39mholdout_golden_per_video[video_col])\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_col = 'video_name' # ????\n",
    "\n",
    "def plot_model_vs_holdout(model_dfs):\n",
    "    videos_to_consider = set(model_dfs.holdout_model_per_video[video_col]) & \\\n",
    "                        set(model_dfs.holdout_golden_per_video[video_col])\n",
    "    raise NotImplementedError()\n",
    "\n",
    "plot_model_vs_holdout(xgb_object_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_holdout_model_pivot_table, xgb_holdout_golden_pivot_table, stop_watch_interaction_times_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>object</th>\n",
       "      <th>agg_sum_total_time_model1</th>\n",
       "      <th>agg_mean_bout_duration_model1</th>\n",
       "      <th>agg_num_interaction_bouts_model1</th>\n",
       "      <th>approach_latency_model1</th>\n",
       "      <th>agg_sum_total_time_golden</th>\n",
       "      <th>agg_mean_bout_duration_golden</th>\n",
       "      <th>agg_num_interaction_bouts_golden</th>\n",
       "      <th>approach_latency_golden</th>\n",
       "      <th>latency_diffs</th>\n",
       "      <th>novel_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03142021_NOB_DOT_3_upsidedown</td>\n",
       "      <td>1</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>5</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>1</td>\n",
       "      <td>38.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03142021_NOB_DOT_3_upsidedown</td>\n",
       "      <td>2</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.384211</td>\n",
       "      <td>19</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>1.138889</td>\n",
       "      <td>6</td>\n",
       "      <td>35.466667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03142021_NOB_DOT_3_upsidedown</td>\n",
       "      <td>3</td>\n",
       "      <td>14.133333</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>25</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>14.633333</td>\n",
       "      <td>2.438889</td>\n",
       "      <td>6</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03142021_NOB_DOT_3_upsidedown</td>\n",
       "      <td>4</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>0.380556</td>\n",
       "      <td>12</td>\n",
       "      <td>46.166667</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>4</td>\n",
       "      <td>46.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03142021_NOB_DOT_3_upsidedown</td>\n",
       "      <td>5</td>\n",
       "      <td>3.633333</td>\n",
       "      <td>0.279487</td>\n",
       "      <td>13</td>\n",
       "      <td>16.466667</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>1.308333</td>\n",
       "      <td>4</td>\n",
       "      <td>16.233333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03142021_NOB_DOT_3_upsidedown</td>\n",
       "      <td>6</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>22</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>7</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-06-27_NOB_DOT_22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>22</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>8</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-06-27_NOB_DOT_22</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>18</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>2.683333</td>\n",
       "      <td>2</td>\n",
       "      <td>112.466667</td>\n",
       "      <td>-109.766667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-06-27_NOB_DOT_22</td>\n",
       "      <td>3</td>\n",
       "      <td>10.266667</td>\n",
       "      <td>1.026667</td>\n",
       "      <td>10</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>5</td>\n",
       "      <td>17.566667</td>\n",
       "      <td>-17.533333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-06-27_NOB_DOT_22</td>\n",
       "      <td>4</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>6</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>4</td>\n",
       "      <td>60.800000</td>\n",
       "      <td>-49.900000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-06-27_NOB_DOT_22</td>\n",
       "      <td>5</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>18</td>\n",
       "      <td>35.733333</td>\n",
       "      <td>10.266667</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>6</td>\n",
       "      <td>35.800000</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-06-27_NOB_DOT_22</td>\n",
       "      <td>6</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>18</td>\n",
       "      <td>24.233333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>24.166667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       video_name  object  agg_sum_total_time_model1  \\\n",
       "0   03142021_NOB_DOT_3_upsidedown       1                   1.933333   \n",
       "1   03142021_NOB_DOT_3_upsidedown       2                   7.300000   \n",
       "2   03142021_NOB_DOT_3_upsidedown       3                  14.133333   \n",
       "3   03142021_NOB_DOT_3_upsidedown       4                   4.566667   \n",
       "4   03142021_NOB_DOT_3_upsidedown       5                   3.633333   \n",
       "5   03142021_NOB_DOT_3_upsidedown       6                   8.800000   \n",
       "6           2022-06-27_NOB_DOT_22       1                   7.300000   \n",
       "7           2022-06-27_NOB_DOT_22       2                   4.500000   \n",
       "8           2022-06-27_NOB_DOT_22       3                  10.266667   \n",
       "9           2022-06-27_NOB_DOT_22       4                   6.600000   \n",
       "10          2022-06-27_NOB_DOT_22       5                   9.000000   \n",
       "11          2022-06-27_NOB_DOT_22       6                   5.933333   \n",
       "\n",
       "    agg_mean_bout_duration_model1  agg_num_interaction_bouts_model1  \\\n",
       "0                        0.386667                                 5   \n",
       "1                        0.384211                                19   \n",
       "2                        0.565333                                25   \n",
       "3                        0.380556                                12   \n",
       "4                        0.279487                                13   \n",
       "5                        0.400000                                22   \n",
       "6                        0.331818                                22   \n",
       "7                        0.250000                                18   \n",
       "8                        1.026667                                10   \n",
       "9                        1.100000                                 6   \n",
       "10                       0.500000                                18   \n",
       "11                       0.329630                                18   \n",
       "\n",
       "    approach_latency_model1  agg_sum_total_time_golden  \\\n",
       "0                 38.100000                   1.633333   \n",
       "1                 35.500000                   6.833333   \n",
       "2                  2.233333                  14.633333   \n",
       "3                 46.166667                   4.266667   \n",
       "4                 16.466667                   5.233333   \n",
       "5                  7.466667                   6.000000   \n",
       "6                  7.333333                   6.900000   \n",
       "7                  2.700000                   5.366667   \n",
       "8                  0.033333                  10.166667   \n",
       "9                 10.900000                   6.700000   \n",
       "10                35.733333                  10.266667   \n",
       "11                24.233333                   7.000000   \n",
       "\n",
       "    agg_mean_bout_duration_golden  agg_num_interaction_bouts_golden  \\\n",
       "0                        1.633333                                 1   \n",
       "1                        1.138889                                 6   \n",
       "2                        2.438889                                 6   \n",
       "3                        1.066667                                 4   \n",
       "4                        1.308333                                 4   \n",
       "5                        0.857143                                 7   \n",
       "6                        0.862500                                 8   \n",
       "7                        2.683333                                 2   \n",
       "8                        2.033333                                 5   \n",
       "9                        1.675000                                 4   \n",
       "10                       1.711111                                 6   \n",
       "11                       1.166667                                 6   \n",
       "\n",
       "    approach_latency_golden  latency_diffs  novel_object  \n",
       "0                 38.066667       0.033333             4  \n",
       "1                 35.466667       0.033333             4  \n",
       "2                  2.400000      -0.166667             4  \n",
       "3                 46.166667       0.000000             4  \n",
       "4                 16.233333       0.233333             4  \n",
       "5                  7.300000       0.166667             4  \n",
       "6                  7.500000      -0.166667             2  \n",
       "7                112.466667    -109.766667             2  \n",
       "8                 17.566667     -17.533333             2  \n",
       "9                 60.800000     -49.900000             2  \n",
       "10                35.800000      -0.066667             2  \n",
       "11                24.166667       0.066667             2  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_m_df = xgb_odour_dfs.holdout_model_per_video\n",
    "_g_df = xgb_odour_dfs.holdout_golden_per_video\n",
    "\n",
    "agg_label = 'approach_latency'\n",
    "model_suffix = '_model1'\n",
    "golden_suffix = '_golden'\n",
    "_df = _m_df.merge(_g_df, on=['video_name', 'object'], suffixes=[model_suffix, golden_suffix])\n",
    "\n",
    "_df['latency_diffs'] = _df[agg_label + model_suffix] - _df[agg_label + golden_suffix]\n",
    "_df\n",
    "\n",
    "# Load novel labels csv\n",
    "novel_labels_df = pd.read_csv(os.path.join('hackathon', 'OBJ-novelposition.csv'))\n",
    "# TODO: Verify video names are the same\n",
    "\n",
    "# TODO: Map old video names => new video names in _df, so they match novel_labels\n",
    "_temp_name_map_df = pd.DataFrame(\n",
    "    {\n",
    "        'new': ['03142021_NOB_DOT_3_upsidedown', '2022-06-27_NOB_DOT_22'],\n",
    "        'old': ['08102021_DOT_Rat7_8', '2022-06-12_NOD_DOT_17'],\n",
    "    }\n",
    "    )\n",
    "\n",
    "_df = _df.replace(dict(zip(_temp_name_map_df.old, _temp_name_map_df.new)))\n",
    "\n",
    "_df = _df.merge(novel_labels_df, on='video_name')\n",
    "_df\n",
    "\n",
    "# NEXT: Group by video, take only where novel object = (the one from the csv)\n",
    "#       OR: left_join, then take where the two columns are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51fdd72c8e74e125f597ef5451e2ab80bdf6a3c052618ab754f2f9443adc0a9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
