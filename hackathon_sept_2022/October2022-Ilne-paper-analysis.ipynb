{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT: Comparing ML model (built in or same as Simba) interaction times to gold standard holdout set and stopwatch human data\n",
    "\n",
    "NOTE: \"score\" will refer to binary f1, precision, and/or recall.  Relative to the target class, \"Interaction\".\n",
    "\n",
    "Goal:  \n",
    "- Build a classifier based on the same procedure as Simba.  \n",
    "- Score via per-video cross validation during training, to estimate the generalization accuracy for unseen videos.\n",
    "- Score at each step of processing:\n",
    "    - Building the classifier\n",
    "    - min_bought_duratin post processing\n",
    "    - Kleinburg Filtering post processing\n",
    "- Compare to stop watched labelled human data.\n",
    "- Analyze the distribution of errors relative to each individual object, each treatment class, and each rat.\n",
    "    - Ideally the errors will have no bias and be zero mean Guassian across each categorical split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import glob\n",
    "import os\n",
    "import functools\n",
    "\n",
    "## Dataset class to encapsulate opening files and creating cv_indexes required for running cross_validation in sklearn\n",
    "## on a per video basis.  We will also encapsulate handling individual Dataframes per video vs. one large Dataframe\n",
    "## with all the videos.  The large Dataframe\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "PartialResults = namedtuple(\n",
    "    'PartialResults',\n",
    "    'precision recall f1 c_mat')\n",
    "# TODO: FullResults appears to be unused!\n",
    "FullResults = namedtuple(\n",
    "    'FullResults',\n",
    "    'model test_results train_results total_time')\n",
    "\n",
    "def build_partial_result(y_true, y_pred):\n",
    "    try:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    except:\n",
    "        # must be multi class\n",
    "        classes = sorted(x for x in numpy.unique(y_true) if x != 0) # Exclude the majority class\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=classes, average='weighted')\n",
    "    # precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    c_mat = confusion_matrix(y_true, y_pred)\n",
    "    return PartialResults(precision, recall, f1, c_mat)\n",
    "\n",
    "class ModelResultLabels(object):\n",
    "    \"\"\" Another data class for holding results \"\"\"\n",
    "    def __init__(self, func, y_binary, y_multi, y_prob, binary_results, multi_label_results):\n",
    "        self._func = func # just in case, will use name for printing\n",
    "        self.y_binary = y_binary\n",
    "        self.y_multi = y_multi\n",
    "        self.y_prob = y_prob # Probability will always be relative to the binary labels.\n",
    "        self.binary_results: PartialResults = binary_results\n",
    "        self.multi_label_results: PartialResults = multi_label_results\n",
    "\n",
    "class PerVideoDataClass(object):\n",
    "    \"\"\" The Dataset class will aggregate 1 instance of this class for each video it manages. \"\"\"\n",
    "    def __init__(self, file_path, df, x_extractor, y_binary_label_extractor, y_multi_label_extractor):\n",
    "        self.file_path = file_path # just in case\n",
    "        self.video_name = os.path.splitext(os.path.basename(file_path))[0] # the video name contains meta data about animal and treatment group etc.\n",
    "        # self.video_metadata = VideoMetadata.from_name(self.video_name)\n",
    "        self.video_metadata = None # TODO: Put the meta-data on the per video class??\n",
    "        self.X = x_extractor(df)\n",
    "        self.y_binary = y_binary_label_extractor(df) # The test labels.\n",
    "        self.y_multi = y_multi_label_extractor(df, self.y_binary)\n",
    "        self._y_multi_label_extractor = functools.partial(y_multi_label_extractor, df) # need for later, the rest can go.\n",
    "        from collections import OrderedDict, defaultdict\n",
    "        # Dictionary with keys being classifier descriptions (tuples, or other hashable types that describe your classifier),\n",
    "        # and values being ordered dictionaries.\n",
    "        self.model_result_labels = defaultdict(OrderedDict)\n",
    "    \n",
    "    def apply_and_record_postprocessing_step(self, classifier_desc, func, y_binary, y_prob=None):\n",
    "        \"\"\" Func was used to produce y_binary, we record the results for analysis later. \"\"\"\n",
    "        if callable(func):\n",
    "            step_key = func.__name__\n",
    "        else:\n",
    "            step_key = func.__class__.__name__\n",
    "        y_multi = self._y_multi_label_extractor(y_binary)\n",
    "        self.model_result_labels[classifier_desc][step_key] = ModelResultLabels(\n",
    "            func, y_binary, y_multi, y_prob, \n",
    "            build_partial_result(self.y_binary, y_binary),\n",
    "            build_partial_result(self.y_multi, y_multi))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'''\n",
    "        Video name: {self.video_name}\n",
    "        Results stored: {self.model_result_labels.keys()}\n",
    "        '''\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, per_video_data_classes):\n",
    "        self.per_video_data_classes = per_video_data_classes\n",
    "\n",
    "    @classmethod\n",
    "    def from_scratch(cls, input_files, x_extractor, y_binary_label_extractor, y_multi_label_extractor):\n",
    "        # assert isinstance(input_files, list)\n",
    "        dfs = [pd.read_csv(f, index_col=0) for f in input_files]\n",
    "        # self._original_dfs = dfs # Just in case\n",
    "        per_video_data_classes = [\n",
    "            PerVideoDataClass(\n",
    "                file_path,\n",
    "                df, \n",
    "                x_extractor=x_extractor,\n",
    "                y_binary_label_extractor=y_binary_label_extractor,\n",
    "                y_multi_label_extractor=y_multi_label_extractor)\n",
    "            for file_path, df in zip(input_files, dfs)\n",
    "        ]\n",
    "        return cls(per_video_data_classes)\n",
    "\n",
    "    @property\n",
    "    def data_files(self):\n",
    "        return [per_video_data.file_path for per_video_data in self.per_video_data_classes]\n",
    "\n",
    "    def __str__(self):\n",
    "        files_str = '\\n\\t'.join(self.data_files)\n",
    "        paths_str = f'Data files: {files_str}'\n",
    "        return f'{self.__class__.__name__}:\\n' \\\n",
    "               f'Number of files: {len(self.data_files)}\\n' \\\n",
    "               f'Paths: {paths_str}'\n",
    "\n",
    "## Pre Processing:\n",
    "## All we need to do is select the desired input features, and the target columns\n",
    "\n",
    "## Define specific extraction methods.\n",
    "def build_Y_get_interaction(col='Interaction'):\n",
    "    \"\"\" For the objects datasets \"\"\"\n",
    "    def Y_get_interaction(df: pd.DataFrame):\n",
    "        ys = df[col]\n",
    "        ys = ys.fillna(value=0.0)\n",
    "        return ys.values\n",
    "    return Y_get_interaction\n",
    "\n",
    "\n",
    "def build_Y_get_multi_label(distance_features):\n",
    "    def Y_get_multi_label(df, ys_binary):\n",
    "        # +1 Because column_0 ==>  Object_1\n",
    "        nearest_obj = df[distance_features].values.argmin(axis=1) + 1\n",
    "        return nearest_obj * ys_binary\n",
    "    return Y_get_multi_label\n",
    "\n",
    "# x extractors\n",
    "def build_X_extractor(input_features):\n",
    "    def X_extractor(df):\n",
    "        # input_features should be a set of columns known to be in the Dataframe.\n",
    "        return df[input_features]\n",
    "    return X_extractor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI_features: ['Stimulus 1 Animal_1 distance', 'Stimulus 2 Animal_1 distance', 'Stimulus 3 Animal_1 distance', 'Stimulus 4 Animal_1 distance', 'Stimulus 5 Animal_1 distance', 'Stimulus 6 Animal_1 distance']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interaction_features = [\n",
    "    'Interaction',\n",
    "    'Probability_Interaction'\n",
    "]\n",
    "\n",
    "raw_dlc_features_only = [\n",
    "    \"Ear_left_p\",\n",
    "    \"Ear_left_x\",\n",
    "    \"Ear_left_y\",\n",
    "\n",
    "    \"Ear_right_p\",\n",
    "    \"Ear_right_x\",\n",
    "    \"Ear_right_y\",\n",
    "\n",
    "    \"Lat_left_p\",\n",
    "    \"Lat_left_x\",\n",
    "    \"Lat_left_y\",\n",
    "\n",
    "    \"Lat_right_p\",\n",
    "    \"Lat_right_x\",\n",
    "    \"Lat_right_y\",\n",
    "\n",
    "    \"Center_p\",\n",
    "    \"Center_x\",\n",
    "    \"Center_y\",\n",
    "\n",
    "    \"Nose_p\",\n",
    "    \"Nose_x\",\n",
    "    \"Nose_y\",\n",
    "\n",
    "    \"Tail_base_p\",\n",
    "    \"Tail_base_x\",\n",
    "    \"Tail_base_y\",\n",
    "\n",
    "    \"Tail_end_x\",\n",
    "    \"Tail_end_y\",\n",
    "    \"Tail_end_p\",\n",
    "]\n",
    "\n",
    "## Load the data.  Pre engineered features created in Simba with Region of Interest (ROI) data included.\n",
    "## ROI data is centered on each of 6 objects of interest.\n",
    "training_simba_csv_files = glob.glob(\n",
    "    os.path.join('hackathon', 'Iteration_2_withROI', 'targets_inserted', '*.csv'))\n",
    "holdout_simba_csv_files = glob.glob(\n",
    "    os.path.join('hackathon', 'Iteration_2_withROI', 'hold_dataset', '*.csv'))\n",
    "\n",
    "# # TEMP: Only 1 each for now while coding\n",
    "# training_simba_csv_files = training_simba_csv_files[0:2]\n",
    "# holdout_simba_csv_files = holdout_simba_csv_files[0:2]\n",
    "\n",
    "# temporary Dataframe so we can read the columns.\n",
    "temp_df = pd.read_csv(training_simba_csv_files[0], index_col=0)\n",
    "\n",
    "exclude_columns = interaction_features + raw_dlc_features_only\n",
    "input_features = [col for col in temp_df.columns if col not in exclude_columns]\n",
    "x_extractor = build_X_extractor(input_features)\n",
    "y_binary_label_extractor = build_Y_get_interaction(col='Interaction')\n",
    "\n",
    "import re\n",
    "distance_re = re.compile(r'^Stimulus [0-9] Animal_[0-9]+ distance$')\n",
    "# \n",
    "distance_features = [col for col in temp_df.columns if distance_re.match(col)]\n",
    "print('ROI_features:', distance_features)\n",
    "y_multi_label_extractor = build_Y_get_multi_label(distance_features)\n",
    "\n",
    "# def apply_and_record_postprocessing_step(self, func, y_binary): # Don't forget to use this later\n",
    "\n",
    "training_dataset = Dataset.from_scratch(training_simba_csv_files, x_extractor, y_binary_label_extractor, y_multi_label_extractor)\n",
    "# We don't make cv indexes for the holdout set because we will only be using this to verify\n",
    "# model performance on unseen videos.\n",
    "holdout_dataset = Dataset.from_scratch(holdout_simba_csv_files, x_extractor, y_binary_label_extractor, y_multi_label_extractor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Rat ID Stimuli Type Task Variation  Novel ID\n",
      "File Name                                                           \n",
      "08_11_2021_DOT_Rat7_8        7        Odour            DOT       NaN\n",
      "08_12_2021_IOT_Rat3_4        3        Odour            IOT       NaN\n",
      "08_13_2021_DOT_Rat9_10       9        Odour            DOT       NaN\n",
      "08_14_2021_DOT_Rat7_8        8        Odour            DOT       NaN\n",
      "2022-06-11_NOD_DOT_9         9        Odour            DOT       NaN\n",
      "Generated from video name: \n",
      "        Video Name: 2022-06-26_NOB_IOT_5\n",
      "        Rat ID: 5\n",
      "        Stimuli Type: Object\n",
      "        Task Variation: IOT\n",
      "        Treatment: None\n",
      "        Novel ID: None\n",
      "        Date (of recording): 2022-06-26\n",
      "        Extra (notes): None\n",
      "        \n",
      "Training object dataset: Dataset:\n",
      "Number of files: 10\n",
      "Paths: Data files: hackathon\\Iteration_2_withROI\\targets_inserted\\08092021_DOT_Rat9_10(2).csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08102021_DOT_Rat11_12.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08102021_DOT_Rat7_8(2).csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-20_NOB_DOT_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-21_NOB_DOT_22.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-21_NOB_IOT_23.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-24_NOB_IOT_22.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-26_NOB_DOT_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-26_NOB_IOT_1.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-26_NOB_IOT_5.csv\n",
      "Holdout object dataset: Dataset:\n",
      "Number of files: 3\n",
      "Paths: Data files: hackathon\\Iteration_2_withROI\\hold_dataset\\08092021_IOT_Rat7_8.csv\n",
      "\thackathon\\Iteration_2_withROI\\hold_dataset\\2022-06-23_NOB_IOT_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\hold_dataset\\2022-06-26_NOB_DOT_6.csv\n",
      "Training odour dataset: Dataset:\n",
      "Number of files: 12\n",
      "Paths: Data files: hackathon\\Iteration_2_withROI\\targets_inserted\\08092021_DOT_Rat9_10.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08092021_IOT_Rat11_12.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08102021_IOT_Rat3_4(2).csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08102021_IOT_Rat3_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_11_2021_DOT_Rat7_8.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_12_2021_IOT_Rat3_4.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_13_2021_DOT_Rat9_10.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\08_14_2021_DOT_Rat7_8.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-11_NOD_DOT_11.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-11_NOD_DOT_9.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-11_NOD_IOT_12.csv\n",
      "\thackathon\\Iteration_2_withROI\\targets_inserted\\2022-06-12_NOD_IOT_14.csv\n",
      "Holdout odour dataset: Dataset:\n",
      "Number of files: 3\n",
      "Paths: Data files: hackathon\\Iteration_2_withROI\\hold_dataset\\08102021_DOT_Rat7_8.csv\n",
      "\thackathon\\Iteration_2_withROI\\hold_dataset\\08122021_IOT_Rat11_12.csv\n",
      "\thackathon\\Iteration_2_withROI\\hold_dataset\\2022-06-12_NOD_DOT_17.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Load the unlabeled set?\n",
    "# TODO: Load and record the video meta-data for each\n",
    "\n",
    "class VideoMetadata(object):\n",
    "    def __init__(self, video_name, *, rat_id, stimuli_type, task_variation, treatment, novel_id, date, extra):\n",
    "        # TODO: Video stub name? Or with extension? A path ever??\n",
    "        # 'phase' == 'task_variation'\n",
    "        self.video_name = video_name\n",
    "        self.rat_id = rat_id\n",
    "        self.stimuli_type = stimuli_type\n",
    "        self.task_variation = task_variation\n",
    "        self.treatment = treatment\n",
    "        self.novel_id = novel_id\n",
    "        self.date = date\n",
    "        self.extra = extra\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'''\n",
    "        Video Name: {self.video_name}\n",
    "        Rat ID: {self.rat_id}\n",
    "        Stimuli Type: {self.stimuli_type}\n",
    "        Task Variation: {self.task_variation}\n",
    "        Treatment: {self.treatment}\n",
    "        Novel ID: {self.novel_id}\n",
    "        Date (of recording): {self.date}\n",
    "        Extra (notes): {self.extra}\n",
    "        '''\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, video_name):\n",
    "        # ex: 2022-06-11_NOD_DOT_9\n",
    "        nod_nob_to_stimuli_type = {\n",
    "            'NOD': 'Odour',\n",
    "            'NOB': 'Object'\n",
    "        }\n",
    "        date, raw_NOD_NOB, task_variation, rat_id = video_name.split('_')\n",
    "        stimuli_type = nod_nob_to_stimuli_type[raw_NOD_NOB] # If this errors out, name is malformed\n",
    "        # Treatment is unknown... unless we get a rat_id -> treatment mapping...\n",
    "        # Extra is not present from name alone...\n",
    "        # Don't know what novel id is from video name alone...\n",
    "        return cls(video_name, rat_id=rat_id, stimuli_type=stimuli_type,\n",
    "                    task_variation=task_variation, treatment=None, novel_id=None, date=date, extra=None)\n",
    "\n",
    "\n",
    "video_metadata_csv = os.path.join('hackathon', 'Iteration_2_withROI', 'trainingset_key.csv')\n",
    "## TODO: Does this key have metadata for all the videos? Training set? Holdout set?\n",
    "video_metadata_df = pd.read_csv(video_metadata_csv, index_col='File Name')\n",
    "print(video_metadata_df.head())\n",
    "\n",
    "def populate_video_metadata(dataset):\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        try:\n",
    "            row = video_metadata_df.loc[per_video_data.video_name]\n",
    "            rat_id = row['Rat ID']\n",
    "            stimuli_type = row['Stimuli Type']\n",
    "            task_variation = row['Task Variation']\n",
    "            novel_id = row['Novel ID']\n",
    "            per_video_data.video_metadata = VideoMetadata(\n",
    "                video_name=per_video_data.video_name,\n",
    "                rat_id=rat_id,\n",
    "                stimuli_type=stimuli_type,\n",
    "                novel_id=novel_id,\n",
    "                task_variation=task_variation,\n",
    "                treatment=None,\n",
    "                date=None,\n",
    "                extra=None\n",
    "                )\n",
    "\n",
    "        except KeyError:\n",
    "            video_metadata = VideoMetadata.from_name(per_video_data.video_name)\n",
    "            print('Generated from video name:', video_metadata)\n",
    "            per_video_data.video_metadata = video_metadata\n",
    "\n",
    "populate_video_metadata(training_dataset)\n",
    "populate_video_metadata(holdout_dataset)\n",
    "\n",
    "training_odour_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in training_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Odour'])\n",
    "training_object_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in training_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Object'])\n",
    "\n",
    "holdout_odour_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in holdout_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Odour'])\n",
    "holdout_object_dataset = Dataset(\n",
    "    [per_video_data for per_video_data in holdout_dataset.per_video_data_classes \n",
    "     if per_video_data.video_metadata.stimuli_type == 'Object'])\n",
    "\n",
    "\n",
    "training_combined_dataset = training_dataset # Only required for training xgb combined\n",
    "# holdout_combined_dataset = holdout_dataset # Not required\n",
    "\n",
    "print(f'Training object dataset: {training_object_dataset}')\n",
    "print(f'Holdout object dataset: {holdout_object_dataset}')\n",
    "print(f'Training odour dataset: {training_odour_dataset}')\n",
    "print(f'Holdout odour dataset: {holdout_odour_dataset}')\n",
    "\n",
    "\n",
    "del training_dataset\n",
    "del holdout_dataset # LOL; Risky\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "Okay, data is loaded, features and labels extracted and stored in two Dataset objects.\n",
    "No we are ready to fit a model, and get some performance metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting new xgb model...\n",
      "Sample weight applied to positive class: 3.8895560797769675\n",
      "Fitting new xgb model...\n",
      "Sample weight applied to positive class: 4.09393063583815\n",
      "Fitting new xgb model...\n",
      "Sample weight applied to positive class: 4.1051296735662275\n",
      "Loading model from: hackathon\\Iteration_2_withROI\\models\\object\\Interaction.sav\n",
      "Loading model from: hackathon\\Iteration_2_withROI\\models\\odour\\Interaction.sav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# From a previous GridSearchCV:\n",
    "# \n",
    "# Finished training model; best_score: 0.4699529225702816; \n",
    "# best_estimator: XGBClassifier(base_score=0.5, booster='gbtree', gamma=0.0,\n",
    "#               grow_policy='lossguide', interaction_constraints=None,\n",
    "#               learning_rate=0.3, max_delta_step=1, max_depth=4,\n",
    "#               min_child_weight=0, missing=None, n_estimators=300, n_jobs=14,\n",
    "#               nthread=None, num_parallel_tree=1, objective='binary:logistic',\n",
    "#               random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "#               sampling_method='gradient_based',\n",
    "#               scale_pos_weight=4.296046179280971, seed=None, silent=None,\n",
    "#               subsample=0.5, tree_method='gpu_hist', verbosity=1)\n",
    "# Best grid search params: {'gamma': 0.0, 'learning_rate': 0.3, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 300, 'scale_pos_weight': 4.296046179280971}\n",
    "#\n",
    "# NOTE: scale_pos_weight will be fit with a bit of a trick for xgboost, based on the frequency of labels\n",
    "#       in the input dataset.\n",
    "\n",
    "\n",
    "# 1. Get all training Xs and ys from the dataset.  Use proportion in ys to set scale_pos_weight\n",
    "\n",
    "def train_xgb(dataset: Dataset, classifier_desc):\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        Xs.append(per_video_data.X)\n",
    "        ys.append(per_video_data.y_binary) # use binary ys for training and predictions.\n",
    "\n",
    "    Xs = pd.concat(Xs)\n",
    "    # Xs = numpy.vstack(Xs)\n",
    "    ys = numpy.hstack(ys)\n",
    "    print('Fitting new xgb model...')\n",
    "    new_scale_pos_weights = (ys == 0).sum() / (ys >= 1).sum()\n",
    "    print('Sample weight applied to positive class:', new_scale_pos_weights)\n",
    "    xgb_clf = XGBClassifier(base_score=0.5, booster='gbtree', gamma=0.0,\n",
    "                  grow_policy='lossguide', learning_rate=0.3, max_delta_step=1, max_depth=4,\n",
    "                  min_child_weight=0, missing=0, n_estimators=300, n_jobs=14,\n",
    "                  objective='binary:logistic',\n",
    "                  # objective='binary:logitraw',\n",
    "                  random_state=42, sampling_method='gradient_based',\n",
    "                  scale_pos_weight=new_scale_pos_weights, seed=42, silent=None,\n",
    "                  subsample=0.5, tree_method='gpu_hist', verbosity=1)\n",
    "    xgb_clf.fit(Xs, ys)\n",
    "    xgb_clf._classifier_desc = classifier_desc\n",
    "    return xgb_clf\n",
    "\n",
    "xgb_odour_clf = train_xgb(training_odour_dataset, 'XGBClassifier_odour')\n",
    "xgb_object_clf = train_xgb(training_object_dataset, 'XGBClassifier_object')\n",
    "xgb_combined_clf = train_xgb(training_combined_dataset, 'XGBClassifier_combined')\n",
    "# If a path is provided we load a model file from disk, otherwise we fit a new one.\n",
    "# model_path = 'TEMP_DecisionTreeModel_for_notebook.pkl' # Put path to your model here\n",
    "object_simba_model_path = os.path.join('hackathon', 'Iteration_2_withROI', 'models', 'object', 'Interaction.sav')\n",
    "odour_simba_model_path = os.path.join('hackathon', 'Iteration_2_withROI', 'models', 'odour', 'Interaction.sav')\n",
    "\n",
    "import pickle\n",
    "if object_simba_model_path and os.path.isfile(object_simba_model_path):\n",
    "  print(f'Loading model from: {object_simba_model_path}')\n",
    "  with open(object_simba_model_path, 'rb') as f:\n",
    "    simba_object_clf = pickle.load(f)\n",
    "if odour_simba_model_path and os.path.isfile(odour_simba_model_path):\n",
    "  print(f'Loading model from: {odour_simba_model_path}')\n",
    "  with open(odour_simba_model_path, 'rb') as f:\n",
    "    simba_odour_clf = pickle.load(f)\n",
    "else:\n",
    "  pass\n",
    "  ## Had a bug?\n",
    "  # simba_clf = RandomForestClassifier(\n",
    "  #               n_estimators=200,\n",
    "  #               bootstrap=True,\n",
    "  #               verbose=0, # 1 if you want to see jobs etc\n",
    "  #               n_jobs=-1,\n",
    "  #               criterion='entropy',  # Gini is standard, shouldn't be a huge factor\n",
    "  #               min_samples_leaf=2,\n",
    "  #               max_features='sqrt',\n",
    "  #               # max_depth=15,  # LIMIT MAX DEPTH!!  Runtime AND generalization error should improve drastically\n",
    "  #               random_state=42,\n",
    "  #               #     ccp_alpha=0.005, # NEW PARAMETER, I NEED TO DEFINE MY EXPERIMENT SETUPS BETTER, AND STORE SOME RESULTS!!\n",
    "  #               # Probably need to whip up a database again, that's the only way I have been able to navigate this in the past\n",
    "  #               # Alternatively I could very carefully define my experiments, and then run them all in a batch and create a\n",
    "  #               # meaningful report.  This is probably the best way to proceed.  It will lead to the most robust iteration\n",
    "  #               # and progress.\n",
    "  #               ## NEW: Turning this on rather than under/over sampling.\n",
    "  #               class_weight='balanced',  # balance weights at nodes based on class frequencies\n",
    "  #             )\n",
    "  # dt_clf.fit(Xs, ys)\n",
    "  # if model_path:\n",
    "    # with open(model_path, 'wb') as f:\n",
    "      # pickle.dump(clf, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Always fit xgb classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Results and Apply Post Processing\n",
    "Now we have a trained model.  We're going to define some post-processing functions that match what is provided in Simba and then record the results at each step (classifier labels, labels after min_bought_duration smoothing, \n",
    "and labels after Kleinburg Filtering).  Then we will calculate classifier performance at each of these steps.\n",
    "Finally we will calculate total interaction times for each video, then aggregate the results per animal, per treatment group, and per object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min bought duration in frames: 3\n",
      "AARONT: k-filtering bouts (head): [[0 221 5328]\n",
      " [1 221 230]\n",
      " [1.0 339 362]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 384 7118]\n",
      " [1 384 417]\n",
      " [2 384 417]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_IOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 217 6978]\n",
      " [1 217 224]\n",
      " [1.0 314 336]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5371]\n",
      " [1 0 28]\n",
      " [2 0 28]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 42 5386]\n",
      " [1 42 187]\n",
      " [2 42 68]]\n",
      "Recorded data for: \n",
      "        Video name: 08_11_2021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 226 5265]\n",
      " [1 226 284]\n",
      " [2 226 259]]\n",
      "Recorded data for: \n",
      "        Video name: 08_12_2021_IOT_Rat3_4\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 111 5298]\n",
      " [1 111 157]\n",
      " [2 111 157]]\n",
      "Recorded data for: \n",
      "        Video name: 08_13_2021_DOT_Rat9_10\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 74 5399]\n",
      " [1 74 109]\n",
      " [1.0 151 162]]\n",
      "Recorded data for: \n",
      "        Video name: 08_14_2021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5399]\n",
      " [1 0 76]\n",
      " [2 0 76]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 6 5348]\n",
      " [1 6 36]\n",
      " [2 6 36]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_9\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5391]\n",
      " [1.0 70 87]\n",
      " [1.0 176 226]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_IOT_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5100]\n",
      " [1.0 45 67]\n",
      " [2.0 45 67]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_IOT_14\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 79 5071]\n",
      " [1 79 136]\n",
      " [2 79 136]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 50 4431]\n",
      " [1 50 69]\n",
      " [2 50 69]]\n",
      "Recorded data for: \n",
      "        Video name: 08122021_IOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 1 5291]\n",
      " [1 1 19]\n",
      " [2 1 19]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_DOT_17\n",
      "        Results stored: dict_keys(['XGBClassifier_odour'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 91 7113]\n",
      " [1 91 101]\n",
      " [2 91 101]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 72 7126]\n",
      " [1 72 82]\n",
      " [1.0 127 178]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 164 7199]\n",
      " [1 164 231]\n",
      " [2 164 231]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 18 8636]\n",
      " [1 18 32]\n",
      " [2 18 32]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-20_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 72 8943]\n",
      " [1 72 81]\n",
      " [1.0 142 327]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_DOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 12 8712]\n",
      " [1 12 32]\n",
      " [2 12 32]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_IOT_23\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 15 8844]\n",
      " [1 15 37]\n",
      " [2 15 37]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-24_NOB_IOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 11 8024]\n",
      " [1 11 19]\n",
      " [1.0 47 55]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 46 8881]\n",
      " [1 46 58]\n",
      " [2 46 58]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_1\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 23 8898]\n",
      " [1 23 34]\n",
      " [1.0 99 105]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_5\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 41 6906]\n",
      " [1 41 74]\n",
      " [1.0 324 449]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_IOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 18 8854]\n",
      " [1 18 29]\n",
      " [1.0 66 80]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-23_NOB_IOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 39 8812]\n",
      " [1 39 166]\n",
      " [2 39 142]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_6\n",
      "        Results stored: dict_keys(['XGBClassifier_object'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 32 5329]\n",
      " [1.0 82 97]\n",
      " [1.0 221 233]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 383 7117]\n",
      " [1 383 413]\n",
      " [2 383 413]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_IOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 215 7010]\n",
      " [1 215 223]\n",
      " [1.0 311 337]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 1 5376]\n",
      " [1 1 28]\n",
      " [2 1 28]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 42 5394]\n",
      " [1 42 187]\n",
      " [2.0 75 187]]\n",
      "Recorded data for: \n",
      "        Video name: 08_11_2021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 227 5267]\n",
      " [1 227 287]\n",
      " [2 227 260]]\n",
      "Recorded data for: \n",
      "        Video name: 08_12_2021_IOT_Rat3_4\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 107 5299]\n",
      " [1 107 157]\n",
      " [2 107 157]]\n",
      "Recorded data for: \n",
      "        Video name: 08_13_2021_DOT_Rat9_10\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 73 5399]\n",
      " [1 73 111]\n",
      " [1.0 151 174]]\n",
      "Recorded data for: \n",
      "        Video name: 08_14_2021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5399]\n",
      " [1 0 76]\n",
      " [2 0 76]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 7 5348]\n",
      " [1 7 42]\n",
      " [2 7 42]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_9\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5392]\n",
      " [1.0 69 87]\n",
      " [1.0 176 227]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_IOT_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5098]\n",
      " [1.0 45 67]\n",
      " [2.0 45 67]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_IOT_14\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 48 5071]\n",
      " [1 48 126]\n",
      " [2 48 126]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 48 4434]\n",
      " [1 48 70]\n",
      " [2 48 70]]\n",
      "Recorded data for: \n",
      "        Video name: 08122021_IOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 0 5301]\n",
      " [1 0 25]\n",
      " [1.0 78 88]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_DOT_17\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 91 7112]\n",
      " [1 91 120]\n",
      " [2 91 102]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 55 7129]\n",
      " [1.0 70 81]\n",
      " [1.0 126 177]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 154 7199]\n",
      " [1 154 231]\n",
      " [1.0 357 368]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 19 8641]\n",
      " [1 19 32]\n",
      " [2 19 32]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-20_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 71 8947]\n",
      " [1 71 81]\n",
      " [1.0 142 328]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_DOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 12 8714]\n",
      " [1 12 34]\n",
      " [2 12 34]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_IOT_23\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 14 8929]\n",
      " [1 14 38]\n",
      " [2 14 38]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-24_NOB_IOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 11 8852]\n",
      " [1 11 19]\n",
      " [1.0 47 54]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 46 8883]\n",
      " [1 46 60]\n",
      " [2 46 60]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_1\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 23 8900]\n",
      " [1 23 36]\n",
      " [1.0 135 142]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_5\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 25 7130]\n",
      " [1 25 70]\n",
      " [2 25 70]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_IOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 18 8857]\n",
      " [1 18 29]\n",
      " [1.0 65 81]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-23_NOB_IOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n",
      "AARONT: k-filtering bouts (head): [[0 38 8812]\n",
      " [1 38 140]\n",
      " [2 38 140]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_6\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 90 5328]\n",
      " [1.0 221 227]\n",
      " [1.0 339 362]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 383 7116]\n",
      " [1 383 413]\n",
      " [2 383 413]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_IOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 218 6977]\n",
      " [1 218 223]\n",
      " [1.0 316 336]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 2 5371]\n",
      " [1 2 27]\n",
      " [2 2 27]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_IOT_Rat3_4\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 42 5386]\n",
      " [1 42 187]\n",
      " [2 42 69]]\n",
      "Recorded data for: \n",
      "        Video name: 08_11_2021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 228 5265]\n",
      " [1 228 284]\n",
      " [2 228 259]]\n",
      "Recorded data for: \n",
      "        Video name: 08_12_2021_IOT_Rat3_4\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 114 5296]\n",
      " [1 114 156]\n",
      " [2 114 156]]\n",
      "Recorded data for: \n",
      "        Video name: 08_13_2021_DOT_Rat9_10\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 74 5399]\n",
      " [1 74 109]\n",
      " [2 74 109]]\n",
      "Recorded data for: \n",
      "        Video name: 08_14_2021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 0 5399]\n",
      " [1 0 76]\n",
      " [2 0 76]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_11\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 7 5348]\n",
      " [1 7 36]\n",
      " [2 7 36]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_DOT_9\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 0 5391]\n",
      " [1.0 70 87]\n",
      " [1.0 177 226]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-11_NOD_IOT_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 45 5100]\n",
      " [1 45 67]\n",
      " [2 45 67]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_IOT_14\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 67 5060]\n",
      " [1 67 134]\n",
      " [2 67 134]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 50 4431]\n",
      " [1 50 134]\n",
      " [2 50 70]]\n",
      "Recorded data for: \n",
      "        Video name: 08122021_IOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 2 5292]\n",
      " [1 2 8]\n",
      " [1.0 221 245]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-12_NOD_DOT_17\n",
      "        Results stored: dict_keys(['XGBClassifier_odour', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 91 7110]\n",
      " [1 91 101]\n",
      " [2 91 101]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_DOT_Rat9_10(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 72 7122]\n",
      " [1 72 79]\n",
      " [1.0 129 150]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat11_12\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 169 7199]\n",
      " [1 169 231]\n",
      " [2 169 231]]\n",
      "Recorded data for: \n",
      "        Video name: 08102021_DOT_Rat7_8(2)\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 20 8634]\n",
      " [1 20 31]\n",
      " [2 20 31]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-20_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 74 8943]\n",
      " [1 74 81]\n",
      " [1.0 144 325]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_DOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 12 8710]\n",
      " [1 12 32]\n",
      " [2 12 32]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-21_NOB_IOT_23\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 16 8918]\n",
      " [1 16 36]\n",
      " [2 16 36]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-24_NOB_IOT_22\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 11 8024]\n",
      " [1 11 18]\n",
      " [1.0 48 54]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 47 8878]\n",
      " [1 47 57]\n",
      " [2 47 57]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_1\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 25 8897]\n",
      " [1 25 34]\n",
      " [2 25 34]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_IOT_5\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 26 6904]\n",
      " [1 26 41]\n",
      " [2 26 41]]\n",
      "Recorded data for: \n",
      "        Video name: 08092021_IOT_Rat7_8\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 20 8734]\n",
      " [1 20 28]\n",
      " [2 20 28]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-23_NOB_IOT_4\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "c:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AARONT: k-filtering bouts (head): [[0 41 8812]\n",
      " [1 41 166]\n",
      " [2 41 139]]\n",
      "Recorded data for: \n",
      "        Video name: 2022-06-26_NOB_DOT_6\n",
      "        Results stored: dict_keys(['XGBClassifier_object', 'XGBClassifier_combined', 'RandomForestClassifier'])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def kleinberg(offsets: np.ndarray, s=2, gamma=1):\n",
    "    \"\"\" TODO: Cite/give credit to Simba devs for implementation\"\"\"\n",
    "    if s <= 1:\n",
    "        raise ValueError(\"s must be greater than 1'!\")\n",
    "    if gamma <= 0:\n",
    "        raise ValueError(\"gamma must be positive!\")\n",
    "    if len(offsets) < 1:\n",
    "        raise ValueError(\"offsets must be non-empty!\")\n",
    "\n",
    "    assert offsets.ndim == 1\n",
    "    offsets = np.array(offsets, dtype=object)\n",
    "\n",
    "    if offsets.size == 1:\n",
    "        bursts = np.array([0, offsets[0], offsets[0]], ndmin=2, dtype=object)\n",
    "        return bursts\n",
    "\n",
    "    # offsets = np.sort(offsets)\n",
    "    gaps = np.diff(offsets)\n",
    "\n",
    "    if not np.all(gaps):\n",
    "        raise ValueError(\"Input cannot contain events with zero time between!\")\n",
    "\n",
    "    T = np.sum(gaps)\n",
    "    n = np.size(gaps)\n",
    "\n",
    "    g_hat = T / n\n",
    "\n",
    "    k = int(math.ceil(float(1 + math.log(T, s) + math.log(1 / np.amin(gaps), s))))\n",
    "\n",
    "    gamma_log_n = gamma * math.log(n)\n",
    "\n",
    "    def tau(i, j):\n",
    "        if i >= j:\n",
    "            return 0\n",
    "        else:\n",
    "            return (j - i) * gamma_log_n\n",
    "\n",
    "    alpha_function = np.vectorize(lambda x: s ** x / g_hat)\n",
    "    alpha = alpha_function(np.arange(k))\n",
    "\n",
    "    def f(j, x): # The exponential dist function for index j\n",
    "        return alpha[j] * math.exp(-alpha[j] * x)\n",
    "\n",
    "    C = np.repeat(float(\"inf\"), k)\n",
    "    C[0] = 0\n",
    "\n",
    "    q = np.empty((k, 0))\n",
    "    for t in range(n):\n",
    "        C_prime = np.repeat(float(\"inf\"), k)\n",
    "        q_prime = np.empty((k, t + 1))\n",
    "        q_prime.fill(np.nan)\n",
    "\n",
    "        for j in range(k):\n",
    "            cost_function = np.vectorize(lambda x: C[x] + tau(x, j))\n",
    "            cost = cost_function(np.arange(0, k))\n",
    "\n",
    "            el = np.argmin(cost)\n",
    "\n",
    "            if f(j, gaps[t]) > 0:\n",
    "                C_prime[j] = cost[el] - math.log(f(j, gaps[t]))\n",
    "\n",
    "            if t > 0:\n",
    "                q_prime[j, :t] = q[el, :]\n",
    "\n",
    "            q_prime[j, t] = j + 1\n",
    "\n",
    "        C = C_prime\n",
    "        q = q_prime\n",
    "\n",
    "    j = np.argmin(C)\n",
    "    q = q[j, :]\n",
    "\n",
    "    prev_q = 0\n",
    "\n",
    "    N = 0\n",
    "    for t in range(n):\n",
    "        if q[t] > prev_q:\n",
    "            N = N + q[t] - prev_q\n",
    "        prev_q = q[t]\n",
    "\n",
    "    # bursts = np.vstack([np.repeat(np.nan, N), np.repeat(offsets[0], N), np.repeat(offsets[0], N)]).transpose()\n",
    "    bursts = np.array([np.repeat(np.nan, N), np.repeat(offsets[0], N), np.repeat(offsets[0], N)], ndmin=2, dtype=object).transpose()\n",
    "    burst_counter = -1\n",
    "    prev_q = 0\n",
    "    stack = np.repeat(np.nan, N)\n",
    "    stack_counter = -1\n",
    "    for t in range(n):\n",
    "        if q[t] > prev_q:\n",
    "            num_levels_opened = q[t] - prev_q\n",
    "            for i in range(int(num_levels_opened)):\n",
    "                burst_counter += 1\n",
    "                bursts[burst_counter, 0] = prev_q + i\n",
    "                bursts[burst_counter, 1] = offsets[t]\n",
    "                stack_counter += 1\n",
    "                stack[stack_counter] = burst_counter\n",
    "        elif q[t] < prev_q:\n",
    "            num_levels_closed = prev_q - q[t]\n",
    "            for i in range(int(num_levels_closed)):\n",
    "                bursts[int(stack[stack_counter]), 2] = offsets[t]\n",
    "                stack_counter -= 1\n",
    "        prev_q = q[t]\n",
    "\n",
    "    while stack_counter >= 0:\n",
    "        bursts[int(stack[stack_counter]), 2] = offsets[n]\n",
    "        stack_counter -= 1\n",
    "\n",
    "    return bursts\n",
    "\n",
    "def build_Y_post_processor_klienberg_filtering():\n",
    "    def Y_post_processor_klienberg_filtering(y_pred): #, _df: pd.DataFrame):\n",
    "        # df = _df.copy(deep=True)\n",
    "        # AARONT: TODO: Had 'math domain error downstream here, would have to fix that!  Turning off'\n",
    "        # from simba.Kleinberg_burst_analysis import kleinberg\n",
    "        # kleinberg filtering setup args etc\n",
    "        classifierName = 'Interaction'\n",
    "        logs_path = 'TEMP_kburg_logs_path'\n",
    "        os.makedirs(logs_path, exist_ok=True)\n",
    "        hierarchy = 1\n",
    "        ## Trying to do this without requiring the dataframe...\n",
    "        # assert len(df) == len(y_pred)\n",
    "        # currDf = df[y_pred == 1]\n",
    "        # offsets = list(currDf.index.values)\n",
    "        # split into offsets by video\n",
    "        ## AARONT: This will cause issues if we used for example undersampling upstream, since we\n",
    "        #          aren't using the video indexes anymore.  But we shouldn't be doing that upstream,\n",
    "        #          so it shouldn't be a problem.  And even if someone did that would produce very strange\n",
    "        #          results and shouldn't be done.\n",
    "        offsets = numpy.where(y_pred == 1)[0]\n",
    "\n",
    "        # kleinberg apply algorithm\n",
    "        # print(f'offsets: {offsets}')\n",
    "        # print(f'df cols: {df.columns}')\n",
    "        # AARONT: TODO: I think the math domain error is due to the offsets calculation, they need to have some spacing\n",
    "        #               or something like that and are not getting the spacing they need!\n",
    "        # From the paper: Adjusting 'b' controls inertia that keeps automaton in it's current state (which arg is b?)\n",
    "        #\n",
    "        kleinbergBouts = kleinberg(offsets, s=2.0, gamma=0.3) # TODO: Params?\n",
    "        print(f'AARONT: k-filtering bouts (head): {kleinbergBouts[0:3]}')\n",
    "        kleinbergDf = pd.DataFrame(kleinbergBouts, columns=['Hierarchy', 'Start', 'Stop'])\n",
    "        kleinbergDf['Stop'] += 1\n",
    "        file_name = 'Kleinberg_log_' + classifierName + '.csv'\n",
    "        logs_file_name = os.path.join(logs_path, file_name)\n",
    "        kleinbergDf.to_csv(logs_file_name)\n",
    "        kleinbergDf_2 = kleinbergDf[kleinbergDf['Hierarchy'] == hierarchy].reset_index(drop=True)\n",
    "        # df[classifierName] = 0\n",
    "        new_y_pred = numpy.zeros_like(y_pred)\n",
    "        for index, row in kleinbergDf_2.iterrows():\n",
    "            rangeList = list(range(int(row['Start']), int(row['Stop'])))\n",
    "            new_y_pred[rangeList] = 1\n",
    "            # for frame in rangeList:\n",
    "                # df.at[frame, classifierName] = 1\n",
    "        # y_pred = df[classifierName].values\n",
    "        return new_y_pred\n",
    "    return Y_post_processor_klienberg_filtering\n",
    "\n",
    "\n",
    "def FROM_SIMBA_plug_holes_shortest_bout(y_pred, min_bout_duration): #, fps=None, shortest_bout=None):\n",
    "    \"\"\"\n",
    "    First, find all patterns like `1 0 0 0 ... 0 0 0 1` where the number of frames that are zeros is\n",
    "    less than or equal to min_bout_duration and fill them with 1's.\n",
    "    Then find all patterns like `0 1 1 1 ... 1 1 1 0` with the same length specification, and fill those\n",
    "    with 0's.\n",
    "    \"\"\"\n",
    "    col_name = 'y_pred_col'\n",
    "    data_df = pd.DataFrame(y_pred, columns=[col_name])\n",
    "    # frames_to_plug = int(int(fps) * int(shortest_bout) / 1000)\n",
    "    frames_to_plug_lst = list(range(1, min_bout_duration + 1))\n",
    "    frames_to_plug_lst.reverse()\n",
    "    patternListofLists, negPatternListofList = [], []\n",
    "    for k in frames_to_plug_lst:\n",
    "        zerosInList, oneInlist = [0] * k, [1] * k\n",
    "        currList = [1]\n",
    "        currList.extend(zerosInList)\n",
    "        currList.extend([1])\n",
    "        currListNeg = [0]\n",
    "        currListNeg.extend(oneInlist)\n",
    "        currListNeg.extend([0])\n",
    "        patternListofLists.append(currList)\n",
    "        negPatternListofList.append(currListNeg)\n",
    "    fill_patterns = numpy.asarray(patternListofLists, dtype=object)\n",
    "    remove_patterns = numpy.asarray(negPatternListofList, dtype=object)\n",
    "\n",
    "    for currPattern in fill_patterns:\n",
    "        n_obs = len(currPattern)\n",
    "        data_df['rolling_match'] = (data_df[col_name].rolling(window=n_obs, min_periods=n_obs)\n",
    "                                    .apply(lambda x: (x == currPattern).all(), raw=True)\n",
    "                                    .mask(lambda x: x == 0)\n",
    "                                    .bfill(limit=n_obs - 1)\n",
    "                                    .fillna(0)\n",
    "                                    .astype(bool)\n",
    "                                    )\n",
    "        data_df.loc[data_df['rolling_match'] == True, col_name] = 1\n",
    "        data_df = data_df.drop(['rolling_match'], axis=1)\n",
    "\n",
    "    for currPattern in remove_patterns:\n",
    "        n_obs = len(currPattern)\n",
    "        data_df['rolling_match'] = (data_df[col_name].rolling(window=n_obs, min_periods=n_obs)\n",
    "                                    .apply(lambda x: (x == currPattern).all(), raw=True)\n",
    "                                    .mask(lambda x: x == 0)\n",
    "                                    .bfill(limit=n_obs - 1)\n",
    "                                    .fillna(0)\n",
    "                                    .astype(bool)\n",
    "                                    )\n",
    "        data_df.loc[data_df['rolling_match'] == True, col_name] = 0\n",
    "        data_df = data_df.drop(['rolling_match'], axis=1)\n",
    "\n",
    "    return data_df[col_name]\n",
    "\n",
    "\n",
    "def build_Y_post_processor_min_bought_duration(min_bout_duration):\n",
    "    def Y_post_processor_min_bought_duration(y_pred: numpy.ndarray):\n",
    "        \"\"\" given y_pred a vector of binary predictions, enforce a minimum number of\n",
    "        concurrent predictions \"\"\"\n",
    "        assert numpy.all((y_pred == 1) | (y_pred == 0)), f'ERROR: y_pred must be a binary vector.  Got this instead: {y_pred}'\n",
    "        assert isinstance(min_bout_duration, int)\n",
    "\n",
    "        # print(f'y_pred BEFORE min_bought: (sum is {numpy.sum(y_pred)}; {y_pred}')\n",
    "        y_pred = FROM_SIMBA_plug_holes_shortest_bout(y_pred, min_bout_duration)\n",
    "        # print(f'y_pred AFTER min_bought: (sum is {numpy.sum(y_pred)}; {y_pred}')\n",
    "        return y_pred\n",
    "    return Y_post_processor_min_bought_duration\n",
    "\n",
    "\n",
    "video_frame_rate_in_seconds = 30 # fps for all of our videos\n",
    "min_bought_duration_in_ms = 100\n",
    "# ms * (frame_rate/ms) = frame_rate\n",
    "min_bought_duration_in_frames = int(\n",
    "    min_bought_duration_in_ms * video_frame_rate_in_seconds / 1000\n",
    ")\n",
    "print('min bought duration in frames:', min_bought_duration_in_frames)\n",
    "Y_post_processor_min_bought_duration = build_Y_post_processor_min_bought_duration(min_bought_duration_in_frames)\n",
    "Y_post_processor_klienberg_filtering = build_Y_post_processor_klienberg_filtering()\n",
    "\n",
    "def get_classifier_desc(clf):\n",
    "    if isinstance(clf, XGBClassifier):\n",
    "        # NOTE: If we ever try searching parameters we can modify this to be a tuple with the classifier name and params\n",
    "        return clf._classifier_desc # I added this manually haha\n",
    "    elif isinstance(clf, RandomForestClassifier):\n",
    "        return clf.__class__.__name__\n",
    "    else:\n",
    "        raise NotImplementedError(f'Do not have a classifier description extractor defined for {clf.__class__.__name__} models')\n",
    "\n",
    "# Store the results of applying the base classifier to the data\n",
    "def run_model_and_record_results(dataset, clf=None, precomputed_y_preds=None):\n",
    "    assert not (clf and precomputed_y_preds), 'If clf is provided it will be used to compute y predictions, otherwise you can provide \"precomputed_y_preds\".  You can not provide both.  Pick one'\n",
    "    assert clf or precomputed_y_preds, 'You most provide one of \"clf\" or \"precomputed_y_preds\"'\n",
    "    # precomputed_y_preds must be a dictionary of video_names -> np.ndarray of y predictions.\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        X = per_video_data.X\n",
    "        y_pred = clf.predict(X)\n",
    "        y_prob = clf.predict_proba(X)\n",
    "        classifier_desc = get_classifier_desc(clf)\n",
    "        per_video_data.apply_and_record_postprocessing_step(classifier_desc, clf, y_pred, y_prob)\n",
    "        y_pred = Y_post_processor_min_bought_duration(y_pred)\n",
    "        per_video_data.apply_and_record_postprocessing_step(classifier_desc, Y_post_processor_min_bought_duration, y_pred)\n",
    "        y_pred = Y_post_processor_klienberg_filtering(y_pred)\n",
    "        per_video_data.apply_and_record_postprocessing_step(classifier_desc, Y_post_processor_klienberg_filtering, y_pred)\n",
    "\n",
    "        print('Recorded data for:', per_video_data)\n",
    "\n",
    "\n",
    "\n",
    "run_model_and_record_results(training_odour_dataset, xgb_odour_clf)\n",
    "run_model_and_record_results(holdout_odour_dataset, xgb_odour_clf)\n",
    "run_model_and_record_results(training_object_dataset, xgb_object_clf)\n",
    "run_model_and_record_results(holdout_object_dataset, xgb_object_clf)\n",
    "\n",
    "run_model_and_record_results(training_odour_dataset, xgb_combined_clf)\n",
    "run_model_and_record_results(holdout_odour_dataset, xgb_combined_clf)\n",
    "run_model_and_record_results(training_object_dataset, xgb_combined_clf)\n",
    "run_model_and_record_results(holdout_object_dataset, xgb_combined_clf)\n",
    "\n",
    "run_model_and_record_results(training_odour_dataset, simba_odour_clf)\n",
    "run_model_and_record_results(holdout_odour_dataset, simba_odour_clf)\n",
    "run_model_and_record_results(training_object_dataset, simba_object_clf)\n",
    "run_model_and_record_results(holdout_object_dataset, simba_object_clf)\n",
    "\n",
    "\n",
    "# TODO: Load arbitrary results (ROI predictions in particular) and add them to the per_video_data_classes as another classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "TRAINING ODOUR SCORES\n",
      "\n",
      "########################################\n",
      "08092021_DOT_Rat9_10\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9561231172233137, recall=1.0, f1=0.9775694676933379, c_mat=array([[3873,   67],\n",
      "       [   0, 1460]], dtype=int64))\n",
      "PartialResults(precision=0.9564138350292988, recall=1.0, f1=0.9776481508795553, c_mat=array([[3873,   19,    9,    8,    6,   12,   13],\n",
      "       [   0,  355,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   86,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  320,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   98,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  314,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  287]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8428074245939675, recall=0.9952054794520548, f1=0.9126884422110553, c_mat=array([[3669,  271],\n",
      "       [   7, 1453]], dtype=int64))\n",
      "PartialResults(precision=0.8508395532011015, recall=0.9952054794520548, f1=0.9154934818330993, c_mat=array([[3669,   70,   43,   27,   48,   32,   51],\n",
      "       [   3,  352,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,   84,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  320,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   97,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  313,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  287]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9910591471801926, recall=0.986986301369863, f1=0.9890185312285518, c_mat=array([[3927,   13],\n",
      "       [  19, 1441]], dtype=int64))\n",
      "PartialResults(precision=0.9910915065387592, recall=0.986986301369863, f1=0.9890011561750707, c_mat=array([[3927,    3,    4,    3,    0,    1,    2],\n",
      "       [   6,  349,    0,    0,    0,    0,    0],\n",
      "       [   4,    0,   82,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  319,    0,    0,    0],\n",
      "       [   4,    0,    0,    0,   94,    0,    0],\n",
      "       [   3,    0,    0,    0,    0,  311,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  286]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08092021_IOT_Rat11_12\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9226914817465999, recall=0.9945987654320988, f1=0.9572966951355365, c_mat=array([[5796,  108],\n",
      "       [   7, 1289]], dtype=int64))\n",
      "PartialResults(precision=0.9234325194582078, recall=0.9945987654320988, f1=0.9574695810423932, c_mat=array([[5796,   38,    6,   30,   24,    4,    6],\n",
      "       [   1,  328,    0,    0,    0,    0,    0],\n",
      "       [   4,    0,  110,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  262,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  372,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,   71,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  146]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7138711549622752, recall=0.9490740740740741, f1=0.8148393507784035, c_mat=array([[5411,  493],\n",
      "       [  66, 1230]], dtype=int64))\n",
      "PartialResults(precision=0.7189955660339724, recall=0.9490740740740741, f1=0.8171306793728901, c_mat=array([[5411,  137,   79,   89,   93,   23,   72],\n",
      "       [  16,  313,    0,    0,    0,    0,    0],\n",
      "       [  10,    0,  104,    0,    0,    0,    0],\n",
      "       [  13,    0,    0,  250,    0,    0,    0],\n",
      "       [   7,    0,    0,    0,  366,    0,    0],\n",
      "       [   4,    0,    0,    0,    0,   67,    0],\n",
      "       [  16,    0,    0,    0,    0,    0,  130]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9804919423240034, recall=0.8919753086419753, f1=0.9341414141414142, c_mat=array([[5881,   23],\n",
      "       [ 140, 1156]], dtype=int64))\n",
      "PartialResults(precision=0.9804402397226657, recall=0.8919753086419753, f1=0.9338914598942182, c_mat=array([[5881,    8,    6,    4,    5,    0,    0],\n",
      "       [  39,  290,    0,    0,    0,    0,    0],\n",
      "       [  19,    0,   95,    0,    0,    0,    0],\n",
      "       [  32,    0,    0,  231,    0,    0,    0],\n",
      "       [  24,    0,    0,    0,  349,    0,    0],\n",
      "       [  11,    0,    0,    0,    0,   60,    0],\n",
      "       [  15,    0,    0,    0,    0,    0,  131]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08102021_IOT_Rat3_4(2)\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9238218205293738, recall=0.9909972299168975, f1=0.956231206147678, c_mat=array([[5638,  118],\n",
      "       [  13, 1431]], dtype=int64))\n",
      "PartialResults(precision=0.9253695707168199, recall=0.9909972299168975, f1=0.9566484472087957, c_mat=array([[5638,    6,   10,   14,   43,   21,   24],\n",
      "       [   3,  143,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  160,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,   77,    0,    0,    0],\n",
      "       [   4,    0,    0,    0,  297,    0,    0],\n",
      "       [   5,    0,    0,    0,    0,  461,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  293]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.6868787276341949, recall=0.9570637119113573, f1=0.7997685185185186, c_mat=array([[5126,  630],\n",
      "       [  62, 1382]], dtype=int64))\n",
      "PartialResults(precision=0.6964499414487841, recall=0.9570637119113573, f1=0.8040101465175477, c_mat=array([[5126,   83,  136,   44,  127,  123,  117],\n",
      "       [   6,  140,    0,    0,    0,    0,    0],\n",
      "       [  14,    0,  146,    0,    0,    0,    0],\n",
      "       [   5,    0,    0,   72,    0,    0,    0],\n",
      "       [   7,    0,    0,    0,  294,    0,    0],\n",
      "       [  13,    0,    0,    0,    0,  453,    0],\n",
      "       [  17,    0,    0,    0,    0,    0,  277]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9935298346513299, recall=0.9570637119113573, f1=0.9749559082892417, c_mat=array([[5747,    9],\n",
      "       [  62, 1382]], dtype=int64))\n",
      "PartialResults(precision=0.9936081187171928, recall=0.9570637119113573, f1=0.9749439708851558, c_mat=array([[5747,    1,    0,    0,    2,    0,    6],\n",
      "       [   7,  139,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,  154,    0,    0,    0,    0],\n",
      "       [   5,    0,    0,   72,    0,    0,    0],\n",
      "       [   8,    0,    0,    0,  293,    0,    0],\n",
      "       [  23,    0,    0,    0,    0,  443,    0],\n",
      "       [  13,    0,    0,    0,    0,    0,  281]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08102021_IOT_Rat3_4\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9409090909090909, recall=1.0, f1=0.9695550351288056, c_mat=array([[4080,   78],\n",
      "       [   0, 1242]], dtype=int64))\n",
      "PartialResults(precision=0.9412988567749949, recall=1.0, f1=0.9696641590111041, c_mat=array([[4080,    7,    8,    7,   12,   25,   19],\n",
      "       [   0,  132,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  143,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  162,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   88,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  358,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  359]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7929712460063898, recall=0.999194847020934, f1=0.8842180263626648, c_mat=array([[3834,  324],\n",
      "       [   1, 1241]], dtype=int64))\n",
      "PartialResults(precision=0.8035165042618152, recall=0.999194847020934, f1=0.8879841651343606, c_mat=array([[3834,   41,   74,   38,   53,   78,   40],\n",
      "       [   0,  132,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  143,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  162,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   88,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  358,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  358]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9753184713375797, recall=0.9863123993558777, f1=0.9807846277021617, c_mat=array([[4127,   31],\n",
      "       [  17, 1225]], dtype=int64))\n",
      "PartialResults(precision=0.9754190801108401, recall=0.9863123993558777, f1=0.9807605860480085, c_mat=array([[4127,    4,    1,    5,    2,    8,   11],\n",
      "       [   3,  129,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,  137,    0,    0,    0,    0],\n",
      "       [   3,    0,    0,  159,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   87,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  357,    0],\n",
      "       [   3,    0,    0,    0,    0,    0,  356]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08_11_2021_DOT_Rat7_8\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.948051948051948, recall=1.0, f1=0.9733333333333333, c_mat=array([[3937,   76],\n",
      "       [   0, 1387]], dtype=int64))\n",
      "PartialResults(precision=0.9490741912198206, recall=1.0, f1=0.9736105447261597, c_mat=array([[3937,   28,   20,    3,   11,   14],\n",
      "       [   0,  274,    0,    0,    0,    0],\n",
      "       [   0,    0,  213,    0,    0,    0],\n",
      "       [   0,    0,    0,  295,    0,    0],\n",
      "       [   0,    0,    0,    0,  213,    0],\n",
      "       [   0,    0,    0,    0,    0,  392]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8496932515337423, recall=0.9985580389329488, f1=0.9181305933046072, c_mat=array([[3768,  245],\n",
      "       [   2, 1385]], dtype=int64))\n",
      "PartialResults(precision=0.8525923910678678, recall=0.9985580389329488, f1=0.9190615032170714, c_mat=array([[3768,   71,   50,   35,   50,   39],\n",
      "       [   1,  273,    0,    0,    0,    0],\n",
      "       [   0,    0,  213,    0,    0,    0],\n",
      "       [   0,    0,    0,  295,    0,    0],\n",
      "       [   1,    0,    0,    0,  212,    0],\n",
      "       [   0,    0,    0,    0,    0,  392]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9906137184115523, recall=0.989185291997116, f1=0.9898989898989898, c_mat=array([[4000,   13],\n",
      "       [  15, 1372]], dtype=int64))\n",
      "PartialResults(precision=0.9906546512183069, recall=0.989185291997116, f1=0.9898981584193236, c_mat=array([[4000,    1,    5,    1,    2,    4],\n",
      "       [   5,  269,    0,    0,    0,    0],\n",
      "       [   4,    0,  209,    0,    0,    0],\n",
      "       [   4,    0,    0,  291,    0,    0],\n",
      "       [   1,    0,    0,    0,  212,    0],\n",
      "       [   1,    0,    0,    0,    0,  391]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08_12_2021_IOT_Rat3_4\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9393939393939394, recall=0.9970760233918129, f1=0.9673758865248228, c_mat=array([[5036,   22],\n",
      "       [   1,  341]], dtype=int64))\n",
      "PartialResults(precision=0.9433799914625746, recall=0.9970760233918129, f1=0.9686046218444655, c_mat=array([[5036,    1,    7,    2,    3,    2,    7],\n",
      "       [   1,   65,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   69,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  103,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   45,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    2,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   57]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.688659793814433, recall=0.9766081871345029, f1=0.8077388149939541, c_mat=array([[4907,  151],\n",
      "       [   8,  334]], dtype=int64))\n",
      "PartialResults(precision=0.7167581695982679, recall=0.9766081871345029, f1=0.8212915981467184, c_mat=array([[4907,   36,   30,   15,   15,   11,   44],\n",
      "       [   3,   63,    0,    0,    0,    0,    0],\n",
      "       [   3,    0,   66,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  103,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   44,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    2,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,   56]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9703264094955489, recall=0.956140350877193, f1=0.9631811487481591, c_mat=array([[5048,   10],\n",
      "       [  15,  327]], dtype=int64))\n",
      "PartialResults(precision=0.9759258804660906, recall=0.956140350877193, f1=0.964728222023848, c_mat=array([[5048,    3,    1,    1,    0,    3,    2],\n",
      "       [   2,   64,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,   63,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  102,    0,    0,    0],\n",
      "       [   4,    0,    0,    0,   41,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    2,    0],\n",
      "       [   2,    0,    0,    0,    0,    0,   55]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08_13_2021_DOT_Rat9_10\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9455864570737605, recall=1.0, f1=0.9720323182100683, c_mat=array([[4573,   45],\n",
      "       [   0,  782]], dtype=int64))\n",
      "PartialResults(precision=0.946311546377713, recall=1.0, f1=0.9722304507996621, c_mat=array([[4573,    3,    5,   11,   19,    4,    3],\n",
      "       [   0,   36,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  168,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,   97,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  258,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  142,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   81]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8082901554404145, recall=0.9974424552429667, f1=0.8929593589009731, c_mat=array([[4433,  185],\n",
      "       [   2,  780]], dtype=int64))\n",
      "PartialResults(precision=0.8098911529584887, recall=0.9974424552429667, f1=0.893520489771714, c_mat=array([[4433,   15,   45,   27,   48,   36,   14],\n",
      "       [   0,   36,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  166,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,   97,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  258,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  142,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   81]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9782330345710627, recall=0.9769820971867008, f1=0.9776071657069738, c_mat=array([[4601,   17],\n",
      "       [  18,  764]], dtype=int64))\n",
      "PartialResults(precision=0.9785835779602946, recall=0.9769820971867008, f1=0.9776435303457565, c_mat=array([[4601,    3,    2,    1,    4,    4,    3],\n",
      "       [   0,   36,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,  162,    0,    0,    0,    0],\n",
      "       [   2,    0,    0,   95,    0,    0,    0],\n",
      "       [   7,    0,    0,    0,  251,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  140,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,   80]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08_14_2021_DOT_Rat7_8\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9652122641509434, recall=0.9993894993894994, f1=0.9820035992801439, c_mat=array([[3703,   59],\n",
      "       [   1, 1637]], dtype=int64))\n",
      "PartialResults(precision=0.9656081069682272, recall=0.9993894993894994, f1=0.9821069124591476, c_mat=array([[3703,    8,   11,    4,    5,   25,    6],\n",
      "       [   0,  138,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  444,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  200,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  256,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  349,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  250]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8438796680497925, recall=0.9932844932844933, f1=0.9125070106561973, c_mat=array([[3461,  301],\n",
      "       [  11, 1627]], dtype=int64))\n",
      "PartialResults(precision=0.8466776496044396, recall=0.9932844932844933, f1=0.9132958360623556, c_mat=array([[3461,   22,   39,   54,   57,   79,   50],\n",
      "       [   1,  137,    0,    0,    0,    0,    0],\n",
      "       [   7,    0,  438,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  200,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  255,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  348,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  249]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9853031230863442, recall=0.9822954822954822, f1=0.9837970039743197, c_mat=array([[3738,   24],\n",
      "       [  29, 1609]], dtype=int64))\n",
      "PartialResults(precision=0.9854566424753223, recall=0.9822954822954822, f1=0.9838303736493008, c_mat=array([[3738,    3,    2,    1,    3,   13,    2],\n",
      "       [   3,  135,    0,    0,    0,    0,    0],\n",
      "       [   9,    0,  436,    0,    0,    0,    0],\n",
      "       [   3,    0,    0,  197,    0,    0,    0],\n",
      "       [   6,    0,    0,    0,  250,    0,    0],\n",
      "       [   6,    0,    0,    0,    0,  343,    0],\n",
      "       [   2,    0,    0,    0,    0,    0,  248]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-11_NOD_DOT_11\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9396615158204562, recall=0.9984362783424551, f1=0.9681576952236542, c_mat=array([[4039,   82],\n",
      "       [   2, 1277]], dtype=int64))\n",
      "PartialResults(precision=0.9402355079171661, recall=0.9984362783424551, f1=0.9683088457731965, c_mat=array([[4039,   18,    7,    6,   16,   20,   15],\n",
      "       [   0,  391,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  115,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  145,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  144,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  193,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  289]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8155526992287918, recall=0.9921813917122753, f1=0.8952380952380953, c_mat=array([[3834,  287],\n",
      "       [  10, 1269]], dtype=int64))\n",
      "PartialResults(precision=0.8222903101832306, recall=0.9921813917122753, f1=0.897569025393776, c_mat=array([[3834,   45,   44,   24,   66,   32,   76],\n",
      "       [   0,  391,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  114,    0,    0,    0,    0],\n",
      "       [   2,    0,    0,  144,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  143,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  191,    0],\n",
      "       [   4,    0,    0,    0,    0,    0,  286]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9723289777094543, recall=0.9890539483971853, f1=0.9806201550387597, c_mat=array([[4085,   36],\n",
      "       [  14, 1265]], dtype=int64))\n",
      "PartialResults(precision=0.9723724276067741, recall=0.9890539483971853, f1=0.9806185060151008, c_mat=array([[4085,    8,    4,    6,    2,    5,   11],\n",
      "       [   1,  390,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  114,    0,    0,    0,    0],\n",
      "       [   2,    0,    0,  144,    0,    0,    0],\n",
      "       [   3,    0,    0,    0,  141,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  193,    0],\n",
      "       [   7,    0,    0,    0,    0,    0,  283]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-11_NOD_DOT_9\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9517601043024772, recall=1.0, f1=0.9752839011356046, c_mat=array([[4633,   37],\n",
      "       [   0,  730]], dtype=int64))\n",
      "PartialResults(precision=0.9527038777871695, recall=1.0, f1=0.9755409627978353, c_mat=array([[4633,    4,    5,    2,    2,   18,    6],\n",
      "       [   0,  129,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  123,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  120,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   85,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  166,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  107]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7978021978021979, recall=0.9945205479452055, f1=0.8853658536585367, c_mat=array([[4486,  184],\n",
      "       [   4,  726]], dtype=int64))\n",
      "PartialResults(precision=0.8060029947985594, recall=0.9945205479452055, f1=0.8881993803904986, c_mat=array([[4486,   22,   32,    8,   17,   75,   30],\n",
      "       [   1,  128,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  121,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  120,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   85,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  165,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  107]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.978319783197832, recall=0.989041095890411, f1=0.9836512261580382, c_mat=array([[4654,   16],\n",
      "       [   8,  722]], dtype=int64))\n",
      "PartialResults(precision=0.9784019700197822, recall=0.989041095890411, f1=0.983633583127039, c_mat=array([[4654,    4,    1,    3,    1,    4,    3],\n",
      "       [   1,  128,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  121,    0,    0,    0,    0],\n",
      "       [   4,    0,    0,  116,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   84,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  166,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  107]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-11_NOD_IOT_12\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9527649769585254, recall=0.9975874547647768, f1=0.9746611667648792, c_mat=array([[3660,   82],\n",
      "       [   4, 1654]], dtype=int64))\n",
      "PartialResults(precision=0.9532794672842237, recall=0.9975874547647768, f1=0.9747999906679035, c_mat=array([[3660,   12,    9,   11,    9,   22,   19],\n",
      "       [   0,  287,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   52,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  148,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  214,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  612,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  341]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8503086419753086, recall=0.996984318455971, f1=0.9178234314269849, c_mat=array([[3451,  291],\n",
      "       [   5, 1653]], dtype=int64))\n",
      "PartialResults(precision=0.8547223467341091, recall=0.996984318455971, f1=0.9192705519637294, c_mat=array([[3451,   56,   27,   16,   37,   63,   92],\n",
      "       [   1,  286,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   52,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  148,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  214,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  612,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  341]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9784560143626571, recall=0.9861278648974668, f1=0.9822769600480624, c_mat=array([[3706,   36],\n",
      "       [  23, 1635]], dtype=int64))\n",
      "PartialResults(precision=0.9784620920756798, recall=0.9861278648974668, f1=0.9822610742280417, c_mat=array([[3706,    6,    0,    2,    5,   15,    8],\n",
      "       [   3,  284,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   52,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  147,    0,    0,    0],\n",
      "       [   8,    0,    0,    0,  207,    0,    0],\n",
      "       [   7,    0,    0,    0,    0,  607,    0],\n",
      "       [   4,    0,    0,    0,    0,    0,  338]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-12_NOD_IOT_14\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9667994687915007, recall=0.9958960328317373, f1=0.9811320754716981, c_mat=array([[4644,   25],\n",
      "       [   3,  728]], dtype=int64))\n",
      "PartialResults(precision=0.967050454468912, recall=0.9958960328317373, f1=0.9812015041938106, c_mat=array([[4644,    3,    6,    6,    2,    5,    3],\n",
      "       [   0,  111,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  130,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,   83,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  140,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  208,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,   56]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8393063583815029, recall=0.9931600547195623, f1=0.9097744360902257, c_mat=array([[4530,  139],\n",
      "       [   5,  726]], dtype=int64))\n",
      "PartialResults(precision=0.8476002693972027, recall=0.9931600547195623, f1=0.9125309684360994, c_mat=array([[4530,    4,   50,   21,   37,   21,    6],\n",
      "       [   0,  111,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  128,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,   83,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  140,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  208,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,   56]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9862068965517241, recall=0.9781121751025992, f1=0.9821428571428571, c_mat=array([[4659,   10],\n",
      "       [  16,  715]], dtype=int64))\n",
      "PartialResults(precision=0.986479734141332, recall=0.9781121751025992, f1=0.9821429455707501, c_mat=array([[4659,    2,    2,    0,    1,    1,    4],\n",
      "       [   1,  110,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  128,    0,    0,    0,    0],\n",
      "       [   4,    0,    0,   80,    0,    0,    0],\n",
      "       [   6,    0,    0,    0,  135,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  207,    0],\n",
      "       [   2,    0,    0,    0,    0,    0,   55]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "\n",
      "**************************************************\n",
      "HOLDOUT ODOUR SCORES\n",
      "\n",
      "########################################\n",
      "08102021_DOT_Rat7_8\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.6992014196983141, recall=0.6804835924006909, f1=0.6897155361050329, c_mat=array([[3903,  339],\n",
      "       [ 370,  788]], dtype=int64))\n",
      "PartialResults(precision=0.7225413501645259, recall=0.6804835924006909, f1=0.6930169300166573, c_mat=array([[3903,   23,   80,   50,   64,   24,   98],\n",
      "       [  28,   21,    0,    0,    0,    0,    0],\n",
      "       [  51,    0,  154,    0,    0,    0,    0],\n",
      "       [ 160,    0,    0,  279,    0,    0,    0],\n",
      "       [  47,    0,    0,    0,   81,    0,    0],\n",
      "       [  38,    0,    0,    0,    0,  119,    0],\n",
      "       [  46,    0,    0,    0,    0,    0,  134]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.6476002629848784, recall=0.8506044905008635, f1=0.7353490108249346, c_mat=array([[3706,  536],\n",
      "       [ 173,  985]], dtype=int64))\n",
      "PartialResults(precision=0.6723872322363121, recall=0.8506044905008635, f1=0.7424275061739845, c_mat=array([[3706,   28,  119,   99,   68,   47,  175],\n",
      "       [   2,   47,    0,    0,    0,    0,    0],\n",
      "       [  26,    0,  179,    0,    0,    0,    0],\n",
      "       [  92,    0,    0,  347,    0,    0,    0],\n",
      "       [  20,    0,    0,    0,  108,    0,    0],\n",
      "       [  18,    0,    0,    0,    0,  139,    0],\n",
      "       [  15,    0,    0,    0,    0,    0,  165]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.589171974522293, recall=0.4792746113989637, f1=0.5285714285714286, c_mat=array([[3855,  387],\n",
      "       [ 603,  555]], dtype=int64))\n",
      "PartialResults(precision=0.6793422505566155, recall=0.4792746113989637, f1=0.5194701677338012, c_mat=array([[3855,   24,   65,   28,   41,   26,  203],\n",
      "       [   8,   41,    0,    0,    0,    0,    0],\n",
      "       [ 111,    0,   94,    0,    0,    0,    0],\n",
      "       [ 309,    0,    0,  130,    0,    0,    0],\n",
      "       [  50,    0,    0,    0,   78,    0,    0],\n",
      "       [  75,    0,    0,    0,    0,   82,    0],\n",
      "       [  50,    0,    0,    0,    0,    0,  130]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08122021_IOT_Rat11_12\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.5648584905660378, recall=0.8661844484629295, f1=0.6837972876516775, c_mat=array([[4478,  369],\n",
      "       [  74,  479]], dtype=int64))\n",
      "PartialResults(precision=0.662011168103605, recall=0.8661844484629295, f1=0.720904096456728, c_mat=array([[4478,  161,    3,   63,   75,   56,   11],\n",
      "       [  30,  119,    0,    0,    0,    0,    0],\n",
      "       [  26,    0,   74,    0,    0,    0,    0],\n",
      "       [   5,    0,    0,  117,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,   24,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,   46,    0],\n",
      "       [  13,    0,    0,    0,    0,    0,   99]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.5395348837209303, recall=0.8390596745027125, f1=0.656758669497523, c_mat=array([[4451,  396],\n",
      "       [  89,  464]], dtype=int64))\n",
      "PartialResults(precision=0.6420551941911816, recall=0.8390596745027125, f1=0.7079380124926636, c_mat=array([[4451,   92,   14,   83,  128,   67,   12],\n",
      "       [  45,  104,    0,    0,    0,    0,    0],\n",
      "       [  13,    0,   87,    0,    0,    0,    0],\n",
      "       [  20,    0,    0,  102,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   23,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,   46,    0],\n",
      "       [  10,    0,    0,    0,    0,    0,  102]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.5283842794759825, recall=0.6564195298372514, f1=0.585483870967742, c_mat=array([[4523,  324],\n",
      "       [ 190,  363]], dtype=int64))\n",
      "PartialResults(precision=0.5857398687764787, recall=0.6564195298372514, f1=0.6048265357402522, c_mat=array([[4523,  174,    4,   57,   25,   54,   10],\n",
      "       [ 125,   24,    0,    0,    0,    0,    0],\n",
      "       [  27,    0,   73,    0,    0,    0,    0],\n",
      "       [  20,    0,    0,  102,    0,    0,    0],\n",
      "       [   7,    0,    0,    0,   17,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,   46,    0],\n",
      "       [  11,    0,    0,    0,    0,    0,  101]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-12_NOD_DOT_17\n",
      ":::: Results for XGBClassifier_odour model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8776923076923077, recall=0.819683908045977, f1=0.8476968796433877, c_mat=array([[3849,  159],\n",
      "       [ 251, 1141]], dtype=int64))\n",
      "PartialResults(precision=0.880815360919041, recall=0.819683908045977, f1=0.8457775036036312, c_mat=array([[3849,   51,   24,   30,   13,   27,   14],\n",
      "       [  24,  183,    0,    0,    0,    0,    0],\n",
      "       [  44,    0,  117,    0,    0,    0,    0],\n",
      "       [  24,    0,    0,  281,    0,    0,    0],\n",
      "       [  18,    0,    0,    0,  183,    0,    0],\n",
      "       [  79,    0,    0,    0,    0,  229,    0],\n",
      "       [  62,    0,    0,    0,    0,    0,  148]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8002496878901373, recall=0.9209770114942529, f1=0.8563794255177021, c_mat=array([[3688,  320],\n",
      "       [ 110, 1282]], dtype=int64))\n",
      "PartialResults(precision=0.8127023815323583, recall=0.9209770114942529, f1=0.8600975604533704, c_mat=array([[3688,  119,   53,   42,   25,   37,   44],\n",
      "       [  14,  193,    0,    0,    0,    0,    0],\n",
      "       [  15,    0,  146,    0,    0,    0,    0],\n",
      "       [   9,    0,    0,  296,    0,    0,    0],\n",
      "       [   5,    0,    0,    0,  196,    0,    0],\n",
      "       [  37,    0,    0,    0,    0,  271,    0],\n",
      "       [  30,    0,    0,    0,    0,    0,  180]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.872168284789644, recall=0.7744252873563219, f1=0.8203957382039574, c_mat=array([[3850,  158],\n",
      "       [ 314, 1078]], dtype=int64))\n",
      "PartialResults(precision=0.8771989504409548, recall=0.7744252873563219, f1=0.8148853362188262, c_mat=array([[3850,   64,   11,   19,    3,   27,   34],\n",
      "       [  38,  169,    0,    0,    0,    0,    0],\n",
      "       [  85,    0,   76,    0,    0,    0,    0],\n",
      "       [   9,    0,    0,  296,    0,    0,    0],\n",
      "       [  41,    0,    0,    0,  160,    0,    0],\n",
      "       [  80,    0,    0,    0,    0,  228,    0],\n",
      "       [  61,    0,    0,    0,    0,    0,  149]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "\n",
      "**************************************************\n",
      "TRAINING OBJECT SCORES\n",
      "\n",
      "########################################\n",
      "08092021_DOT_Rat9_10(2)\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9245033112582781, recall=0.9971428571428571, f1=0.9594501718213058, c_mat=array([[5686,  114],\n",
      "       [   4, 1396]], dtype=int64))\n",
      "PartialResults(precision=0.9247087881163331, recall=0.9971428571428571, f1=0.9595070179535939, c_mat=array([[5686,   24,   13,   22,   13,   29,   13],\n",
      "       [   2,  281,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  254,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  247,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  167,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  285,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  162]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8266104756170981, recall=0.9807142857142858, f1=0.8970924534465861, c_mat=array([[5512,  288],\n",
      "       [  27, 1373]], dtype=int64))\n",
      "PartialResults(precision=0.8284125490881583, recall=0.9807142857142858, f1=0.8976833337486895, c_mat=array([[5512,   67,   36,   40,   24,   81,   40],\n",
      "       [   6,  277,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  252,    0,    0,    0,    0],\n",
      "       [   8,    0,    0,  240,    0,    0,    0],\n",
      "       [   2,    0,    0,    0,  166,    0,    0],\n",
      "       [   7,    0,    0,    0,    0,  278,    0],\n",
      "       [   2,    0,    0,    0,    0,    0,  160]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9565217391304348, recall=0.9428571428571428, f1=0.9496402877697843, c_mat=array([[5740,   60],\n",
      "       [  80, 1320]], dtype=int64))\n",
      "PartialResults(precision=0.9569358451017732, recall=0.9428571428571428, f1=0.9497159921457915, c_mat=array([[5740,   16,    5,    7,    2,   15,   15],\n",
      "       [  12,  271,    0,    0,    0,    0,    0],\n",
      "       [  10,    0,  244,    0,    0,    0,    0],\n",
      "       [  19,    0,    0,  229,    0,    0,    0],\n",
      "       [   7,    0,    0,    0,  161,    0,    0],\n",
      "       [  20,    0,    0,    0,    0,  265,    0],\n",
      "       [  12,    0,    0,    0,    0,    0,  150]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08102021_DOT_Rat11_12\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9348516949152542, recall=0.9983031674208145, f1=0.9655361050328227, c_mat=array([[5309,  123],\n",
      "       [   3, 1765]], dtype=int64))\n",
      "PartialResults(precision=0.9354730993580621, recall=0.9983031674208145, f1=0.9657200414377557, c_mat=array([[5309,   25,   12,    4,   48,   19,   15],\n",
      "       [   0,  263,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  186,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,   81,    0,    0,    0],\n",
      "       [   3,    0,    0,    0,  444,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  373,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  418]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8151658767772512, recall=0.9728506787330317, f1=0.8870551830840638, c_mat=array([[5042,  390],\n",
      "       [  48, 1720]], dtype=int64))\n",
      "PartialResults(precision=0.8169567636243874, recall=0.9728506787330317, f1=0.8876670223497004, c_mat=array([[5042,   58,   51,   25,  128,   55,   73],\n",
      "       [   7,  256,    0,    0,    0,    0,    0],\n",
      "       [   7,    0,  179,    0,    0,    0,    0],\n",
      "       [   2,    0,    0,   79,    0,    0,    0],\n",
      "       [  16,    0,    0,    0,  431,    0,    0],\n",
      "       [  12,    0,    0,    0,    0,  361,    0],\n",
      "       [   4,    0,    0,    0,    0,    0,  414]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.970166379804934, recall=0.956447963800905, f1=0.9632583309598405, c_mat=array([[5380,   52],\n",
      "       [  77, 1691]], dtype=int64))\n",
      "PartialResults(precision=0.9707474478883132, recall=0.956447963800905, f1=0.9633115777064016, c_mat=array([[5380,   20,    2,    2,   10,    3,   15],\n",
      "       [  12,  251,    0,    0,    0,    0,    0],\n",
      "       [  14,    0,  172,    0,    0,    0,    0],\n",
      "       [   3,    0,    0,   78,    0,    0,    0],\n",
      "       [  16,    0,    0,    0,  431,    0,    0],\n",
      "       [  21,    0,    0,    0,    0,  352,    0],\n",
      "       [  11,    0,    0,    0,    0,    0,  407]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "08102021_DOT_Rat7_8(2)\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9539295392953929, recall=0.9971671388101983, f1=0.9750692520775623, c_mat=array([[4980,  102],\n",
      "       [   6, 2112]], dtype=int64))\n",
      "PartialResults(precision=0.9540920557758383, recall=0.9971671388101983, f1=0.9751151121618177, c_mat=array([[4980,   12,   17,   20,   24,   16,   13],\n",
      "       [   0,  363,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  364,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  267,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  385,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  348,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  385]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8395311236863379, recall=0.9806421152030217, f1=0.9046167247386759, c_mat=array([[4685,  397],\n",
      "       [  41, 2077]], dtype=int64))\n",
      "PartialResults(precision=0.8408670209545231, recall=0.9806421152030217, f1=0.905012144930815, c_mat=array([[4685,   38,   61,   50,   82,   90,   76],\n",
      "       [   4,  359,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,  360,    0,    0,    0,    0],\n",
      "       [  12,    0,    0,  256,    0,    0,    0],\n",
      "       [   7,    0,    0,    0,  379,    0,    0],\n",
      "       [   3,    0,    0,    0,    0,  347,    0],\n",
      "       [   9,    0,    0,    0,    0,    0,  376]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9821176470588235, recall=0.9853635505193579, f1=0.9837379212821117, c_mat=array([[5044,   38],\n",
      "       [  31, 2087]], dtype=int64))\n",
      "PartialResults(precision=0.9826007573696277, recall=0.9853635505193579, f1=0.9837868020837227, c_mat=array([[5044,   21,    0,    1,    6,    7,    3],\n",
      "       [   1,  362,    0,    0,    0,    0,    0],\n",
      "       [   7,    0,  359,    0,    0,    0,    0],\n",
      "       [  12,    0,    0,  256,    0,    0,    0],\n",
      "       [   5,    0,    0,    0,  381,    0,    0],\n",
      "       [   3,    0,    0,    0,    0,  347,    0],\n",
      "       [   3,    0,    0,    0,    0,    0,  382]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-20_NOB_DOT_4\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8766423357664234, recall=0.9958540630182421, f1=0.9324534161490684, c_mat=array([[7625,  169],\n",
      "       [   5, 1201]], dtype=int64))\n",
      "PartialResults(precision=0.8812897385989946, recall=0.9958540630182421, f1=0.9339404599844732, c_mat=array([[7625,    6,   29,   36,   26,   25,   47],\n",
      "       [   0,   85,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  464,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  150,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  157,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  193,    0],\n",
      "       [   2,    0,    0,    0,    0,    0,  152]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7509457755359394, recall=0.9875621890547264, f1=0.8531518624641833, c_mat=array([[7399,  395],\n",
      "       [  15, 1191]], dtype=int64))\n",
      "PartialResults(precision=0.755085376511754, recall=0.9875621890547264, f1=0.8547741587874207, c_mat=array([[7399,   23,  105,   65,   71,   58,   73],\n",
      "       [   1,   84,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  462,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  150,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  157,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  193,    0],\n",
      "       [   9,    0,    0,    0,    0,    0,  145]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9890310786106032, recall=0.8971807628524047, f1=0.9408695652173912, c_mat=array([[7782,   12],\n",
      "       [ 124, 1082]], dtype=int64))\n",
      "PartialResults(precision=0.9889810479700086, recall=0.8971807628524047, f1=0.9390799983565671, c_mat=array([[7782,    1,    2,    3,    1,    3,    2],\n",
      "       [   6,   79,    0,    0,    0,    0,    0],\n",
      "       [  50,    0,  414,    0,    0,    0,    0],\n",
      "       [  11,    0,    0,  140,    0,    0,    0],\n",
      "       [   8,    0,    0,    0,  149,    0,    0],\n",
      "       [   5,    0,    0,    0,    0,  190,    0],\n",
      "       [  44,    0,    0,    0,    0,    0,  110]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-21_NOB_DOT_22\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9528922757187391, recall=0.9985480943738657, f1=0.9751861042183623, c_mat=array([[6109,  136],\n",
      "       [   4, 2751]], dtype=int64))\n",
      "PartialResults(precision=0.9540778783170979, recall=0.9985480943738657, f1=0.9755121783692833, c_mat=array([[6109,    4,   21,   16,   27,   19,   49],\n",
      "       [   0,  443,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  172,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  386,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  160,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  491,    0],\n",
      "       [   4,    0,    0,    0,    0,    0, 1099]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9012304622547389, recall=0.9836660617059891, f1=0.9406456091634849, c_mat=array([[5948,  297],\n",
      "       [  45, 2710]], dtype=int64))\n",
      "PartialResults(precision=0.904323511693797, recall=0.9836660617059891, f1=0.9415632859147827, c_mat=array([[5948,   17,   43,   26,   50,   49,  112],\n",
      "       [   0,  443,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  171,    0,    0,    0,    0],\n",
      "       [   4,    0,    0,  382,    0,    0,    0],\n",
      "       [   3,    0,    0,    0,  157,    0,    0],\n",
      "       [   2,    0,    0,    0,    0,  489,    0],\n",
      "       [  35,    0,    0,    0,    0,    0, 1068]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9936224489795918, recall=0.8482758620689655, f1=0.9152144115919327, c_mat=array([[6230,   15],\n",
      "       [ 418, 2337]], dtype=int64))\n",
      "PartialResults(precision=0.9936964277448649, recall=0.8482758620689655, f1=0.9134514420980826, c_mat=array([[6230,    0,    3,    2,    4,    2,    4],\n",
      "       [   3,  440,    0,    0,    0,    0,    0],\n",
      "       [  16,    0,  156,    0,    0,    0,    0],\n",
      "       [  92,    0,    0,  294,    0,    0,    0],\n",
      "       [  11,    0,    0,    0,  149,    0,    0],\n",
      "       [  82,    0,    0,    0,    0,  409,    0],\n",
      "       [ 214,    0,    0,    0,    0,    0,  889]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-21_NOB_IOT_23\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8932527693856999, recall=0.9988738738738738, f1=0.9431153641679956, c_mat=array([[8006,  106],\n",
      "       [   1,  887]], dtype=int64))\n",
      "PartialResults(precision=0.8950967269904601, recall=0.9988738738738738, f1=0.9436576861156297, c_mat=array([[8006,    8,   11,   14,   17,   26,   30],\n",
      "       [   0,  123,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   53,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  168,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  104,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  286,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  153]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7356902356902357, recall=0.9842342342342343, f1=0.8420038535645473, c_mat=array([[7798,  314],\n",
      "       [  14,  874]], dtype=int64))\n",
      "PartialResults(precision=0.7484105747386237, recall=0.9842342342342343, f1=0.847256831565116, c_mat=array([[7798,   21,   53,   36,   41,   85,   78],\n",
      "       [   1,  122,    0,    0,    0,    0,    0],\n",
      "       [   3,    0,   50,    0,    0,    0,    0],\n",
      "       [   6,    0,    0,  162,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  103,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  287,    0],\n",
      "       [   3,    0,    0,    0,    0,    0,  150]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9800498753117207, recall=0.8851351351351351, f1=0.9301775147928993, c_mat=array([[8096,   16],\n",
      "       [ 102,  786]], dtype=int64))\n",
      "PartialResults(precision=0.9801813564106701, recall=0.8851351351351351, f1=0.927911577597751, c_mat=array([[8096,    0,    0,    2,    2,    7,    5],\n",
      "       [  13,  110,    0,    0,    0,    0,    0],\n",
      "       [   8,    0,   45,    0,    0,    0,    0],\n",
      "       [  26,    0,    0,  142,    0,    0,    0],\n",
      "       [  30,    0,    0,    0,   74,    0,    0],\n",
      "       [   3,    0,    0,    0,    0,  284,    0],\n",
      "       [  22,    0,    0,    0,    0,    0,  131]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-24_NOB_IOT_22\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9302931596091205, recall=1.0, f1=0.9638879514006076, c_mat=array([[7465,  107],\n",
      "       [   0, 1428]], dtype=int64))\n",
      "PartialResults(precision=0.9311543744337824, recall=1.0, f1=0.9641289963423572, c_mat=array([[7465,   10,   20,   19,   10,   11,   37],\n",
      "       [   0,  170,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  172,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  416,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  222,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  143,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  305]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8286549707602339, recall=0.992296918767507, f1=0.9031230082855322, c_mat=array([[7279,  293],\n",
      "       [  11, 1417]], dtype=int64))\n",
      "PartialResults(precision=0.8348977334715734, recall=0.992296918767507, f1=0.9051011305459244, c_mat=array([[7279,   37,   65,   28,   46,   45,   72],\n",
      "       [   2,  168,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,  170,    0,    0,    0,    0],\n",
      "       [   4,    0,    0,  412,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  221,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  143,    0],\n",
      "       [   2,    0,    0,    0,    0,    0,  303]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9742836149889786, recall=0.9285714285714286, f1=0.9508784510577268, c_mat=array([[7537,   35],\n",
      "       [ 102, 1326]], dtype=int64))\n",
      "PartialResults(precision=0.9742081013544407, recall=0.9285714285714286, f1=0.9506008462221115, c_mat=array([[7537,    2,    0,   11,    2,    7,   13],\n",
      "       [   9,  161,    0,    0,    0,    0,    0],\n",
      "       [   9,    0,  163,    0,    0,    0,    0],\n",
      "       [  13,    0,    0,  403,    0,    0,    0],\n",
      "       [  20,    0,    0,    0,  202,    0,    0],\n",
      "       [  20,    0,    0,    0,    0,  123,    0],\n",
      "       [  31,    0,    0,    0,    0,    0,  274]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-26_NOB_DOT_4\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9558566433566433, recall=0.9986301369863013, f1=0.976775346136668, c_mat=array([[6709,  101],\n",
      "       [   3, 2187]], dtype=int64))\n",
      "PartialResults(precision=0.9560902031338311, recall=0.9986301369863013, f1=0.9768417337074674, c_mat=array([[6709,   14,   21,   16,    9,   14,   27],\n",
      "       [   1,  317,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  559,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  179,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,   95,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  372,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,  665]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8913132976533553, recall=0.9885844748858448, f1=0.937432344663347, c_mat=array([[6546,  264],\n",
      "       [  25, 2165]], dtype=int64))\n",
      "PartialResults(precision=0.892422121341266, recall=0.9885844748858448, f1=0.9377412377584853, c_mat=array([[6546,   55,   79,   30,   12,   21,   67],\n",
      "       [   2,  316,    0,    0,    0,    0,    0],\n",
      "       [  10,    0,  549,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  178,    0,    0,    0],\n",
      "       [   3,    0,    0,    0,   93,    0,    0],\n",
      "       [   5,    0,    0,    0,    0,  367,    0],\n",
      "       [   4,    0,    0,    0,    0,    0,  662]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9940184883088635, recall=0.8347031963470319, f1=0.907421196326632, c_mat=array([[6799,   11],\n",
      "       [ 362, 1828]], dtype=int64))\n",
      "PartialResults(precision=0.9943871661677786, recall=0.8347031963470319, f1=0.9052880108326407, c_mat=array([[6799,    4,    2,    2,    2,    1,    0],\n",
      "       [  13,  305,    0,    0,    0,    0,    0],\n",
      "       [  64,    0,  495,    0,    0,    0,    0],\n",
      "       [  34,    0,    0,  145,    0,    0,    0],\n",
      "       [   6,    0,    0,    0,   90,    0,    0],\n",
      "       [ 108,    0,    0,    0,    0,  264,    0],\n",
      "       [ 137,    0,    0,    0,    0,    0,  529]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-26_NOB_IOT_1\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9054054054054054, recall=1.0, f1=0.950354609929078, c_mat=array([[8186,   77],\n",
      "       [   0,  737]], dtype=int64))\n",
      "PartialResults(precision=0.9061362174625064, recall=1.0, f1=0.9505651674802954, c_mat=array([[8186,    7,   13,   16,   11,   23,    7],\n",
      "       [   0,  107,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   92,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  124,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,  162,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,  175,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   77]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7672955974842768, recall=0.9932157394843962, f1=0.8657599053814311, c_mat=array([[8041,  222],\n",
      "       [   5,  732]], dtype=int64))\n",
      "PartialResults(precision=0.7725856217150918, recall=0.9932157394843962, f1=0.8675591625308674, c_mat=array([[8041,   16,   43,   33,   35,   71,   24],\n",
      "       [   2,  105,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,   92,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  124,    0,    0,    0],\n",
      "       [   2,    0,    0,    0,  160,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  174,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,   77]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9754768392370572, recall=0.9715061058344641, f1=0.9734874235214139, c_mat=array([[8245,   18],\n",
      "       [  21,  716]], dtype=int64))\n",
      "PartialResults(precision=0.975939042634438, recall=0.9715061058344641, f1=0.9733802465380533, c_mat=array([[8245,    0,    4,    5,    2,    4,    3],\n",
      "       [   5,  102,    0,    0,    0,    0,    0],\n",
      "       [   2,    0,   90,    0,    0,    0,    0],\n",
      "       [   1,    0,    0,  123,    0,    0,    0],\n",
      "       [  11,    0,    0,    0,  151,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  174,    0],\n",
      "       [   1,    0,    0,    0,    0,    0,   76]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-26_NOB_IOT_5\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.9304883413990321, recall=0.9985835694050992, f1=0.9633340924618539, c_mat=array([[6724,  158],\n",
      "       [   3, 2115]], dtype=int64))\n",
      "PartialResults(precision=0.9314922306746336, recall=0.9985835694050992, f1=0.9636068800997565, c_mat=array([[6724,   23,   21,   26,   16,   25,   47],\n",
      "       [   1,  280,    0,    0,    0,    0,    0],\n",
      "       [   0,    0,  209,    0,    0,    0,    0],\n",
      "       [   0,    0,    0,  234,    0,    0,    0],\n",
      "       [   1,    0,    0,    0,  660,    0,    0],\n",
      "       [   1,    0,    0,    0,    0,  254,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,  478]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.8464965573106521, recall=0.9867799811142587, f1=0.9112709832134293, c_mat=array([[6503,  379],\n",
      "       [  28, 2090]], dtype=int64))\n",
      "PartialResults(precision=0.8513847086050066, recall=0.9867799811142587, f1=0.9129384086155895, c_mat=array([[6503,   44,   80,   44,   52,   74,   85],\n",
      "       [   5,  276,    0,    0,    0,    0,    0],\n",
      "       [   6,    0,  203,    0,    0,    0,    0],\n",
      "       [   2,    0,    0,  232,    0,    0,    0],\n",
      "       [   2,    0,    0,    0,  659,    0,    0],\n",
      "       [   4,    0,    0,    0,    0,  251,    0],\n",
      "       [   9,    0,    0,    0,    0,    0,  469]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.9891248058001035, recall=0.9017941454202077, f1=0.9434428253889849, c_mat=array([[6861,   21],\n",
      "       [ 208, 1910]], dtype=int64))\n",
      "PartialResults(precision=0.9890599395647184, recall=0.9017941454202077, f1=0.9426757987557816, c_mat=array([[6861,    3,    3,    5,    3,    1,    6],\n",
      "       [  18,  263,    0,    0,    0,    0,    0],\n",
      "       [  15,    0,  194,    0,    0,    0,    0],\n",
      "       [  24,    0,    0,  210,    0,    0,    0],\n",
      "       [  30,    0,    0,    0,  631,    0,    0],\n",
      "       [  44,    0,    0,    0,    0,  211,    0],\n",
      "       [  77,    0,    0,    0,    0,    0,  401]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "\n",
      "**************************************************\n",
      "HOLDOUT OBJECT SCORES\n",
      "\n",
      "########################################\n",
      "08092021_IOT_Rat7_8\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.46223021582733814, recall=0.7311522048364154, f1=0.5663911845730027, c_mat=array([[4598, 1196],\n",
      "       [ 378, 1028]], dtype=int64))\n",
      "PartialResults(precision=0.5831799163979174, recall=0.7311522048364154, f1=0.6463887714874916, c_mat=array([[4598,  103,   70,   64,  455,  438,   66],\n",
      "       [ 105,  103,    0,    0,    0,    0,    0],\n",
      "       [   1,    0,  107,    0,    0,    0,    0],\n",
      "       [  22,    0,    0,  171,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,    0],\n",
      "       [ 225,    0,    0,    0,    0,  428,    0],\n",
      "       [  25,    0,    0,    0,    0,    0,  219]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.5332721431849472, recall=0.8264580369843528, f1=0.6482566248256625, c_mat=array([[4777, 1017],\n",
      "       [ 244, 1162]], dtype=int64))\n",
      "PartialResults(precision=0.6606364862891901, recall=0.8264580369843528, f1=0.7327800214592229, c_mat=array([[4777,  114,   56,   42,  408,  333,   64],\n",
      "       [  74,  134,    0,    0,    0,    0,    0],\n",
      "       [   4,    0,  104,    0,    0,    0,    0],\n",
      "       [  20,    0,    0,  173,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,    0],\n",
      "       [ 115,    0,    0,    0,    0,  538,    0],\n",
      "       [  31,    0,    0,    0,    0,    0,  213]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.5243535778713169, recall=0.620199146514936, f1=0.5682632779406973, c_mat=array([[5003,  791],\n",
      "       [ 534,  872]], dtype=int64))\n",
      "PartialResults(precision=0.6602359472449213, recall=0.620199146514936, f1=0.6285935658468554, c_mat=array([[5003,   68,   28,   13,  340,  294,   48],\n",
      "       [ 160,   48,    0,    0,    0,    0,    0],\n",
      "       [  36,    0,   72,    0,    0,    0,    0],\n",
      "       [  90,    0,    0,  103,    0,    0,    0],\n",
      "       [   0,    0,    0,    0,    0,    0,    0],\n",
      "       [ 192,    0,    0,    0,    0,  461,    0],\n",
      "       [  56,    0,    0,    0,    0,    0,  188]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-23_NOB_IOT_4\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7928363988383349, recall=0.8318943626206196, f1=0.811895910780669, c_mat=array([[6603,  428],\n",
      "       [ 331, 1638]], dtype=int64))\n",
      "PartialResults(precision=0.7983417396384491, recall=0.8318943626206196, f1=0.8103448503476876, c_mat=array([[6603,   16,   55,   63,  138,   94,   62],\n",
      "       [  16,   61,    0,    0,    0,    0,    0],\n",
      "       [  10,    0,  174,    0,    0,    0,    0],\n",
      "       [  23,    0,    0,  102,    0,    0,    0],\n",
      "       [ 131,    0,    0,    0,  639,    0,    0],\n",
      "       [  15,    0,    0,    0,    0,  362,    0],\n",
      "       [ 136,    0,    0,    0,    0,    0,  300]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7737765466297323, recall=0.851193499238192, f1=0.8106408706166869, c_mat=array([[6541,  490],\n",
      "       [ 293, 1676]], dtype=int64))\n",
      "PartialResults(precision=0.7786704398391441, recall=0.851193499238192, f1=0.8086805631567815, c_mat=array([[6541,   29,   70,   64,  155,   95,   77],\n",
      "       [  16,   61,    0,    0,    0,    0,    0],\n",
      "       [   5,    0,  179,    0,    0,    0,    0],\n",
      "       [   5,    0,    0,  120,    0,    0,    0],\n",
      "       [  76,    0,    0,    0,  694,    0,    0],\n",
      "       [  48,    0,    0,    0,    0,  329,    0],\n",
      "       [ 143,    0,    0,    0,    0,    0,  293]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.8427230046948356, recall=0.5469781615033011, f1=0.663381582999692, c_mat=array([[6830,  201],\n",
      "       [ 892, 1077]], dtype=int64))\n",
      "PartialResults(precision=0.8549767756949975, recall=0.5469781615033011, f1=0.6529222785209622, c_mat=array([[6830,    1,   21,   66,   54,   38,   21],\n",
      "       [  45,   32,    0,    0,    0,    0,    0],\n",
      "       [ 104,    0,   80,    0,    0,    0,    0],\n",
      "       [  67,    0,    0,   58,    0,    0,    0],\n",
      "       [ 304,    0,    0,    0,  466,    0,    0],\n",
      "       [  79,    0,    0,    0,    0,  298,    0],\n",
      "       [ 293,    0,    0,    0,    0,    0,  143]], dtype=int64))\n",
      "------------------------------\n",
      "\n",
      "########################################\n",
      "2022-06-26_NOB_DOT_6\n",
      ":::: Results for XGBClassifier_object model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.7021276595744681, recall=0.7814854682454252, f1=0.7396841569026998, c_mat=array([[7763,  308],\n",
      "       [ 203,  726]], dtype=int64))\n",
      "PartialResults(precision=0.7517252458344773, recall=0.7814854682454252, f1=0.7499006439760262, c_mat=array([[7763,   45,   20,   62,   23,   45,  113],\n",
      "       [  17,  119,    0,    0,    0,    0,    0],\n",
      "       [  63,    0,   88,    0,    0,    0,    0],\n",
      "       [  98,    0,    0,  326,    0,    0,    0],\n",
      "       [  13,    0,    0,    0,   39,    0,    0],\n",
      "       [   6,    0,    0,    0,    0,   84,    0],\n",
      "       [   6,    0,    0,    0,    0,    0,   70]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for XGBClassifier_combined model pipeline ::::\n",
      "XGBClassifier\n",
      "PartialResults(precision=0.6197783461210571, recall=0.7825618945102261, f1=0.691722169362512, c_mat=array([[7625,  446],\n",
      "       [ 202,  727]], dtype=int64))\n",
      "PartialResults(precision=0.6695065136693608, recall=0.7825618945102261, f1=0.7065086981441491, c_mat=array([[7625,   70,   73,   76,   36,   48,  143],\n",
      "       [  17,  119,    0,    0,    0,    0,    0],\n",
      "       [  63,    0,   88,    0,    0,    0,    0],\n",
      "       [ 103,    0,    0,  321,    0,    0,    0],\n",
      "       [  10,    0,    0,    0,   42,    0,    0],\n",
      "       [   3,    0,    0,    0,    0,   87,    0],\n",
      "       [   6,    0,    0,    0,    0,    0,   70]], dtype=int64))\n",
      "------------------------------\n",
      ":::: Results for RandomForestClassifier model pipeline ::::\n",
      "RandomForestClassifier\n",
      "PartialResults(precision=0.8125, recall=0.6017222820236814, f1=0.6914038342609772, c_mat=array([[7942,  129],\n",
      "       [ 370,  559]], dtype=int64))\n",
      "PartialResults(precision=0.8233024987257339, recall=0.6017222820236814, f1=0.6816735661326412, c_mat=array([[7942,   29,   10,   38,    1,   23,   28],\n",
      "       [  32,  104,    0,    0,    0,    0,    0],\n",
      "       [ 104,    0,   47,    0,    0,    0,    0],\n",
      "       [ 150,    0,    0,  274,    0,    0,    0],\n",
      "       [  25,    0,    0,    0,   27,    0,    0],\n",
      "       [  22,    0,    0,    0,    0,   68,    0],\n",
      "       [  37,    0,    0,    0,    0,    0,   39]], dtype=int64))\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## These are the interfaces.\n",
    "# PartialResults = namedtuple(\n",
    "#     'PartialResults',\n",
    "#     'precision recall f1 c_mat X y_true y_pred')\n",
    "# FullResults = namedtuple(\n",
    "#     'FullResults',\n",
    "#     'model test_results train_results total_time')\n",
    "#\n",
    "# def build_partial_result(y_true, y_pred):\n",
    "#     try:\n",
    "#         precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "#     except:\n",
    "#         # must be multi class\n",
    "#         precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "#     # precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "#     c_mat = confusion_matrix(y_true, y_pred)\n",
    "#     return PartialResults(precision, recall, f1, c_mat, X, y_true, y_pred)\n",
    "\n",
    "# class ModelResultLabels(object):\n",
    "#     \"\"\" Another data class for holding results \"\"\"\n",
    "#     def __init__(self, func, y_binary, y_multi, y_prob, binary_results, multi_label_results):\n",
    "#         self._func = func # just in case, will use name for printing\n",
    "#         self.y_binary = y_binary\n",
    "#         self.y_multi = y_multi\n",
    "#         self.y_prob = y_prob # Probability will always be relative to the binary labels.\n",
    "#         self.binary_results = binary_results\n",
    "#         self.multi_label_results = multi_label_results\n",
    "def print_dataset_scores(dataset: Dataset):\n",
    "    for per_video_data in dataset.per_video_data_classes:\n",
    "        print()\n",
    "        print('#' * 40)\n",
    "        print(per_video_data.video_name)\n",
    "        for classifier_desc, ordered_results_dict in per_video_data.model_result_labels.items():\n",
    "            print(f':::: Results for {classifier_desc} model pipeline ::::')\n",
    "            func_name = classifier_desc.split('_')[0]\n",
    "            results = ordered_results_dict[func_name]\n",
    "            print(func_name)\n",
    "            print(results.binary_results)\n",
    "            print(results.multi_label_results)\n",
    "            print('-' * 30)\n",
    "            # for func_name, results in ordered_results_dict.items():\n",
    "            #     print(func_name)\n",
    "            #     print(results.binary_results)\n",
    "            #     print(results.multi_label_results)\n",
    "            #     print('-' * 30)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('TRAINING ODOUR SCORES')\n",
    "print_dataset_scores(training_odour_dataset)\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('HOLDOUT ODOUR SCORES')\n",
    "print_dataset_scores(holdout_odour_dataset)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('TRAINING OBJECT SCORES')\n",
    "print_dataset_scores(training_object_dataset)\n",
    "print()\n",
    "print()\n",
    "print('*' * 50)\n",
    "print('HOLDOUT OBJECT SCORES')\n",
    "print_dataset_scores(holdout_object_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>rat_id</th>\n",
       "      <th>object</th>\n",
       "      <th>min</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>08122021_IOT_Rat11_12</td>\n",
       "      <td>Rat 12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>08122021_IOT_Rat11_12</td>\n",
       "      <td>Rat 12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>08122021_IOT_Rat11_12</td>\n",
       "      <td>Rat 12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>08122021_IOT_Rat11_12</td>\n",
       "      <td>Rat 12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>08122021_IOT_Rat11_12</td>\n",
       "      <td>Rat 12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                video_name  rat_id  object  min  value\n",
       "0     2022-06-23_NOB_IOT_4   Rat 4       1    1    1.9\n",
       "1     2022-06-23_NOB_IOT_4   Rat 4       2    1    2.7\n",
       "2     2022-06-23_NOB_IOT_4   Rat 4       3    1    0.4\n",
       "3     2022-06-23_NOB_IOT_4   Rat 4       4    1    3.4\n",
       "4     2022-06-23_NOB_IOT_4   Rat 4       5    1    1.5\n",
       "..                     ...     ...     ...  ...    ...\n",
       "109  08122021_IOT_Rat11_12  Rat 12       2    3    0.0\n",
       "110  08122021_IOT_Rat11_12  Rat 12       3    3    0.9\n",
       "111  08122021_IOT_Rat11_12  Rat 12       4    3    0.0\n",
       "112  08122021_IOT_Rat11_12  Rat 12       5    3    0.0\n",
       "113  08122021_IOT_Rat11_12  Rat 12       6    3    0.0\n",
       "\n",
       "[114 rows x 5 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the csv file, flatten it into a dataframe, print that dataframe out for reference, then calculate statistics.\n",
    "\n",
    "stop_watch_csv = os.path.join('hackathon', 'Iteration_2_withROI', 'models', 'holdout_stopwatch_TJO.csv')\n",
    "stop_watch_interaction_times_df = pd.read_csv(stop_watch_csv, index_col=None)\n",
    "stop_watch_interaction_times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Final Results.\n",
    "Results will be aggregated in a hierarchy of classes like so:\n",
    "\n",
    "AggregationFunction: Defines the measureable we wish to compute;\n",
    "    - PerVideoResults: Similar to before, we store reusult dataframes pervideo, then classifier, then step.  \n",
    "                       We want to see how the different stages in post processing effect our various measureables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simba_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [105], line 152\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m agg_mean_bout_duration\n\u001b[1;32m--> 152\u001b[0m \u001b[39mfor\u001b[39;00m dir_name, classifier \u001b[39min\u001b[39;00m [(\u001b[39m'\u001b[39m\u001b[39mxgb_clf\u001b[39m\u001b[39m'\u001b[39m, xgb_clf), (\u001b[39m'\u001b[39m\u001b[39msimba_clf\u001b[39m\u001b[39m'\u001b[39m, simba_clf)]:\n\u001b[0;32m    153\u001b[0m     training_model_res_per_minute_df, training_golden_res_per_minute_df \u001b[39m=\u001b[39m build_results_df_from_agg_funcs_and_per_video_data(\n\u001b[0;32m    154\u001b[0m             training_dataset\u001b[39m.\u001b[39mper_video_data_classes,\n\u001b[0;32m    155\u001b[0m             classifier_desc\u001b[39m=\u001b[39mget_classifier_desc(xgb_clf),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m             ]\n\u001b[0;32m    163\u001b[0m         )\n\u001b[0;32m    165\u001b[0m     holdout_model_res_per_minute_df, holdout_golden_res_per_minute_df \u001b[39m=\u001b[39m build_results_df_from_agg_funcs_and_per_video_data(\n\u001b[0;32m    166\u001b[0m             holdout_dataset\u001b[39m.\u001b[39mper_video_data_classes,\n\u001b[0;32m    167\u001b[0m             classifier_desc\u001b[39m=\u001b[39mget_classifier_desc(xgb_clf),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m             ]\n\u001b[0;32m    175\u001b[0m         )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'simba_clf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Lets produce our own data as best we can.\n",
    "# Get the results we have per video, grab the per object results, and then use the 30 frames per second assumtion\n",
    "# to caclulate the total time at each object in seconds.  Can also break this down by minute later BUT need to confirm\n",
    "# with Tim how the data is setup!! Because given 30 frames per second assumption, these videos are (7200/30)/60 = 4 minutes long\n",
    "# which doesn't make sense with the stop watch data provided that makes it seem there are 10 minutes of video in each!!\n",
    "# (5 minutes per animal, with 2 animals per video being given 1 treatment!)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "def build_results_df_from_agg_funcs_and_per_video_data(per_video_data_classes: list[PerVideoDataClass],\n",
    "                    agg_funcs, per_minute, classifier_desc, pipeline_model_step=None):\n",
    "    \"\"\" Dataset will have precomputed results for all the classifiers and videos of interest. \"\"\"\n",
    "    # NOTE: No rat_id_col for these results dataframes, we can map the videoname -> rat_id via the \n",
    "    #       stopwatch dataframe later if we wish.\n",
    "    assert isinstance(agg_funcs, list)\n",
    "    if pipeline_model_step is None:\n",
    "        # Identity, default pipeline step\n",
    "        pipeline_model_step = classifier_desc\n",
    "    video_col = 'video_name'\n",
    "    rat_id_col = 'rat_id'\n",
    "    object_col = 'object'\n",
    "    minute_col = 'min'\n",
    "    if per_minute:\n",
    "        cols = [video_col, object_col, minute_col]\n",
    "    else:\n",
    "        cols = [video_col, object_col]\n",
    "    cols += [func.__name__ for func in agg_funcs]\n",
    "\n",
    "    model_res_df = pd.DataFrame([], columns=cols)\n",
    "    golden_res_df = pd.DataFrame([], columns=cols)\n",
    "    print(f':::: Processing {classifier_desc};{pipeline_model_step} model ::::')\n",
    "\n",
    "    for per_video_data in per_video_data_classes:\n",
    "        print('Processing:', per_video_data.video_name)\n",
    "        y_multi_golden = per_video_data.y_multi\n",
    "\n",
    "        results: ModelResultLabels = per_video_data.model_result_labels[classifier_desc][pipeline_model_step]\n",
    "        # Let's just do the base classifier for now??? Or lets do all 3??\n",
    "        # print(results.multi_label_results)\n",
    "        y_multi = results.y_multi\n",
    "        # TODO:  Here we need to take 1 minute 'bites' of the data!\n",
    "        #        We will build up a dataframe with the same format was what Tim provided!\n",
    "        unique_labels = numpy.unique(y_multi)\n",
    "\n",
    "        if per_minute:\n",
    "            start = 0\n",
    "            frame_rate = 30 # frames per second\n",
    "            frames_in_1_minute = frame_rate * 60\n",
    "            end = frames_in_1_minute\n",
    "            minute_number = 1 # Puny human 1 based indexing\n",
    "            while start < len(y_multi):\n",
    "                if end > len(y_multi):\n",
    "                    print('Maybe going to have a problem, end is', end, 'and y_multi len is ', len(y_multi))\n",
    "                y_multi_cur = y_multi[start:end] # Remember, exclusive indexing\n",
    "                y_multi_golden_cur = y_multi_golden[start:end] # Remember, exclusive indexing\n",
    "                for label in unique_labels:\n",
    "                    model_agg_func_results = {}\n",
    "                    golden_agg_func_results = {}\n",
    "                    if label == 0:\n",
    "                        # Majority label, no interaction\n",
    "                        continue\n",
    "                    # golden_interaction_times[label] = (y_multi_golden_cur == label).sum() / video_frame_rate\n",
    "                    for agg_func in agg_funcs:\n",
    "                        model_agg_func_results[agg_func.__name__] = agg_func(y_multi_cur, label)\n",
    "                        golden_agg_func_results[agg_func.__name__] = agg_func(y_multi_golden_cur, label)\n",
    "                    model_res_df = model_res_df.append({\n",
    "                        video_col: per_video_data.video_name,\n",
    "                        object_col: label,\n",
    "                        minute_col: minute_number,\n",
    "                        **model_agg_func_results},\n",
    "                        ignore_index=True)\n",
    "                    golden_res_df = golden_res_df.append({\n",
    "                        video_col: per_video_data.video_name,\n",
    "                        object_col: label,\n",
    "                        minute_col: minute_number,\n",
    "                        **golden_agg_func_results},\n",
    "                        ignore_index=True)\n",
    "                minute_number += 1\n",
    "                start = end\n",
    "                end += frames_in_1_minute\n",
    "        else:\n",
    "            for label in unique_labels:\n",
    "                model_agg_func_results = {}\n",
    "                golden_agg_func_results = {}\n",
    "                if label == 0:\n",
    "                    # Majority label, no interaction\n",
    "                    continue\n",
    "                # golden_interaction_times[label] = (y_multi_golden_cur == label).sum() / video_frame_rate\n",
    "                for agg_func in agg_funcs:\n",
    "                    model_agg_func_results[agg_func.__name__] = agg_func(y_multi, label)\n",
    "                    golden_agg_func_results[agg_func.__name__] = agg_func(y_multi_golden, label)\n",
    "                model_res_df = model_res_df.append({\n",
    "                    video_col: per_video_data.video_name,\n",
    "                    object_col: label,\n",
    "                    **model_agg_func_results},\n",
    "                    ignore_index=True)\n",
    "                golden_res_df = golden_res_df.append({\n",
    "                    video_col: per_video_data.video_name,\n",
    "                    object_col: label,\n",
    "                    **golden_agg_func_results},\n",
    "                    ignore_index=True)\n",
    "    return model_res_df, golden_res_df\n",
    "\n",
    "\n",
    "def build_agg_sum_total_time(video_frame_rate):\n",
    "    def agg_sum_total_time(y_multi, label):\n",
    "        return (y_multi == label).sum() / video_frame_rate\n",
    "    return agg_sum_total_time\n",
    "\n",
    "def build_agg_num_interaction_bouts():\n",
    "    def agg_num_interaction_bouts(y_multi: np.ndarray, label):\n",
    "        assert isinstance(y_multi, np.ndarray) and y_multi.ndim == 1, 'If we get a list of arrays or an array with more dims we will have to think harder.'\n",
    "        # Find indexes associated with this label.\n",
    "        # If our vector looks like this:\n",
    "        # [0,0,2,2,2,0,0,2]\n",
    "        # Then for label 2 we will get indexes:\n",
    "        # [2,3,4,7]\n",
    "        # The diffs here will be:\n",
    "        # [1,1,3]\n",
    "        # With each 1 associated with at least 2 frames that are part of the same bout.\n",
    "        # So we bound the number of entries in the diff array that are greater than 1,\n",
    "        # and this gives the number of bouts.\n",
    "        idxes = np.where(y_multi == label)[0] # HACKS: The [0] is required because of the way\n",
    "        diffs = np.diff(idxes)\n",
    "        num_bouts = (diffs > 1).sum()\n",
    "        return num_bouts\n",
    "    return agg_num_interaction_bouts\n",
    "\n",
    "def build_agg_mean_bout_duration(video_frame_rate):\n",
    "    def agg_mean_bout_duration(y_multi: np.ndarray, label):\n",
    "        assert isinstance(y_multi, np.ndarray) and y_multi.ndim == 1, 'If we get a list of arrays or an array with more dims we will have to think harder.'\n",
    "        # like agg_num_interaction_bouts\n",
    "        idxes = np.where(y_multi == label)[0]\n",
    "        diffs = np.diff(idxes)\n",
    "        num_bouts = (diffs > 1).sum()\n",
    "        # Like agg_sum_total_time\n",
    "        total_time = (y_multi == label).sum() / video_frame_rate\n",
    "        if num_bouts > 0:\n",
    "            assert total_time > 0\n",
    "            # Combine them, and that's the mean\n",
    "            return total_time / num_bouts\n",
    "        else:\n",
    "            return 0\n",
    "    return agg_mean_bout_duration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_dir_name, classifier, data_split_dir_name, dataset in [\n",
    "            ('xgb_clf', xgb_odour_clf, 'odour', holdout_odour_dataset), \n",
    "            ('simba_clf', simba_odour_clf, 'odour', holdout_odour_dataset),\n",
    "            ('xgb_clf', xgb_object_clf, 'object', holdout_object_dataset), \n",
    "            ('simba_clf', simba_object_clf, 'object', holdout_object_dataset),\n",
    "        ]:\n",
    "    # training_model_res_per_minute_df, training_golden_res_per_minute_df = build_results_df_from_agg_funcs_and_per_video_data(\n",
    "    #         training_dataset.per_video_data_classes,\n",
    "    #         classifier_desc=get_classifier_desc(xgb_clf),\n",
    "    #         per_minute=True,\n",
    "    #         pipeline_model_step=None,\n",
    "    #         agg_funcs=[\n",
    "    #             build_agg_sum_total_time(30),\n",
    "    #             build_agg_mean_bout_duration(30),\n",
    "    #             build_agg_num_interaction_bouts(),\n",
    "    #         ]\n",
    "    #     )\n",
    "\n",
    "    holdout_model_res_per_minute_df, holdout_golden_res_per_minute_df = build_results_df_from_agg_funcs_and_per_video_data(\n",
    "            dataset.per_video_data_classes,\n",
    "            classifier_desc=get_classifier_desc(classifier),\n",
    "            per_minute=True,\n",
    "            pipeline_model_step=classifier.__class__.__name__,\n",
    "            agg_funcs=[\n",
    "                build_agg_sum_total_time(30),\n",
    "                build_agg_mean_bout_duration(30),\n",
    "                build_agg_num_interaction_bouts(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    holdout_model_res_per_video_df, holdout_golden_res_per_video_df = build_results_df_from_agg_funcs_and_per_video_data(\n",
    "            dataset.per_video_data_classes,\n",
    "            classifier_desc=get_classifier_desc(classifier),\n",
    "            per_minute=False,\n",
    "            pipeline_model_step=classifier.__class__.__name__,\n",
    "            agg_funcs=[\n",
    "                build_agg_sum_total_time(30),\n",
    "                build_agg_mean_bout_duration(30),\n",
    "                build_agg_num_interaction_bouts(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def to_csv(df, path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        df.to_csv(path)\n",
    "\n",
    "    to_csv(holdout_model_res_per_minute_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_model_results_per_minute.csv'))\n",
    "    to_csv(holdout_golden_res_per_minute_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_golden_results_per_minute.csv'))\n",
    "    to_csv(holdout_model_res_per_video_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_model_results_per_video.csv'))\n",
    "    to_csv(holdout_golden_res_per_video_df, os.path.join('hackathon', 'notebook_result_csvs', data_split_dir_name, clf_dir_name, 'holdout_golden_results_per_video.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.662250964848232, 0.8571621439179155, 0.7472048958455927]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "QuadMesh.set() got an unexpected keyword argument 'annotate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m         y_preds[step_name]\u001b[39m.\u001b[39mextend(data_thing\u001b[39m.\u001b[39my_binary)\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m step_name, y_pred \u001b[39min\u001b[39;00m y_preds\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 35\u001b[0m     classification_report(y_true, y_pred, title\u001b[39m=\u001b[39;49mstep_name)\n",
      "Cell \u001b[1;32mIn [57], line 16\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, clf, X_data, title)\u001b[0m\n\u001b[0;32m     14\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(plot_data, columns\u001b[39m=\u001b[39mcolumns)\n\u001b[1;32m---> 16\u001b[0m sns\u001b[39m.\u001b[39;49mheatmap(data, vmin\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, vmax\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, annotate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     17\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\seaborn\\matrix.py:459\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m square:\n\u001b[0;32m    458\u001b[0m     ax\u001b[39m.\u001b[39mset_aspect(\u001b[39m\"\u001b[39m\u001b[39mequal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m plotter\u001b[39m.\u001b[39;49mplot(ax, cbar_ax, kwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\seaborn\\matrix.py:306\u001b[0m, in \u001b[0;36m_HeatMapper.plot\u001b[1;34m(self, ax, cax, kws)\u001b[0m\n\u001b[0;32m    303\u001b[0m     kws\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mvmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvmax)\n\u001b[0;32m    305\u001b[0m \u001b[39m# Draw the heatmap\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m mesh \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mpcolormesh(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_data, cmap\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmap, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws)\n\u001b[0;32m    308\u001b[0m \u001b[39m# Set the axis limits\u001b[39;00m\n\u001b[0;32m    309\u001b[0m ax\u001b[39m.\u001b[39mset(xlim\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), ylim\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\matplotlib\\__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1422\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1425\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1426\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1427\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6139\u001b[0m, in \u001b[0;36mAxes.pcolormesh\u001b[1;34m(self, alpha, norm, cmap, vmin, vmax, shading, antialiased, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6135\u001b[0m C \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39mravel()\n\u001b[0;32m   6137\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39msnap\u001b[39m\u001b[39m'\u001b[39m, mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mpcolormesh.snap\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 6139\u001b[0m collection \u001b[39m=\u001b[39m mcoll\u001b[39m.\u001b[39mQuadMesh(\n\u001b[0;32m   6140\u001b[0m     coords, antialiased\u001b[39m=\u001b[39mantialiased, shading\u001b[39m=\u001b[39mshading,\n\u001b[0;32m   6141\u001b[0m     array\u001b[39m=\u001b[39mC, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm, alpha\u001b[39m=\u001b[39malpha, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   6142\u001b[0m collection\u001b[39m.\u001b[39m_scale_norm(norm, vmin, vmax)\n\u001b[0;32m   6143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pcolor_grid_deprecation_helper()\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\matplotlib\\collections.py:1988\u001b[0m, in \u001b[0;36mQuadMesh.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bbox\u001b[39m.\u001b[39mupdate_from_data_xy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coordinates\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m   1986\u001b[0m \u001b[39m# super init delayed after own init because array kwarg requires\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \u001b[39m# self._coordinates and self._shading\u001b[39;00m\n\u001b[1;32m-> 1988\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1989\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_mouseover(\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\matplotlib\\collections.py:202\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset_transform \u001b[39m=\u001b[39m offset_transform\n\u001b[0;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path_effects \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_update(kwargs)\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paths \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\matplotlib\\artist.py:1186\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_update\u001b[39m(\u001b[39mself\u001b[39m, kwargs):\n\u001b[0;32m   1180\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m \u001b[39m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m \u001b[39m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m \n\u001b[0;32m   1184\u001b[0m \u001b[39m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_props(\n\u001b[0;32m   1187\u001b[0m         kwargs, \u001b[39m\"\u001b[39;49m\u001b[39m{cls.__name__}\u001b[39;49;00m\u001b[39m.set() got an unexpected keyword argument \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m   1188\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m{prop_name!r}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\toddy\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\matplotlib\\artist.py:1160\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mset_\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1159\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(func):\n\u001b[1;32m-> 1160\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m   1161\u001b[0m                     errfmt\u001b[39m.\u001b[39mformat(\u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m), prop_name\u001b[39m=\u001b[39mk))\n\u001b[0;32m   1162\u001b[0m             ret\u001b[39m.\u001b[39mappend(func(v))\n\u001b[0;32m   1163\u001b[0m \u001b[39mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: QuadMesh.set() got an unexpected keyword argument 'annotate'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classification_report(y_true, y_pred=None, clf=None, X_data=None, title=''):\n",
    "    assert (clf and X_data) or y_pred\n",
    "    assert not((clf or X_data) and y_pred)\n",
    "    # Make a heat map of classifier measures.\n",
    "    if clf:\n",
    "        y_pred = clf.predict(X_data)\n",
    "    f1_data: PartialResults = build_partial_result(y_true, y_pred)\n",
    "    # We actually don't care about the f1 score on the majority class.  Will only report class(es) of interest.\n",
    "    # TODO: We're going to include the confusion matrix as a subplot!\n",
    "    plot_data = [[f1_data.precision, f1_data.recall, f1_data.f1]]\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    print(plot_data)\n",
    "    columns = ['Precision', 'Recall', 'F1']\n",
    "    data = pd.DataFrame(plot_data, columns=columns)\n",
    "    sns.heatmap(data, vmin=0.0, vmax=1.0, annotate=True)\n",
    "    plt.show()\n",
    "    # plt.xticks(range(len(columns)), columns)\n",
    "    # plt.yticks([])\n",
    "    # plt.imshow(plot_data, cmap='Greens', vmin=0.0, vmax=1.0, annotate=True)\n",
    "    # plt.show()\n",
    "\n",
    "y_true = []\n",
    "from collections import OrderedDict\n",
    "y_preds = OrderedDict() # Will be a list with each step of processing in it\n",
    "for video_data in holdout_dataset.per_video_data_classes:\n",
    "    y_true.extend(video_data.y_binary)\n",
    "    # TODO: Might be easier to make a class for holding results of all types that has this get_classifier_desc as a method\n",
    "    for step_name, data_thing in video_data.model_result_labels[get_classifier_desc(xgb_clf)].items():\n",
    "        if step_name not in y_preds:\n",
    "            y_preds[step_name] = []\n",
    "        y_preds[step_name].extend(data_thing.y_binary)\n",
    "\n",
    "for step_name, y_pred in y_preds.items():\n",
    "    classification_report(y_true, y_pred, title=step_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>object</th>\n",
       "      <th>min</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            video_name object min     value\n",
       "0  08092021_IOT_Rat7_8      1   1  0.000000\n",
       "1  08092021_IOT_Rat7_8      2   1  0.000000\n",
       "2  08092021_IOT_Rat7_8      3   1  2.166667\n",
       "3  08092021_IOT_Rat7_8      4   1  0.000000\n",
       "4  08092021_IOT_Rat7_8      5   1  4.900000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_golden_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>object</th>\n",
       "      <th>min</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08092021_IOT_Rat7_8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            video_name object min     value\n",
       "0  08092021_IOT_Rat7_8      1   1  0.000000\n",
       "1  08092021_IOT_Rat7_8      2   1  0.000000\n",
       "2  08092021_IOT_Rat7_8      3   1  2.000000\n",
       "3  08092021_IOT_Rat7_8      4   1  0.000000\n",
       "4  08092021_IOT_Rat7_8      5   1  6.666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_model_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>rat_id</th>\n",
       "      <th>object</th>\n",
       "      <th>min</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-23_NOB_IOT_4</td>\n",
       "      <td>Rat 4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_name rat_id  object  min  value\n",
       "0  2022-06-23_NOB_IOT_4  Rat 4       1    1    1.9\n",
       "1  2022-06-23_NOB_IOT_4  Rat 4       2    1    2.7\n",
       "2  2022-06-23_NOB_IOT_4  Rat 4       3    1    0.4\n",
       "3  2022-06-23_NOB_IOT_4  Rat 4       4    1    3.4\n",
       "4  2022-06-23_NOB_IOT_4  Rat 4       5    1    1.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_watch_interaction_times_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = stop_watch_interaction_times_df.merge(\n",
    "#     holdout_interaction_times_df,\n",
    "#      on=(video_col, object_col, minute_col),\n",
    "#      suffixes=['_stopwatch', '_model'], validate='1:1')\n",
    "#     #  lsuffix='stopwatch',\n",
    "#     #  rsuffix='model')\n",
    "# full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_col = 'video_name' # ????\n",
    "def build_pivot_table(df: pd.DataFrame, videos_to_consider):\n",
    "    df = df[df[video_col].isin(videos_to_consider)]\n",
    "    return df.pivot_table(\n",
    "        values=['value'],\n",
    "        index=['object'],\n",
    "        columns=['min'],\n",
    "        aggfunc=numpy.sum\n",
    "    )\n",
    "\n",
    "videos_to_consider = set(holdout_model_res_df[video_col]) & \\\n",
    "                     set(holdout_golden_res_df[video_col]) & \\\n",
    "                     set(stop_watch_interaction_times_df[video_col])\n",
    "\n",
    "holdout_model_pivot_table = build_pivot_table(holdout_model_res_df, videos_to_consider)\n",
    "holdout_golden_pivot_table = build_pivot_table(holdout_golden_res_df, videos_to_consider)\n",
    "stop_watch_interaction_times_pivot_table = build_pivot_table(stop_watch_interaction_times_df, videos_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            value                                           \n",
       " min             1          2          3         4          5\n",
       " object                                                      \n",
       " 1        9.900000   8.166667   5.766667  1.666667   2.866667\n",
       " 2        9.200000   9.433333  12.533333  0.233333   0.633333\n",
       " 3       19.666667  20.266667  10.233333  0.066667   2.466667\n",
       " 4        9.066667  12.766667  19.766667  2.633333   4.000000\n",
       " 5       13.700000  10.400000   4.066667  1.333333  10.033333\n",
       " 6       18.833333  10.166667   5.466667  3.500000   5.666667,\n",
       "             value                                      \n",
       " min             1     2          3         4          5\n",
       " object                                                 \n",
       " 1        7.833333   5.7   4.000000  1.333333   1.733333\n",
       " 2        9.433333   9.6   7.333333  0.000000   0.333333\n",
       " 3       18.100000  16.6   9.500000  0.266667   2.700000\n",
       " 4        7.366667   8.6  17.366667  2.333333   3.500000\n",
       " 5        9.066667   9.1   3.300000  1.066667  10.066667\n",
       " 6       10.866667  11.7   2.766667  1.866667   6.600000,\n",
       "        value                      \n",
       " min        1     2     3    4    5\n",
       " object                            \n",
       " 1        9.9   4.1   5.8  2.5  2.3\n",
       " 2        7.6   8.9   7.5  0.2  0.3\n",
       " 3       15.6  14.7   7.2  2.0  1.1\n",
       " 4        7.7   5.1  15.2  1.1  2.7\n",
       " 5        8.4   5.9   3.1  1.4  8.6\n",
       " 6        9.6   9.0   3.3  3.9  2.4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_model_pivot_table, holdout_golden_pivot_table, stop_watch_interaction_times_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model differences from golden\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.066667</td>\n",
       "      <td>-2.466667</td>\n",
       "      <td>-1.766667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-5.200000</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.566667</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.700000</td>\n",
       "      <td>-4.166667</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.633333</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>-0.766667</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-7.966667</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>-2.700000</td>\n",
       "      <td>-1.633333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           value                                        \n",
       "min            1         2         3         4         5\n",
       "object                                                  \n",
       "1      -2.066667 -2.466667 -1.766667 -0.333333 -1.133333\n",
       "2       0.233333  0.166667 -5.200000 -0.233333 -0.300000\n",
       "3      -1.566667 -3.666667 -0.733333  0.200000  0.233333\n",
       "4      -1.700000 -4.166667 -2.400000 -0.300000 -0.500000\n",
       "5      -4.633333 -1.300000 -0.766667 -0.266667  0.033333\n",
       "6      -7.966667  1.533333 -2.700000 -1.633333  0.933333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model differences from golden')\n",
    "golden_vs_model_pivot_table = holdout_golden_pivot_table - holdout_model_pivot_table\n",
    "golden_vs_model_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop watch differences from golden\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.066667</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>-1.733333</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.266667</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>-2.033333</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           value                                   \n",
       "min            1    2         3         4         5\n",
       "object                                             \n",
       "1      -2.066667  1.6 -1.800000 -1.166667 -0.566667\n",
       "2       1.833333  0.7 -0.166667 -0.200000  0.033333\n",
       "3       2.500000  1.9  2.300000 -1.733333  1.600000\n",
       "4      -0.333333  3.5  2.166667  1.233333  0.800000\n",
       "5       0.666667  3.2  0.200000 -0.333333  1.466667\n",
       "6       1.266667  2.7 -0.533333 -2.033333  4.200000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Stop watch differences from golden')\n",
    "golden_vs_stop_watch_pivot_table = holdout_golden_pivot_table - stop_watch_interaction_times_pivot_table\n",
    "golden_vs_stop_watch_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.86666667, 13.6       ,  2.16666667, -4.23333333,  7.53333333])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_vs_stop_watch_pivot_table.values.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.        ,  2.2       ,  6.56666667,  7.36666667,  5.2       ,\n",
       "        5.6       ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_vs_stop_watch_pivot_table.values.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m help(plt\u001b[39m.\u001b[39mhist)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "help(plt.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., 1., 0., 0., 3., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 2., 1., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 0., 0., 2., 1., 2., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 5., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 2., 3., 1.]]),\n",
       " array([-7.96666667, -7.01666667, -6.06666667, -5.11666667, -4.16666667,\n",
       "        -3.21666667, -2.26666667, -1.31666667, -0.36666667,  0.58333333,\n",
       "         1.53333333]),\n",
       " <a list of 5 BarContainer objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(golden_vs_model_pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 1., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 2., 0.],\n",
       "        [1., 0., 1., 2., 0., 0., 2., 0., 0., 0.],\n",
       "        [2., 1., 2., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 2., 0., 0., 0., 1.]]),\n",
       " array([-2.06666667, -1.44      , -0.81333333, -0.18666667,  0.44      ,\n",
       "         1.06666667,  1.69333333,  2.32      ,  2.94666667,  3.57333333,\n",
       "         4.2       ]),\n",
       " <a list of 5 BarContainer objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(golden_vs_stop_watch_pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51fdd72c8e74e125f597ef5451e2ab80bdf6a3c052618ab754f2f9443adc0a9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
